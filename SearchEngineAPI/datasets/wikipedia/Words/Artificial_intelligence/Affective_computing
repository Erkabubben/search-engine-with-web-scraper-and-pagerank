affective computing from wikipedia the free encyclopedia jump to navigation jump to search this article needs to be updated please help update this article to reflect recent events or newly available information january 2023 area of research in computer science aiming to understand the emotional state of users affective computing is the study and development of systems and devices that can recognize interpret process and simulate human affects it is an interdisciplinary field spanning computer science psychology and cognitive science 91 1 93 while some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion 91 2 93 the more modern branch of computer science originated with rosalind picard s 1995 paper 91 3 93 on affective computing and her book affective computing 91 4 93 published by mit press 91 5 93 91 6 93 one of the motivations for the research is the ability to give machines emotional intelligence including to simulate empathy the machine should interpret the emotional state of humans and adapt its behavior to them giving an appropriate response to those emotions contents 1 areas 1 1 detecting and recognizing emotional information 1 2 emotion in machines 2 technologies 2 1 emotional speech 2 1 1 algorithms 2 1 2 databases 2 1 3 speech descriptors 2 2 facial affect detection 2 2 1 facial expression databases 2 2 2 emotion classification 2 2 3 facial action coding system 2 2 4 challenges in facial detection 2 3 body gesture 2 4 physiological monitoring 2 4 1 blood volume pulse 2 4 1 1 overview 2 4 1 2 methodology 2 4 1 3 disadvantages 2 4 2 facial electromyography 2 4 3 galvanic skin response 2 4 4 facial color 2 4 4 1 overview 2 4 4 2 methodology 2 5 visual aesthetics 3 potential applications 3 1 education 3 2 healthcare 3 3 video games 3 4 other applications 4 cognitivist vs interactional approaches 5 see also 6 citations 7 general sources 8 external links areas edit detecting and recognizing emotional information edit detecting emotional information usually begins with passive sensors that capture data about the user s physical state or behavior without interpreting the input the data gathered is analogous to the cues humans use to perceive emotions in others for example a video camera might capture facial expressions body posture and gestures while a microphone might capture speech other sensors detect emotional cues by directly measuring physiological data such as skin temperature and galvanic resistance 91 7 93 recognizing emotional information requires the extraction of meaningful patterns from the gathered data this is done using machine learning techniques that process different modalities such as speech recognition natural language processing or facial expression detection the goal of most of these techniques is to produce labels that would match the labels a human perceiver would give in the same situation for example if a person makes a facial expression furrowing their brow then the computer vision system might be taught to label their face as appearing confused or as concentrating or slightly negative as opposed to positive which it might say if they were smiling in a happy appearing way these labels may or may not correspond to what the person is actually feeling emotion in machines edit another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions a more practical approach based on current technological capabilities is the simulation of emotions in conversational agents in order to enrich and facilitate interactivity between human and machine 91 8 93 marvin minsky one of the pioneering computer scientists in artificial intelligence relates emotions to the broader issues of machine intelligence stating in the emotion machine that emotion is not especially different from the processes that we call thinking 91 9 93 technologies edit in psychology cognitive science and in neuroscience there have been two main approaches for describing how humans perceive and classify emotion continuous or categorical the continuous approach tends to use dimensions such as negative vs positive calm vs aroused the categorical approach tends to use discrete classes such as happy sad angry fearful surprise disgust different kinds of machine learning regression and classification models can be used for having machines produce continuous or discrete labels sometimes models are also built that allow combinations across the categories e g a happy surprised face or a fearful surprised face 91 10 93 the following sections consider many of the kinds of input data used for the task of emotion recognition emotional speech edit various changes in the autonomic nervous system can indirectly alter a person s speech and affective technologies can leverage this information to recognize emotion for example speech produced in a state of fear anger or joy becomes fast loud and precisely enunciated with a higher and wider range in pitch whereas emotions such as tiredness boredom or sadness tend to generate slow low pitched and slurred speech 91 11 93 some emotions have been found to be more easily computationally identified such as anger 91 12 93 or approval 91 13 93 emotional speech processing technologies recognize the user s emotional state using computational analysis of speech features vocal parameters and prosodic features such as pitch variables and speech rate can be analyzed through pattern recognition techniques 91 12 93 91 14 93 speech analysis is an effective method of identifying affective state having an average reported accuracy of 70 to 80 in research from 2003 and 2006 91 15 93 91 16 93 these systems tend to outperform average human accuracy approximately 60 91 12 93 but are less accurate than systems which employ other modalities for emotion detection such as physiological states or facial expressions 91 17 93 however since many speech characteristics are independent of semantics or culture this technique is considered to be a promising route for further research 91 18 93 algorithms edit the process of speech text affect detection requires the creation of a reliable database knowledge base or vector space model 91 19 93 broad enough to fit every need for its application as well as the selection of a successful classifier which will allow for quick and accurate emotion identification currently the most frequently used classifiers are linear discriminant classifiers ldc k nearest neighbor k nn gaussian mixture model gmm support vector machines svm artificial neural networks ann decision tree algorithms and hidden markov models hmms 91 20 93 various studies showed that choosing the appropriate classifier can significantly enhance the overall performance of the system 91 17 93 the list below gives a brief description of each algorithm ldc classification happens based on the value obtained from the linear combination of the feature values which are usually provided in the form of vector features k nn classification happens by locating the object in the feature space and comparing it with the k nearest neighbors training examples the majority vote decides on the classification gmm is a probabilistic model used for representing the existence of subpopulations within the overall population each sub population is described using the mixture distribution which allows for classification of observations into the sub populations 91 21 93 svm is a type of usually binary linear classifier which decides in which of the two or more possible classes each input may fall into ann is a mathematical model inspired by biological neural networks that can better grasp possible non linearities of the feature space decision tree algorithms work based on following a decision tree in which leaves represent the classification outcome and branches represent the conjunction of subsequent features that lead to the classification hmms a statistical markov model in which the states and state transitions are not directly available to observation instead the series of outputs dependent on the states are visible in the case of affect recognition the outputs represent the sequence of speech feature vectors which allow the deduction of states sequences through which the model progressed the states can consist of various intermediate steps in the expression of an emotion and each of them has a probability distribution over the possible output vectors the states sequences allow us to predict the affective state which we are trying to classify and this is one of the most commonly used techniques within the area of speech affect detection it is proved that having enough acoustic evidence available the emotional state of a person can be classified by a set of majority voting classifiers the proposed set of classifiers is based on three main classifiers knn c4 5 and svm rbf kernel this set achieves better performance than each basic classifier taken separately it is compared with two other sets of classifiers one against all oaa multiclass svm with hybrid kernels and the set of classifiers which consists of the following two basic classifiers c5 0 and neural network the proposed variant achieves better performance than the other two sets of classifiers 91 22 93 databases edit the vast majority of present systems are data dependent this creates one of the biggest challenges in detecting emotions based on speech as it implicates choosing an appropriate database used to train the classifier most of the currently possessed data was obtained from actors and is thus a representation of archetypal emotions those so called acted databases are usually based on the basic emotions theory by paul ekman which assumes the existence of six basic emotions anger fear disgust surprise joy sadness the others simply being a mix of the former ones 91 23 93 nevertheless these still offer high audio quality and balanced classes although often too few which contribute to high success rates in recognizing emotions however for real life application naturalistic data is preferred a naturalistic database can be produced by observation and analysis of subjects in their natural context ultimately such database should allow the system to recognize emotions based on their context as well as work out the goals and outcomes of the interaction the nature of this type of data allows for authentic real life implementation due to the fact it describes states naturally occurring during the human computer interaction hci despite the numerous advantages which naturalistic data has over acted data it is difficult to obtain and usually has low emotional intensity moreover data obtained in a natural context has lower signal quality due to surroundings noise and distance of the subjects from the microphone the first attempt to produce such database was the fau aibo emotion corpus for ceices combining efforts for improving automatic classification of emotional user states which was developed based on a realistic context of children age 10 13 playing with sony s aibo robot pet 91 24 93 91 25 93 likewise producing one standard database for all emotional research would provide a method of evaluating and comparing different affect recognition systems speech descriptors edit the complexity of the affect recognition process increases with the number of classes affects and speech descriptors used within the classifier it is therefore crucial to select only the most relevant features in order to assure the ability of the model to successfully identify emotions as well as increasing the performance which is particularly significant to real time detection the range of possible choices is vast with some studies mentioning the use of over 200 distinct features 91 20 93 it is crucial to identify those that are redundant and undesirable in order to optimize the system and increase the success rate of correct emotion detection the most common speech characteristics are categorized into the following groups 91 24 93 91 25 93 frequency characteristics 91 26 93 accent shape affected by the rate of change of the fundamental frequency average pitch description of how high low the speaker speaks relative to the normal speech contour slope describes the tendency of the frequency change over time it can be rising falling or level final lowering the amount by which the frequency falls at the end of an utterance pitch range measures the spread between the maximum and minimum frequency of an utterance time related features speech rate describes the rate of words or syllables uttered over a unit of time stress frequency measures the rate of occurrences of pitch accented utterances voice quality parameters and energy descriptors breathiness measures the aspiration noise in speech brilliance describes the dominance of high or low frequencies in the speech loudness measures the amplitude of the speech waveform translates to the energy of an utterance pause discontinuity describes the transitions between sound and silence pitch discontinuity describes the transitions of the fundamental frequency facial affect detection edit the detection and processing of facial expression are achieved through various methods such as optical flow hidden markov models neural network processing or active appearance models more than one modalities can be combined or fused multimodal recognition e g facial expressions and speech prosody 91 27 93 facial expressions and hand gestures 91 28 93 or facial expressions with speech and text for multimodal data and metadata analysis to provide a more robust estimation of the subject s emotional state affectiva is a company co founded by rosalind picard and rana el kaliouby directly related to affective computing and aims at investigating solutions and software for facial affect detection facial expression databases edit main article facial expression databases creation of an emotion database is a difficult and time consuming task however database creation is an essential step in the creation of a system that will recognize human emotions most of the publicly available emotion databases include posed facial expressions only in posed expression databases the participants are asked to display different basic emotional expressions while in spontaneous expression database the expressions are natural spontaneous emotion elicitation requires significant effort in the selection of proper stimuli which can lead to a rich display of intended emotions secondly the process involves tagging of emotions by trained individuals manually which makes the databases highly reliable since perception of expressions and their intensity is subjective in nature the annotation by experts is essential for the purpose of validation researchers work with three types of databases such as a database of peak expression images only a database of image sequences portraying an emotion from neutral to its peak and video clips with emotional annotations many facial expression databases have been created and made public for expression recognition purpose two of the widely used databases are ck and jaffe emotion classification edit main article emotion classification by doing cross cultural research in papua new guinea on the fore tribesmen at the end of the 1960s paul ekman proposed the idea that facial expressions of emotion are not culturally determined but universal thus he suggested that they are biological in origin and can therefore be safely and correctly categorized 91 23 93 he therefore officially put forth six basic emotions in 1972 91 29 93 anger disgust fear happiness sadness surprise however in the 1990s ekman expanded his list of basic emotions including a range of positive and negative emotions not all of which are encoded in facial muscles 91 30 93 the newly included emotions are amusement contempt contentment embarrassment excitement guilt pride in achievement relief satisfaction sensory pleasure shame facial action coding system edit main article facial action coding system a system has been conceived by psychologists in order to formally categorize the physical expression of emotions on faces the central concept of the facial action coding system or facs as created by paul ekman and wallace v friesen in 1978 based on earlier work by carl herman hjortsj 91 31 93 are action units au they are basically a contraction or a relaxation of one or more muscles psychologists have proposed the following classification of six basic emotions according to their action units here mean and emotion action units happiness 6 12 sadness 1 4 15 surprise 1 2 5b 26 fear 1 2 4 5 20 26 anger 4 5 7 23 disgust 9 15 16 contempt r12a r14a challenges in facial detection edit as with every computational practice in affect detection by facial processing some obstacles need to be surpassed in order to fully unlock the hidden potential of the overall algorithm or method employed in the early days of almost every kind of ai based detection speech recognition face recognition affect recognition the accuracy of modeling and tracking has been an issue as hardware evolves as more data are collected and as new discoveries are made and new practices introduced this lack of accuracy fades leaving behind noise issues however methods for noise removal exist including neighborhood averaging linear gaussian smoothing median filtering 91 32 93 or newer methods such as the bacterial foraging optimization algorithm 91 33 93 91 34 93 other challenges include the fact that posed expressions as used by most subjects of the various studies are not natural and therefore algorithms trained on these may not apply to natural expressions the lack of rotational movement freedom affect detection works very well with frontal use but upon rotating the head more than 20 degrees there ve been problems 91 35 93 facial expressions do not always correspond to an underlying emotion that matches them e g they can be posed or faked or a person can feel emotions but maintain a poker face facs did not include dynamics while dynamics can help disambiguate e g smiles of genuine happiness tend to have different dynamics than try to look happy smiles the facs combinations do not correspond in a 1 1 way with the emotions that the psychologists originally proposed note that this lack of a 1 1 mapping also occurs in speech recognition with homophones and homonyms and many other sources of ambiguity and may be mitigated by bringing in other channels of information accuracy of recognition is improved by adding context however adding context and other modalities increases computational cost and complexity body gesture edit main article gesture recognition gestures could be efficiently used as a means of detecting a particular emotional state of the user especially when used in conjunction with speech and face recognition depending on the specific action gestures could be simple reflexive responses like lifting your shoulders when you don t know the answer to a question or they could be complex and meaningful as when communicating with sign language without making use of any object or surrounding environment we can wave our hands clap or beckon on the other hand when using objects we can point at them move touch or handle these a computer should be able to recognize these analyze the context and respond in a meaningful way in order to be efficiently used for human computer interaction there are many proposed methods 91 36 93 to detect the body gesture some literature differentiates 2 different approaches in gesture recognition a 3d model based and an appearance based 91 37 93 the foremost method makes use of 3d information of key elements of the body parts in order to obtain several important parameters like palm position or joint angles on the other hand appearance based systems use images or videos to for direct interpretation hand gestures have been a common focus of body gesture detection methods 91 37 93 physiological monitoring edit this could be used to detect a user s affective state by monitoring and analyzing their physiological signs these signs range from changes in heart rate and skin conductance to minute contractions of the facial muscles and changes in facial blood flow this area is gaining momentum and we are now seeing real products that implement the techniques the four main physiological signs that are usually analyzed are blood volume pulse galvanic skin response facial electromyography and facial color patterns blood volume pulse edit overview edit a subject s blood volume pulse bvp can be measured by a process called photoplethysmography which produces a graph indicating blood flow through the extremities 91 38 93 the peaks of the waves indicate a cardiac cycle where the heart has pumped blood to the extremities if the subject experiences fear or is startled their heart usually jumps and beats quickly for some time causing the amplitude of the cardiac cycle to increase this can clearly be seen on a photoplethysmograph when the distance between the trough and the peak of the wave has decreased as the subject calms down and as the body s inner core expands allowing more blood to flow back to the extremities the cycle will return to normal methodology edit infra red light is shone on the skin by special sensor hardware and the amount of light reflected is measured the amount of reflected and transmitted light correlates to the bvp as light is absorbed by hemoglobin which is found richly in the bloodstream disadvantages edit it can be cumbersome to ensure that the sensor shining an infra red light and monitoring the reflected light is always pointing at the same extremity especially seeing as subjects often stretch and readjust their position while using a computer there are other factors that can affect one s blood volume pulse as it is a measure of blood flow through the extremities if the subject feels hot or particularly cold then their body may allow more or less blood to flow to the extremities all of this regardless of the subject s emotional state the corrugator supercilii muscle and zygomaticus major muscle are the 2 main muscles used for measuring the electrical activity in facial electromyography facial electromyography edit main article facial electromyography facial electromyography is a technique used to measure the electrical activity of the facial muscles by amplifying the tiny electrical impulses that are generated by muscle fibers when they contract 91 39 93 the face expresses a great deal of emotion however there are two main facial muscle groups that are usually studied to detect emotion the corrugator supercilii muscle also known as the frowning muscle draws the brow down into a frown and therefore is the best test for negative unpleasant emotional response the zygomaticus major muscle is responsible for pulling the corners of the mouth back when you smile and therefore is the muscle used to test for a positive emotional response here we can see a plot of skin resistance measured using gsr and time whilst the subject played a video game there are several peaks that are clear in the graph which suggests that gsr is a good method of differentiating between an aroused and a non aroused state for example at the start of the game where there is usually not much exciting game play there is a high level of resistance recorded which suggests a low level of conductivity and therefore less arousal this is in clear contrast with the sudden trough where the player is killed as one is usually very stressed and tense as their character is killed in the game galvanic skin response edit main article galvanic skin response galvanic skin response gsr is an outdated term for a more general phenomenon known as electrodermal activity or eda eda is a general phenomena whereby the skin s electrical properties change the skin is innervated by the sympathetic nervous system so measuring its resistance or conductance provides a way to quantify small changes in the sympathetic branch of the autonomic nervous system as the sweat glands are activated even before the skin feels sweaty the level of the eda can be captured usually using conductance and used to discern small changes in autonomic arousal the more aroused a subject is the greater the skin conductance tends to be 91 38 93 skin conductance is often measured using two small silver silver chloride electrodes placed somewhere on the skin and applying a small voltage between them to maximize comfort and reduce irritation the electrodes can be placed on the wrist legs or feet which leaves the hands fully free for daily activity facial color edit overview edit the surface of the human face is innervated with a large network of blood vessels blood flow variations in these vessels yield visible color changes on the face whether or not facial emotions activate facial muscles variations in blood flow blood pressure glucose levels and other changes occur also the facial color signal is independent from that provided by facial muscle movements 91 40 93 methodology edit approaches are based on facial color changes delaunay triangulation is used to create the triangular local areas some of these triangles which define the interior of the mouth and eyes sclera and iris are removed use the left triangular areas pixels to create feature vectors 91 40 93 it shows that converting the pixel color of the standard rgb color space to a color space such as orgb color space 91 41 93 or lms channels perform better when dealing with faces 91 42 93 so map the above vector onto the better color space and decompose into red green and yellow blue channels then use deep learning methods to find equivalent emotions visual aesthetics edit aesthetics in the world of art and photography refers to the principles of the nature and appreciation of beauty judging beauty and other aesthetic qualities is a highly subjective task computer scientists at penn state treat the challenge of automatically inferring the aesthetic quality of pictures using their visual content as a machine learning problem with a peer rated on line photo sharing website as a data source 91 43 93 they extract certain visual features based on the intuition that they can discriminate between aesthetically pleasing and displeasing images potential applications edit education edit affection influences learners learning state using affective computing technology computers can judge the learners affection and learning state by recognizing their facial expressions in education the teacher can use the analysis result to understand the student s learning and accepting ability and then formulate reasonable teaching plans at the same time they can pay attention to students inner feelings which is helpful to students psychological health especially in distance education due to the separation of time and space there is no emotional incentive between teachers and students for two way communication without the atmosphere brought by traditional classroom learning students are easily bored and affect the learning effect applying affective computing in distance education system can effectively improve this situation 91 44 93 healthcare edit social robots as well as a growing number of robots used in health care benefit from emotional awareness because they can better judge users and patient s emotional states and alter their actions programming appropriately this is especially important in those countries with growing aging populations and or a lack of younger workers to address their needs 91 45 93 affective computing is also being applied to the development of communicative technologies for use by people with autism 91 46 93 the affective component of a text is also increasingly gaining attention particularly its role in the so called emotional or emotive internet 91 47 93 video games edit affective video games can access their players emotional states through biofeedback devices 91 48 93 a particularly simple form of biofeedback is available through gamepads that measure the pressure with which a button is pressed this has been shown to correlate strongly with the players level of arousal 91 49 93 at the other end of the scale are brain computer interfaces 91 50 93 91 51 93 affective games have been used in medical research to support the emotional development of autistic children 91 52 93 other applications edit other potential applications are centered around social monitoring for example a car can monitor the emotion of all occupants and engage in additional safety measures such as alerting other vehicles if it detects the driver to be angry 91 53 93 affective computing has potential applications in human computer interaction such as affective mirrors allowing the user to see how he or she performs emotion monitoring agents sending a warning before one sends an angry email or even music players selecting tracks based on mood 91 54 93 one idea put forth by the romanian researcher dr nicu sebe in an interview is the analysis of a person s face while they are using a certain product he mentioned ice cream as an example 91 55 93 companies would then be able to use such analysis to infer whether their product will or will not be well received by the respective market one could also use affective state recognition in order to judge the impact of a tv advertisement through a real time video recording of that person and through the subsequent study of his or her facial expression averaging the results obtained on a large group of subjects one can tell whether that commercial or movie has the desired effect and what the elements which interest the watcher most are cognitivist vs interactional approaches edit within the field of human computer interaction rosalind picard s cognitivist or information model concept of emotion has been criticized by and contrasted with the post cognitivist or interactional pragmatist approach taken by kirsten boehner and others which views emotion as inherently social 91 56 93 picard s focus is human computer interaction and her goal for affective computing is to give computers the ability to recognize express and in some cases have emotions 91 4 93 in contrast the interactional approach seeks to help people to understand and experience their own emotions 91 57 93 and to improve computer mediated interpersonal communication it does not necessarily seek to map emotion into an objective mathematical model for machine interpretation but rather let humans make sense of each other s emotional expressions in open ended ways that might be ambiguous subjective and sensitive to context 91 57 93 58 8202 284 8202 91 example needed 93 picard s critics describe her concept of emotion as objective internal private and mechanistic they say it reduces emotion to a discrete psychological signal occurring inside the body that can be measured and which is an input to cognition undercutting the complexity of emotional experience 91 57 93 58 8202 280 8202 91 57 93 58 8202 278 8202 the interactional approach asserts that though emotion has biophysical aspects it is culturally grounded dynamically experienced and to some degree constructed in action and interaction 91 57 93 58 8202 276 8202 put another way it considers emotion as a social and cultural product experienced through our interactions 91 58 93 91 57 93 91 59 93 see also edit affect control theory affective design affective haptics chatterbot cyberemotions character computing emotion markup language emotionml emotion recognition friendly artificial intelligence kismet robot multimodal sentiment analysis sentiment analysis wearable computer citations edit tao jianhua tieniu tan 2005 affective computing a review affective computing and intelligent interaction vol 160 lncs 3784 springer pp 160 981 995 doi 10 1007 11573548 james william 1884 what is emotion mind 9 34 188 205 doi 10 1093 mind os ix 34 188 cited by tao and tan affective computing mit technical report 321 abstract 1995 a b picard rosalind 1997 affective computing cambridge ma mit press p 160 1 kleine cosack christian october 2006 recognition and simulation of emotions pdf archived from the original pdf on may 28 2008 retrieved may 13 2008 the introduction of emotion to computer science was done by pickard sic who created the field of affective computing diamond david december 2003 the love machine building computers that care wired archived from the original on 18 may 2008 retrieved may 13 2008 rosalind picard a genial mit professor is the field s godmother her 1997 book affective computing triggered an explosion of interest in the emotional side of computers and their users garay nestor idoia cearreta juan miguel l pez inmaculada fajardo april 2006 assistive technology and affective mediation pdf human technology 2 1 55 83 doi 10 17011 ht urn 2006159 archived pdf from the original on 28 may 2008 retrieved 2008 05 12 heise david 2004 enculturating agents with expressive role behavior in sabine payr trappl robert eds agent culture human agent interaction in a mutlicultural world lawrence erlbaum associates pp 160 127 142 restak richard 2006 12 17 mind over matter the washington post retrieved 2008 05 13 aleix and shichuan du martinez 2012 a model of the perception of facial expressions of emotion by humans research overview and perspectives pdf the journal of machine learning research 13 1 1589 1608 breazeal cynthia aryananda lijin 2002 recognition of affective communicative intent in robot directed speech pdf autonomous robots springer 12 1 83 104 doi 10 1023 a 1013215010749 issn 160 0929 5593 s2cid 160 459892 a b c dellaert f polizin t and waibel a recognizing emotion in speech in proc of icslp 1996 philadelphia pa pp 1970 1973 1996 roy d pentland a 1996 10 01 automatic spoken affect classification and analysis proceedings of the second international conference on automatic face and gesture recognition pp 160 363 367 doi 10 1109 afgr 1996 557292 isbn 160 978 0 8186 7713 7 s2cid 160 23157273 lee c m narayanan s pieraccini r recognition of negative emotion in the human speech signals workshop on auto speech recognition and understanding dec 2001 neiberg d elenius k laskowski k 2006 emotion recognition in spontaneous speech using gmms pdf proceedings of interspeech doi 10 21437 interspeech 2006 277 yacoub sherif simske steve lin xiaofan burns john 2003 recognition of emotions in interactive voice response systems proceedings of eurospeech 729 732 citeseerx 160 10 1 1 420 8158 doi 10 21437 eurospeech 2003 307 s2cid 160 11671944 a b hudlicka 2003 p 160 24 hudlicka 2003 p 160 25 charles osgood william may murray miron 1975 cross cultural universals of affective meaning univ of illinois press isbn 160 978 94 007 5069 2 a b scherer b nziger amp roesch 2010 p 160 241 gaussian mixture model connexions sharing knowledge and building communities retrieved 10 march 2011 s e khoruzhnikov et 160 al 2014 extended speech emotion recognition and prediction scientific and technical journal of information technologies mechanics and optics 14 6 137 a b ekman p amp friesen w v 1969 the repertoire of nonverbal behavior categories origins usage and coding semiotica 1 49 98 a b steidl stefan 5 march 2011 fau aibo emotion corpus pattern recognition lab a b scherer b nziger amp roesch 2010 p 160 243 singh premjeet saha goutam sahidullah md 2021 non linear frequency warping using constant q transformation for speech emotion recognition 2021 international conference on computer communication and informatics iccci pp 160 1 4 arxiv 2102 04029 doi 10 1109 iccci50826 2021 9402569 isbn 160 978 1 7281 5875 4 s2cid 160 231846518 caridakis g malatesta l kessous l amir n raouzaiou a karpouzis k november 2 4 2006 modeling naturalistic affective states via facial and vocal expressions recognition international conference on multimodal interfaces icmi 06 banff alberta canada balomenos t raouzaiou a ioannou s drosopoulos a karpouzis k kollias s 2004 emotion analysis in man machine interaction systems in bengio samy bourlard herve eds machine learning for multimodal interaction lecture notes in computer science vol 160 3361 springer verlag pp 160 318 328 ekman paul 1972 cole j ed universals and cultural differences in facial expression of emotion nebraska symposium on motivation lincoln nebraska university of nebraska press pp 160 207 283 ekman paul 1999 basic emotions in dalgleish t power m eds handbook of cognition and emotion pdf sussex uk john wiley amp sons archived from the original pdf on 2010 12 28 facial action coding system facs and the facs manual archived october 19 2013 at the wayback machine a human face retrieved 21 march 2011 spatial domain methods clever algorithms bacterial foraging optimization algorithm swarm algorithms clever algorithms archived 2019 06 12 at the wayback machine clever algorithms retrieved 21 march 2011 soft computing soft computing retrieved 18 march 2011 williams mark better face recognition software technology review technology review the authority on the future of technology retrieved 21 march 2011 j k aggarwal q cai human motion analysis a review computer vision and image understanding vol 73 no 3 1999 a b pavlovic vladimir i sharma rajeev huang thomas s 1997 visual interpretation of hand gestures for human computer interaction a review pdf ieee transactions on pattern analysis and machine intelligence 19 7 677 695 doi 10 1109 34 598226 a b picard rosalind 1998 affective computing mit larsen jt norris cj cacioppo jt effects of positive and negative affect on electromyographic activity over zygomaticus major and corrugator supercilii september 2003 a b benitez quiroz carlos f srinivasan ramprakash martinez aleix m 2018 03 19 facial color is an efficient mechanism to visually transmit emotion proceedings of the national academy of sciences 115 14 3581 3586 doi 10 1073 pnas 1716084115 pmc 160 5889636 pmid 160 29555780 bratkova margarita boulos solomon shirley peter 2009 orgb a practical opponent color space for computer graphics ieee computer graphics and applications 29 1 42 55 doi 10 1109 mcg 2009 13 pmid 160 19363957 s2cid 160 16690341 hadas shahar hagit hel or micro expression classification using facial color and deep learning methods the ieee international conference on computer vision iccv 2019 pp 0 0 ritendra datta dhiraj joshi jia li and james z wang studying aesthetics in photographic images using a computational approach lecture notes in computer science vol 3953 proceedings of the european conference on computer vision part iii pp 288 301 graz austria may 2006 wu chih hung huang yueh min hwang jan pan november 2016 review of affective computing in education learning trends and challenges british journal of educational technology 47 6 1304 1323 doi 10 1111 bjet 12324 yonck richard 2017 heart of the machine our future in a world of artificial emotional intelligence new york arcade publishing pp 160 150 153 isbn 160 9781628727333 oclc 160 956349457 projects in affective computing shanahan james qu yan wiebe janyce 2006 computing attitude and affect in text theory and applications dordrecht springer science amp business media p 94 isbn 160 1402040261 gilleade kiel mark dix alan allanson jen 2005 affective videogames and modes of affective gaming assist me challenge me emote me pdf proc digra conf archived from the original pdf on 2015 04 06 retrieved 2016 12 10 sykes jonathan brown simon 2003 affective gaming measuring emotion through the gamepad chi 03 extended abstracts on human factors in computing systems citeseerx 160 10 1 1 92 2123 doi 10 1145 765891 765957 isbn 160 1581136374 nijholt anton plass oude bos danny reuderink boris 2009 turning shortcomings into challenges brain computer interfaces for games pdf entertainment computing 1 2 85 94 bibcode 2009itie conf 153n doi 10 1016 j entcom 2009 09 007 reuderink boris nijholt anton poel mannes 2009 affective pacman a frustrating game for brain computer interface experiments intelligent technologies for interactive entertainment intetain pp 160 221 227 doi 10 1007 978 3 642 02315 6 23 isbn 160 978 3 642 02314 9 khandaker m 2009 designing affective video games to support the social emotional development of teenagers with autism spectrum disorders studies in health technology and informatics 144 37 9 pmid 160 19592726 in car facial recognition detects angry drivers to prevent road rage gizmodo 30 august 2018 janssen joris h van den broek egon l july 2012 tune in to your emotions a robust personalized affective music player user modeling and user adapted interaction 22 3 255 279 doi 10 1007 s11257 011 9107 7 mona lisa smiling computer scientists develop software that evaluates facial expressions sciencedaily 1 august 2006 archived from the original on 19 october 2007 battarbee katja koskinen ilpo 2005 co experience user experience as interaction pdf codesign 1 1 5 18 citeseerx 160 10 1 1 294 9178 doi 10 1080 15710880412331289917 s2cid 160 15296236 a b c d e f boehner kirsten depaula rogerio dourish paul sengers phoebe 2007 how emotion is made and measured international journal of human computer studies 65 4 275 291 doi 10 1016 j ijhcs 2006 11 016 boehner kirsten depaula rogerio dourish paul sengers phoebe 2005 affection from information to interaction proceedings of the aarhus decennial conference on critical computing 59 68 hook kristina staahl anna sundstrom petra laaksolahti jarmo 2008 interactional empowerment pdf proc chi 647 656 general sources edit hudlicka eva 2003 to feel or not to feel the role of affect in human computer interaction international journal of human computer studies 59 1 2 1 32 citeseerx 160 10 1 1 180 6429 doi 10 1016 s1071 5819 03 00047 8 scherer klaus r b nziger tanja roesch etienne b 2010 a blueprint for affective computing a sourcebook and manual oxford oxford university press external links edit affective computing research group at the mit media laboratory computational emotion group at usc emotion processing unit epu emotive computing group at the university of memphis 2011 international conference on affective computing and intelligent interaction brain body and bytes psychophysiological user interaction chi 2010 workshop 10 15 april 2010 ieee transactions on affective computing tac opensmile popular state of the art open source toolkit for large scale feature extraction for affect recognition and computational paralinguistics links to related articles vtecomputer sciencenote this template roughly follows the 2012 acm computing classification system hardware printed circuit board peripheral integrated circuit very large scale integration systems on chip socs energy consumption green computing electronic design automation hardware acceleration computer systems organization computer architecture embedded system real time computing dependability networks network architecture network protocol network components network scheduler network performance evaluation network service software organization interpreter middleware virtual machine operating system software quality software notations and tools programming paradigm programming language compiler domain specific language modeling language software framework integrated development environment software configuration management software library software repository software development control variable software development process requirements analysis software design software construction software deployment software engineering software maintenance programming team open source model theory of computation model of computation formal language automata theory computability theory computational complexity theory logic semantics algorithms algorithm design analysis of algorithms algorithmic efficiency randomized algorithm computational geometry mathematics of computing discrete mathematics probability statistics mathematical software information theory mathematical analysis numerical analysis theoretical computer science information systems database management system information storage systems enterprise information system social information systems geographic information system decision support system process control system multimedia information system data mining digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion detection system hardware security network security information security application security human computer interaction interaction design social computing ubiquitous computing visualization accessibility synthography concurrency concurrent computing parallel computing distributed computing multithreading multiprocessing artificial intelligence natural language processing knowledge representation and reasoning computer vision automated planning and scheduling search methodology control method philosophy of artificial intelligence distributed artificial intelligence machine learning supervised learning unsupervised learning reinforcement learning multi task learning cross validation graphics animation rendering image manipulation graphics processing unit mixed reality virtual reality image compression solid modeling applied computing e commerce enterprise software computational mathematics computational physics computational chemistry computational biology computational social science computational engineering computational healthcare digital art electronic publishing cyberwarfare electronic voting video games word processing operations research educational technology document management category outline wikiproject commons vteemotions list emotions acceptance admiration adoration aesthetic affection agitation agony amusement anger angst anguish annoyance anticipation anxiety apathy arousal attraction awe boredom calmness compassion confidence confusion contempt contentment courage cruelty curiosity defeat depression desire disappointment disgust distrust doubt ecstasy embarrassment vicarious empathy emptiness enthrallment enthusiasm envy euphoria excitement faith fear flow frustration gratification gratitude greed grief guilt happiness hatred hiraeth homesickness hope horror hostility humiliation hygge hysteria indulgence infatuation insecurity inspiration interest irritation isolation jealousy joy kindness loneliness love limerence lust mono no aware neglect nostalgia outrage panic passion pity self pity pleasure pride grandiosity hubris insult vanity rage regret rejection relief remorse resentment sadness melancholy saudade schadenfreude sehnsucht sentimentality shame shock shyness social connection sorrow spite stress chronic suffering surprise sympathy trust wonder sense of wonder worry worldviews cynicism defeatism nihilism optimism pessimism reclusion weltschmerz related affect consciousness in education measures in psychology affective computing forecasting neuroscience science spectrum affectivity positive negative appeal to emotion amygdala hijack emotion and art and memory and music and sex and sleep classification evolution expressed functional accounts group homeostatic in animals perception recognition in conversation regulation interpersonal work emotional aperture bias blackmail competence conflict contagion detachment dysregulation eating exhaustion expression and gender intelligence and bullying empathy quotient intimacy isolation lability labor lateralization literacy prosody reasoning responsivity security symbiosis emotional thought method well being emotionality bounded emotions and culture history in decision making in the workplace in virtual communication moral self conscious social social sharing sociology feeling group affective tone interactions between the emotional and executive brain systems jealousy in art meta emotion pathognomy pathos social emotional development stoic passions theory affect appraisal constructed emotion discrete emotion somatic marker italics indicate emotion names in foreign languages vtepsychology history philosophy portal psychologist basic psychology abnormal affective neuroscience affective science behavioral genetics behavioral neuroscience behaviorism cognitive cognitivism cognitive neuroscience social comparative cross cultural cultural developmental differential ecological evolutionary experimental gestalt intelligence mathematical moral neuropsychology perception personality positive psycholinguistics psychophysiology quantitative social theoretical applied psychology anomalistic applied behavior analysis assessment clinical coaching community consumer counseling critical educational ergonomics feminist forensic health industrial and organizational legal media medical military music occupational health pastoral political psychometrics psychotherapy religion school sport and exercise suicidology systems traffic methodologies animal testing archival research behavior epigenetics case study content analysis experiments human subject research interviews neuroimaging observation psychophysics qualitative research quantitative research self report inventory statistical surveys psychologists wilhelm wundt 160 1832 1920 william james 160 1842 1910 ivan pavlov 160 1849 1936 sigmund freud 160 1856 1939 edward thorndike 160 1874 1949 carl jung 160 1875 1961 john b watson 160 1878 1958 clark l hull 160 1884 1952 kurt lewin 160 1890 1947 jean piaget 160 1896 1980 gordon allport 160 1897 1967 j p guilford 160 1897 1987 carl rogers 160 1902 1987 erik erikson 160 1902 1994 b f skinner 160 1904 1990 donald o hebb 160 1904 1985 ernest hilgard 160 1904 2001 harry harlow 160 1905 1981 raymond cattell 160 1905 1998 abraham maslow 160 1908 1970 neal e miller 160 1909 2002 jerome bruner 160 1915 2016 donald t campbell 160 1916 1996 hans eysenck 160 1916 1997 herbert a simon 160 1916 2001 david mcclelland 160 1917 1998 leon festinger 160 1919 1989 george a miller 160 1920 2012 richard lazarus 160 1922 2002 stanley schachter 160 1922 1997 robert zajonc 160 1923 2008 albert bandura 160 1925 2021 roger brown 160 1925 1997 endel tulving 160 b 160 1927 lawrence kohlberg 160 1927 1987 noam chomsky 160 b 160 1928 ulric neisser 160 1928 2012 jerome kagan 160 1929 2021 walter mischel 160 1930 2018 elliot aronson 160 b 160 1932 daniel kahneman 160 b 160 1934 paul ekman 160 b 160 1934 michael posner 160 b 160 1936 amos tversky 160 1937 1996 bruce mcewen 160 1938 2020 larry squire 160 b 160 1941 richard e nisbett 160 b 160 1941 martin seligman 160 b 160 1942 ed diener 160 1946 2021 shelley e taylor 160 b 160 1946 john anderson 160 b 160 1947 ronald c kessler 160 b 160 1947 joseph e ledoux 160 b 160 1949 richard davidson 160 b 160 1951 susan fiske 160 b 160 1952 roy baumeister 160 b 160 1953 lists counseling topics disciplines organizations outline psychologists psychotherapies research methods schools of thought timeline topics wiktionary definition wiktionary category wikisource wikimedia commons wikiquote wikinews wikibooks vtepervasive gamesconcepts role playing persistence performing arts storytelling transmedia gamemaster ubiquitous computing context awareness crossmedia emergence genres ubiquitous games mobile games alternate reality games live action role playing games affective gaming smart toys location based games exergames augmented reality tabletop games serious games treasure hunts flash mobs transreality gaming developers blast theory eric zimmerman jane mcgonigal niantic mojang retrieved from https en wikipedia org w index php title affective computing amp oldid 1131015344 categories affective computingaffective sciencehidden categories cs1 long volume valuewebarchive template wayback linkswikipedia articles in need of updating from january 2023all wikipedia articles in need of updatingarticles with short descriptionshort description matches wikidataall articles needing examplesarticles needing examples from september 2018articles containing welsh language textarticles containing danish language textarticles containing japanese language textarticles containing portuguese language textarticles containing german language text 