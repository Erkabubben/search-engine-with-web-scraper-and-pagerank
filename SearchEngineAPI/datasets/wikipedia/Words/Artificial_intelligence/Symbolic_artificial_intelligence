symbolic artificial intelligence from wikipedia the free encyclopedia jump to navigation jump to search methods in artificial intelligence research part of a series onartificial intelligence major goals artificial general intelligence planning computer vision general game playing knowledge reasoning machine learning natural language processing robotics approaches symbolic deep learning bayesian networks evolutionary algorithms philosophy chinese room friendly ai control problem takeover ethics existential risk turing test history timeline progress ai winter technology applications projects programming languages glossary glossary vte in artificial intelligence symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high level symbolic human readable representations of problems logic and search 91 1 93 symbolic ai used tools such as logic programming production rules semantic nets and frames and it developed applications such as knowledge based systems in particular expert systems symbolic mathematics automated theorem provers ontologies the semantic web and automated planning and scheduling systems the symbolic ai paradigm led to seminal ideas in search symbolic programming languages agents multi agent systems the semantic web and the strengths and limitations of formal knowledge and reasoning systems symbolic ai was the dominant paradigm of ai research from the mid 1950s until the middle 1990s 91 2 93 91 3 93 researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the ultimate goal of their field 91 4 93 an early boom with early successes such as the logic theorist and samuel s checker s playing program led to unrealistic expectations and promises and was followed by the first ai winter as funding dried up 91 5 93 91 6 93 a second boom 1969 1986 occurred with the rise of expert systems their promise of capturing corporate expertise and an enthusiastic corporate embrace 91 7 93 91 8 93 that boom and some early successes e g with xcon at dec was followed again by later disappointment 91 8 93 problems with difficulties in knowledge acquisition maintaining large knowledge bases and brittleness in handling out of domain problems arose another second ai winter 1988 2011 followed 91 9 93 subsequently ai researchers focused on addressing underlying problems in handling uncertainty and in knowledge acquisition 91 10 93 uncertainty was addressed with formal methods such as hidden markov models bayesian reasoning and statistical relational learning 91 11 93 91 12 93 symbolic machine learning addressed the knowledge acquisition problem with contributions including version space valiant s pac learning quinlan s id3 decision tree learning case based learning and inductive logic programming to learn relations 91 10 93 neural networks a sub symbolic approach had been pursued from early days and was to reemerge strongly in 2012 early examples are rosenblatt s perceptron learning work the backpropagation work of rumelhart hinton and williams 91 13 93 and work in convolutional neural networks by lecun et al in 1989 91 14 93 however neural networks were not viewed as successful until about 2012 until big data became commonplace the general consensus in the al community was that the so called neural network approach was hopeless systems just didn t work that well compared to other methods a revolution came in 2012 when a number of people including a team of researchers working with hinton worked out a way to use the power of gpus to enormously increase the power of neural networks 91 15 93 over the next several years deep learning had spectacular success in handling vision speech recognition speech synthesis image generation and machine translation however since 2020 as inherent difficulties with bias explanation comprehensibility and robustness became more apparent with deep learning approaches an increasing number of ai researchers have called for combining the best of both the symbolic and neural network approaches 91 16 93 91 17 93 and addressing areas that both approaches have difficulty with such as common sense reasoning 91 15 93 contents 1 foundational ideas 2 a short history 2 1 the first ai summer irrational exuberance 1948 1966 2 1 1 approaches inspired by human or animal cognition or behavior 2 1 2 heuristic search 2 1 3 early work on knowledge representation and reasoning 2 1 3 1 modeling formal reasoning with logic the neats 2 1 3 2 modeling implicit common sense knowledge with frames and scripts the scruffies 2 2 the first ai winter crushed dreams 1967 1977 2 3 the second ai summer knowledge is power 1978 1987 2 3 1 knowledge based systems 2 3 2 success with expert systems 2 3 2 1 examples 2 3 2 2 architecture of knowledge based and expert systems 2 4 the second ai winter 1988 1993 2 5 adding in more rigorous foundations 1993 2011 2 5 1 uncertain reasoning 2 5 2 machine learning 2 6 deep learning and neuro symbolic ai 2011 now 2 6 1 neuro symbolic ai integrating neural and symbolic approaches 3 techniques and contributions 3 1 ai programming languages 3 2 search 3 3 knowledge representation and reasoning 3 3 1 knowledge representation 3 3 2 automatic theorem proving 3 3 3 reasoning in knowledge based systems 3 3 4 commonsense reasoning 3 3 5 constraints and constraint based reasoning 3 4 automated planning 3 5 natural language processing 3 6 agents and multi agent systems 4 controversies 4 1 connectionist ai philosophical challenges and sociological conflicts 4 2 philosophical critiques from dreyfus and other philosophers 4 3 situated robotics the world as a model 4 4 current views 5 see also 6 notes 7 citations 8 references foundational ideas edit the symbolic approach was succinctly expressed in the physical symbol systems hypothesis proposed by newell and simon in 1976 a physical symbol system has the necessary and sufficient means of general intelligent action 91 18 93 later practitioners using knowledge based approaches adopted a second maxim in the knowledge lies the power 91 19 93 to describe that high performance in a specific domain required both general and highly domain specific knowledge ed feigenbaum and doug lenat called this the knowledge principle 1 the knowledge principle if a program is to perform a complex task well it must know a great deal about the world in which it operates 2 a plausible extension of that principle called the breadth hypothesis there are two additional abilities necessary for intelligent behavior in unexpected situations falling back on increasingly general knowledge and analogizing to specific but far flung knowledge 91 20 93 finally with the rise of deep learning the symbolic ai approach has been compared to deep learning as complementary with parallels having been drawn many times by ai researchers between kahneman s research on human reasoning and decision making reflected in his book thinking fast and slow and the so called ai systems 1 and 2 which would in principle be modelled by deep learning and symbolic reasoning respectively in this view symbolic reasoning is more apt for deliberative reasoning planning and explanation while deep learning is more apt for fast pattern recognition in perceptual applications with noisy data 91 16 93 91 17 93 a short history edit a short history of symbolic ai to the present day follows below time periods and titles are drawn from henry kautz s 2020 aaai robert s engelmore memorial lecture 91 21 93 and the longer wikipedia article on the history of ai with dates and titles differing slightly for increased clarity the first ai summer irrational exuberance 1948 1966 edit success at early attempts in ai occurred in three main areas artificial neural networks knowledge representation and heuristic search contributing to high expectations this section summarizes kautz s reprise of early ai history approaches inspired by human or animal cognition or behavior edit cybernetic approaches attempted to replicate the feedback loops between animals and their environments a robotic turtle with sensors motors for driving and steering and seven vacuum tubes for control based on a preprogrammed neural net was built as early as 1948 this work can be seen as an early precursor to later work in neural networks reinforcement learning and situated robotics 91 22 93 an important early symbolic ai program was the logic theorist written by allen newell herbert simon and cliff shaw in 1955 56 as it was able to prove 38 elementary theorems from whitehead and russell s principia mathematica newell simon and shaw later generalized this work to create a domain independent problem solver gps general problem solver gps solved problems represented with formal operators via state space search using means ends analysis 91 23 93 during the 1960s symbolic approaches achieved great success at simulating intelligent behavior in structured environments such as game playing symbolic mathematics and theorem proving ai research was centered in three institutions in the 1960s carnegie mellon university stanford mit and later university of edinburgh each one developed its own style of research earlier approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background herbert simon and allen newell studied human problem solving skills and attempted to formalize them and their work laid the foundations of the field of artificial intelligence as well as cognitive science operations research and management science their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems 91 24 93 91 25 93 this tradition centered at carnegie mellon university would eventually culminate in the development of the soar architecture in the middle 1980s 91 26 93 91 27 93 heuristic search edit in addition to the highly specialized domain specific kinds of knowledge that we will see later used in expert systems early symbolic ai researchers discovered another more general application of knowledge these were called heuristics rules of thumb that guide a search in promising directions how can non enumerative search be practical when the underlying problem is exponentially hard the approach advocated by simon and newell is to employ heuristics fast algorithms that may fail on some inputs or output suboptimal solutions 91 28 93 another important advance was to find a way to apply these heuristics that guarantees a solution will be found if there is one not withstanding the occasional fallibility of heuristics the a algorithm provided a general frame for complete and optimal heuristically guided search a is used as a subroutine within practically every ai algorithm today but is still no magic bullet its guarantee of completeness is bought at the cost of worst case exponential time 91 28 93 early work on knowledge representation and reasoning edit early work covered both applications of formal reasoning emphasizing first order logic along with attempts to handle common sense reasoning in a less formal manner modeling formal reasoning with logic the neats edit main article logic programming unlike simon and newell john mccarthy felt that machines did not need to simulate the exact mechanisms of human thought but could instead try to find the essence of abstract reasoning and problem solving with logic regardless of whether people used the same algorithms 91 a 93 his laboratory at stanford sail focused on using formal logic to solve a wide variety of problems including knowledge representation planning and learning 91 32 93 logic was also the focus of the work at the university of edinburgh and elsewhere in europe which led to the development of the programming language prolog and the science of logic programming 91 33 93 91 34 93 modeling implicit common sense knowledge with frames and scripts the scruffies edit main article neats vs scruffies researchers at mit such as marvin minsky and seymour papert 91 35 93 91 36 93 91 37 93 found that solving difficult problems in vision and natural language processing required ad hoc solutions they argued that no simple and general principle like logic would capture all the aspects of intelligent behavior roger schank described their anti logic approaches as scruffy as opposed to the neat paradigms at cmu and stanford 91 38 93 91 39 93 commonsense knowledge bases such as doug lenat s cyc are an example of scruffy ai since they must be built by hand one complicated concept at a time 91 40 93 91 41 93 91 42 93 the first ai winter crushed dreams 1967 1977 edit the first ai winter was a shock during the first ai summer many people thought that machine intelligence could be achieved in just a few years the defense advance research projects agency darpa launched programs to support ai research with the goal of using ai to solve problems of national security in particular to automate the translation of russian to english for intelligence operations and to create autonomous tanks for the battlefield researchers had begun to realize that achieving ai was going to be much harder than was supposed a decade earlier but a combination of hubris and disingenuousness led many university and think tank researchers to accept funding with promises of deliverables that they should have known they could not fulfill by the mid 1960s neither useful natural language translation systems nor autonomous tanks had been created and a dramatic backlash set in new darpa leadership canceled existing ai funding programs outside of the united states the most fertile ground for ai research was the united kingdom the ai winter in the united kingdom was spurred on not so much by disappointed military leaders as by rival academics who viewed ai researchers as charlatans and a drain on research funding a professor of applied mathematics sir james lighthill was commissioned by parliament to evaluate the state of ai research in the nation the report stated that all of the problems being worked on in ai would be better handled by researchers from other disciplines such as applied mathematics the report also claimed that ai successes on toy problems could never scale to real world applications due to combinatorial explosion 91 43 93 the second ai summer knowledge is power 1978 1987 edit knowledge based systems edit as limitations with weak domain independent methods became more and more apparent 91 44 93 researchers from all three traditions began to build knowledge into ai applications 91 45 93 91 46 93 the knowledge revolution was driven by the realization that knowledge underlies high performance domain specific ai applications success with expert systems edit main article expert systems this knowledge revolution led to the development and deployment of expert systems introduced by edward feigenbaum the first commercially successful form of ai software 91 47 93 91 48 93 91 49 93 examples edit key expert systems were dendral which found the structure of organic molecules from their chemical formula and mass spectrometer readings mycin which diagnosed bacteremia and suggested further lab tests when necessary by interpreting lab results patient history and doctor observations with about 450 rules mycin was able to perform as well as some experts and considerably better than junior doctors 91 50 93 internist and caduceus which tackled internal medicine diagnosis internist attempted to capture the expertise of the chairman of internal medicine at the university of pittsburgh school of medicine while caduceus could eventually diagnose up to 1000 different diseases guidon which showed how a knowledge base built for expert problem solving could be repurposed for teaching 91 51 93 xcon to configure vax computers a then laborious process that could take up to 90 days xcon reduced the time to about 90 minutes 91 52 93 dendral is considered the first expert system that relied on knowledge intensive problem solving it is described below by ed feigenbaum from a communications of the acm interview interview with ed feigenbaum one of the people at stanford interested in computer based models of mind was joshua lederberg the 1958 nobel prize winner in genetics when i told him i wanted an induction sandbox he said i have just the one for you his lab was doing mass spectrometry of amino acids the question was how do you go from looking at a spectrum of an amino acid to the chemical structure of the amino acid that s how we started the dendral project i was good at heuristic search methods and he had an algorithm which was good at generating the chemical problem space we did not have a grandiose vision we worked bottom up our chemist was carl djerassi inventor of the chemical behind the birth control pill and also one of the world s most respected mass spectrometrists carl and his postdocs were world class experts in mass spectrometry we began to add in their knowledge inventing knowledge engineering as we were going along these experiments amounted to titrating into dendral more and more knowledge the more you did that the smarter the program became we had very good results the generalization was in the knowledge lies the power that was the big idea in my career that is the huge ah ha and it wasn t the way ai was being done previously sounds simple but it s probably ai s most powerful generalization 91 53 93 the other expert systems mentioned above came after dendral mycin exemplifies the classic expert system architecture of a knowledge base of rules coupled to a symbolic reasoning mechanism including the use of certainty factors to handle uncertainty guidon shows how an explicit knowledge base can be repurposed for a second application tutoring and is an example of an intelligent tutoring system a particular kind of knowledge based application clancey showed that it was not sufficient simply to use mycin s rules for instruction but that he also needed to add rules for dialogue management and student modeling 91 51 93 xcon is significant because of the millions of dollars it saved dec which triggered the expert system boom where most all major corporations in the us had expert systems groups with the aim to capture corporate expertise preserve it and automate it by 1988 dec s ai group had 40 expert systems deployed with more on the way dupont had 100 in use and 500 in development nearly every major u s corporation had its own al group and was either using or investigating expert systems 91 54 93 chess expert knowledge was encoded in deep blue in 1996 this allowed ibm s deep blue with the help of symbolic ai to win in a game of chess against the world champion at that time garry kasparov 91 55 93 architecture of knowledge based and expert systems edit a key component of the system architecture for all expert systems is the knowledge base which stores facts and rules for problem solving 91 56 93 the simplest approach for an expert system knowledge base is simply a collection or network of production rules production rules connect symbols in a relationship similar to an if then statement the expert system processes the rules to make deductions and to determine what additional information it needs i e what questions to ask using human readable symbols for example ops5 clips and their successors jess and drools operate in this fashion expert systems can operate in either a forward chaining from evidence to conclusions or backward chaining from goals to needed data and prerequisites manner more advanced knowledge based systems such as soar can also perform meta level reasoning that is reasoning about their own reasoning in terms of deciding how to solve problems and monitoring the success of problem solving strategies blackboard systems are a second kind of knowledge based or expert system architecture they model a community of experts incrementally contributing where they can to solve a problem the problem is represented in multiple levels of abstraction or alternate views the experts knowledge sources volunteer their services whenever they recognize they can make a contribution potential problem solving actions are represented on an agenda that is updated as the problem situation changes a controller decides how useful each contribution is and who should make the next problem solving action one example the bb1 blackboard architecture 91 57 93 was originally inspired by studies of how humans plan to perform multiple tasks in a trip 91 58 93 an innovation of bb1 was to apply the same blackboard model to solving its own control problem i e its controller performed meta level reasoning with knowledge sources that monitored how well a plan or the problem solving was proceeding and could switch from one strategy to another as conditions such as goals or times changed bb1 was applied in multiple domains construction site planning intelligent tutoring systems and real time patient monitoring the second ai winter 1988 1993 edit at the height of the ai boom companies such as symbolics lmi and texas instruments were selling lisp machines specifically targeted to accelerate the development of ai applications and research in addition several artificial intelligence companies such as teknowledge and inference corporation were selling expert system shells training and consulting to corporations unfortunately the ai boom did not last and kautz best describes the second ai winter that followed many reasons can be offered for the arrival of the second ai winter the hardware companies failed when much more cost effective general unix workstations from sun together with good compilers for lisp and prolog came onto the market many commercial deployments of expert systems were discontinued when they proved too costly to maintain medical expert systems never caught on for several reasons the difficulty in keeping them up to date the challenge for medical professionals to learn how to use a bewildering variety of different expert systems for different medical conditions and perhaps most crucially the reluctance of doctors to trust a computer made diagnosis over their gut instinct even for specific domains where the expert systems could outperform an average doctor venture capital money deserted ai practically overnight the world ai conference ijcai hosted an enormous and lavish trade show and thousands of nonacademic attendees in 1987 in vancouver the main ai conference the following year aaai 1988 in st paul was a small and strictly academic affair 91 52 93 adding in more rigorous foundations 1993 2011 edit uncertain reasoning edit both statistical approaches and extensions to logic were tried one statistical approach hidden markov models had already been popularized in the 1980s for speech recognition work 91 11 93 subsequently in 1988 judea pearl popularized the use of bayesian networks as a sound but efficient way of handling uncertain reasoning with his publication of the book probabilistic reasoning in intelligent systems networks of plausible inference 91 59 93 and bayesian approaches were applied successfully in expert systems 91 60 93 even later in the 1990s statistical relational learning an approach that combines probability with logical formulas allowed probability to be combined with first order logic e g with either markov logic networks or probabilistic soft logic other non probabilistic extensions to first order logic to support were also tried for example non monotonic reasoning could be used with truth maintenance systems a truth maintenance system tracked assumptions and justifications for all inferences it allowed inferences to be withdrawn when assumptions were found out to be incorrect or a contradiction was derived explanations could be provided for an inference by explaining which rules were applied to create it and then continuing through underlying inferences and rules all the way back to root assumptions 91 61 93 lofti zadeh had introduced a different kind of extension to handle the representation of vagueness for example in deciding how heavy or tall a man is there is frequently no clear yes or no answer and a predicate for heavy or tall would instead return values between 0 and 1 those values represented to what degree the predicates were true his fuzzy logic further provided a means for propagating combinations of these values through logical formulas 91 62 93 machine learning edit symbolic machine learning approaches were investigated to address the knowledge acquisition bottleneck one of the earliest is meta dendral meta dendral used a generate and test technique to generate plausible rule hypotheses to test against spectra domain and task knowledge reduced the number of candidates tested to a manageable size feigenbaum described meta dendral as the culmination of my dream of the early to mid 1960s having to do with theory formation the conception was that you had a problem solver like dendral that took some inputs and produced an output in doing so it used layers of knowledge to steer and prune the search that knowledge got in there because we interviewed people but how did the people get the knowledge by looking at thousands of spectra so we wanted a program that would look at thousands of spectra and infer the knowledge of mass spectrometry that dendral could use to solve individual hypothesis formation problems we did it we were even able to publish new knowledge of mass spectrometry in the journal of the american chemical society giving credit only in a footnote that a program meta dendral actually did it we were able to do something that had been a dream to have a computer program come up with a new and publishable piece of science 91 53 93 in contrast to the knowledge intensive approach of meta dendral ross quinlan invented a domain independent approach to statistical classification decision tree learning starting first with id3 91 63 93 and then later extending its capabilities to c4 5 91 64 93 the decision trees created are glass box interpretable classifiers with human interpretable classification rules advances were made in understanding machine learning theory too tom mitchell introduced version space learning which describes learning as search through a space of hypotheses with upper more general and lower more specific boundaries encompassing all viable hypotheses consistent with the examples seen so far 91 65 93 more formally valiant introduced probably approximately correct learning pac learning a framework for the mathematical analysis of machine learning 91 66 93 symbolic machine learning encompassed more than learning by example e g john anderson provided a cognitive model of human learning where skill practice results in a compilation of rules from a declarative format to a procedural format with his act r cognitive architecture for example a student might learn to apply supplementary angles are two angles whose measures sum 180 degrees as several different procedural rules e g one rule might say that if x and y are supplementary and you know x then y will be 180 x he called his approach knowledge compilation act r has been used successfully to model aspects of human cognition such as learning and retention act r is also used in intelligent tutoring systems called cognitive tutors to successfully teach geometry computer programming and algebra to school children 91 67 93 inductive logic programming was another approach to learning that allowed logic programs to be synthesized from input output examples e g ehud shapiro s mis model inference system could synthesize prolog programs from examples 91 68 93 john r koza applied genetic algorithms to program synthesis to create genetic programming which he used to synthesize lisp programs finally manna and waldinger provided a more general approach to program synthesis that synthesizes a functional program in the course of proving its specifications to be correct 91 69 93 as an alternative to logic roger schank introduced case based reasoning cbr the cbr approach outlined in his book dynamic memory 91 70 93 focuses first on remembering key problem solving cases for future use and generalizing them where appropriate when faced with a new problem cbr retrieves the most similar previous case and adapts it to the specifics of the current problem 91 71 93 another alternative to logic genetic algorithms and genetic programming are based on an evolutionary model of learning where sets of rules are encoded into populations the rules govern the behavior of individuals and selection of the fittest prunes out sets of unsuitable rules over many generations 91 72 93 symbolic machine learning was applied to learning concepts rules heuristics and problem solving approaches other than those above include learning from instruction or advice i e taking human instruction posed as advice and determining how to operationalize it in specific situations for example in a game of hearts learning exactly how to play a hand to avoid taking points 91 73 93 learning from exemplars improving performance by accepting subject matter expert sme feedback during training when problem solving fails querying the expert to either learn a new exemplar for problem solving or to learn a new explanation as to exactly why one exemplar is more relevant than another for example the program protos learned to diagnose tinnitus cases by interacting with an audiologist 91 74 93 learning by analogy constructing problem solutions based on similar problems seen in the past and then modifying their solutions to fit a new situation or domain 91 75 93 91 76 93 apprentice learning systems learning novel solutions to problems by observing human problem solving domain knowledge explains why novel solutions are correct and how the solution can be generalized leap learned how to design vlsi circuits by observing human designers 91 77 93 learning by discovery i e creating tasks to carry out experiments and then learning from the results doug lenat s eurisko for example learned heuristics to beat human players at the traveller role playing game for two years in a row 91 78 93 learning macro operators i e searching for useful macro operators to be learned from sequences of basic problem solving actions good macro operators simplify problem solving by allowing problems to be solved at a more abstract level 91 79 93 deep learning and neuro symbolic ai 2011 now edit neuro symbolic ai integrating neural and symbolic approaches edit neuro symbolic ai attempts to integrate neural and symbolic architectures in a manner that addresses strengths and weaknesses of each in a complementary fashion in order to support robust ai capable of reasoning learning and cognitive modeling as argued by valiant 91 80 93 and many others 91 81 93 the effective construction of rich computational cognitive models demands the combination of sound symbolic reasoning and efficient machine learning models gary marcus similarly argues that we cannot construct rich cognitive models in an adequate automated way without the triumvirate of hybrid architecture rich prior knowledge and sophisticated techniques for reasoning 91 82 93 and in particular to build a robust knowledge driven approach to ai we must have the machinery of symbol manipulation in our toolkit too much of useful knowledge is abstract to make do without tools that represent and manipulate abstraction and to date the only machinery that we know of that can manipulate such abstract knowledge reliably is the apparatus of symbol manipulation 91 83 93 henry kautz 91 21 93 francesca rossi 91 84 93 and bart selman 91 85 93 have also argued for a synthesis their arguments are based on a need to address the two kinds of thinking discussed in daniel kahneman s book thinking fast and slow kahneman describes human thinking as having two components system 1 and system 2 system 1 is fast automatic intuitive and unconscious system 2 is slower step by step and explicit system 1 is the kind used for pattern recognition while system 2 is far better suited for planning deduction and deliberative thinking in this view deep learning best models the first kind of thinking while symbolic reasoning best models the second kind and both are needed garcez describes research in this area as being ongoing for at least the past twenty years 91 86 93 dating from his 2002 book on neurosymbolic learning systems 91 87 93 a series of workshops on neuro symbolic reasoning has been held every year since 2005 see http www neural symbolic org for details in their 2015 paper neural symbolic learning and reasoning contributions and challenges garcez et al argue that the integration of the symbolic and connectionist paradigms of ai has been pursued by a relatively small research community over the last two decades and has yielded several significant results over the last decade neural symbolic systems have been shown capable of overcoming the so called propositional fixation of neural networks as mccarthy 1988 put it in response to smolensky 1988 see also hinton 1990 neural networks were shown capable of representing modal and temporal logics d avila garcez and lamb 2006 and fragments of first order logic bader hitzler h lldobler 2008 d avila garcez lamb gabbay 2009 further neural symbolic systems have been applied to a number of problems in the areas of bioinformatics control engineering software verification and adaptation visual intelligence ontology learning and computer games 91 81 93 approaches for integration are varied henry kautz s taxonomy of neuro symbolic architectures along with some examples follows symbolic neural symbolic is the current approach of many neural models in natural language processing where words or subword tokens are both the ultimate input and output of large language models examples include bert roberta and gpt 3 symbolic neural is exemplified by alphago where symbolic techniques are used to call neural techniques in this case the symbolic approach is monte carlo tree search and the neural techniques learn how to evaluate game positions neural symbolic uses a neural architecture to interpret perceptual data as symbols and relationships that are then reasoned about symbolically neural symbolic neural relies on symbolic reasoning to generate or label training data that is subsequently learned by a deep learning model e g to train a neural model for symbolic computation by using a macsyma like symbolic mathematics system to create or label examples neural symbolic uses a neural net that is generated from symbolic rules an example is the neural theorem prover 91 88 93 which constructs a neural network from an and or proof tree generated from knowledge base rules and terms logic tensor networks 91 89 93 also fall into this category neural symbolic allows a neural model to directly call a symbolic reasoning engine e g to perform an action or evaluate a state many key research questions remain such as what is the best way to integrate neural and symbolic architectures how should symbolic structures be represented within neural networks and extracted from them how should common sense knowledge be learned and reasoned about how can abstract knowledge that is hard to encode logically be handled techniques and contributions edit this section provides an overview of techniques and contributions in an overall context leading to many other more detailed articles in wikipedia sections on machine learning and uncertain reasoning are covered earlier in the history section ai programming languages edit the key ai programming language in the us during the last symbolic ai boom period was lisp lisp is the second oldest programming language after fortran and was created in 1958 by john mccarthy lisp provided the first read eval print loop to support rapid program development compiled functions could be freely mixed with interpreted functions program tracing stepping and breakpoints were also provided along with the ability to change values or functions and continue from breakpoints or errors it had the first self hosting compiler meaning that the compiler itself was originally written in lisp and then ran interpretively to compile the compiler code other key innovations pioneered by lisp that have spread to other programming languages include garbage collection dynamic typing higher order functions recursion conditionals programs were themselves data structures that other programs could operate on allowing the easy definition of higher level languages in contrast to the us in europe the key ai programming language during that same period was prolog prolog provided a built in store of facts and clauses that could be queried by a read eval print loop the store could act as a knowledge base and the clauses could act as rules or a restricted form of logic as a subset of first order logic prolog was based on horn clauses with a closed world assumption any facts not known were considered false and a unique name assumption for primitive terms e g the identifier barack obama was considered to refer to exactly one object backtracking and unification are built in to prolog alain colmerauer and philippe roussel are credited as the inventors of prolog prolog is a form of logic programming which was invented by robert kowalski its history was also influenced by carl hewitt s planner an assertional database with pattern directed invocation of methods for more detail see the section on the origins of prolog in the planner article prolog is also a kind of declarative programming the logic clauses that describe programs are directly interpreted to run the programs specified no explicit series of actions is required as is the case with imperative programming languages japan championed prolog for its fifth generation project intending to build special hardware for high performance similarly lisp machines were built to run lisp but as the second ai boom turned to bust these companies could not compete with new workstations that could now run lisp or prolog natively at comparable speeds see the history section for more detail smalltalk was another influential ai programming language for example it introduced metaclasses and along with flavors and commonloops influenced the common lisp object system or clos that is now part of common lisp the current standard lisp dialect clos is a lisp based object oriented system that allows multiple inheritance in addition to incremental extensions to both classes and metaclasses thus providing a run time meta object protocol 91 90 93 for other ai programming languages see this list of programming languages for artificial intelligence currently python a multi paradigm programming language is the most popular programming language partly due to its extensive package library that supports data science natural language processing and deep learning python includes a read eval print loop functional elements such as higher order functions and object oriented programming that includes metaclasses search edit main article combinatorial search search arises in many kinds of problem solving including planning constraint satisfaction and playing games such as checkers chess and go the best known ai search tree search algorithms are breadth first search depth first search a and monte carlo search key search algorithms for boolean satisfiability are walksat conflict driven clause learning and the dpll algorithm for adversarial search when playing games alpha beta pruning branch and bound and minimax were early contributions knowledge representation and reasoning edit main article knowledge representation and reasoning multiple different approaches to represent knowledge and then reason with those representations have been investigated below is a quick overview of approaches to knowledge representation and automated reasoning knowledge representation edit main article knowledge representation semantic networks conceptual graphs frames and logic are all approaches to modeling knowledge such as domain knowledge problem solving knowledge and the semantic meaning of language ontologies model key concepts and their relationships in a domain example ontologies are yago wordnet and dolce dolce is an example of an upper ontology that can be used for any domain while wordnet is a lexical resource that can also be viewed as an ontology yago incorporates wordnet as part of its ontology to align facts extracted from wikipedia with wordnet synsets the disease ontology is an example of a medical ontology currently being used description logic is a logic for automated classification of ontologies and for detecting inconsistent classification data owl is a language used to represent ontologies with description logic prot g is a ontology editor that can read in owl ontologies and then check consistency with deductive classifiers such as such as hermit 91 91 93 first order logic is more general than description logic the automated theorem provers discussed below can prove theorems in first order logic horn clause logic is more restricted than first order logic and is used in logic programming languages such as prolog extensions to first order logic include temporal logic to handle time epistemic logic to reason about agent knowledge modal logic to handle possibility and necessity and probabilistic logics to handle logic and probability together automatic theorem proving edit main article automated theorem proving examples of automated theorem provers for first order logic are prover9 acl2 vampire prover9 can be used in conjunction with the mace4 model checker acl2 is a theorem prover that can handle proofs by induction and is a descendant of the boyer moore theorem prover also known as nqthm reasoning in knowledge based systems edit main article reasoning system knowledge based systems have an explicit knowledge base typically of rules to enhance reusability across domains by separating procedural code and domain knowledge a separate inference engine processes rules and adds deletes or modifies a knowledge store forward chaining inference engines are the most common and are seen in clips and ops5 backward chaining occurs in prolog where a more limited logical representation is used horn clauses pattern matching specifically unification is used in prolog a more flexible kind of problem solving occurs when reasoning about what to do next occurs rather than simply choosing one of the available actions this kind of meta level reasoning is used in soar and in the bb1 blackboard architecture cognitive architectures such as act r may have additional capabilities such as the ability to compile frequently used knowledge into higher level chunks commonsense reasoning edit main article commonsense reasoning marvin minsky first proposed frames as a way of interpreting common visual situations such as an office and roger schank extended this idea to scripts for common routines such as dining out cyc has attempted to capture useful common sense knowledge and has micro theories to handle particular kinds of domain specific reasoning qualitative simulation such as benjamin kuipers s qsim 91 92 93 approximates human reasoning about naive physics such as what happens when we heat a liquid in a pot on the stove we expect it to heat and possibly boil over even though we may not know its temperature its boiling point or other details such as atmospheric pressure similarly allen s temporal interval algebra is a simplification of reasoning about time and region connection calculus is a simplification of reasoning about spatial relationships both can be solved with constraint solvers constraints and constraint based reasoning edit main articles constraint programming and spatial temporal reasoning constraint solvers perform a more limited kind of inference than first order logic they can simplify sets of spatiotemporal constraints such as those for rcc or temporal algebra along with solving other kinds of puzzle problems such as wordle sudoku cryptarithmetic problems and so on constraint logic programming can be used to solve scheduling problems for example with constraint handling rules chr automated planning edit main article automated planning and scheduling the general problem solver gps cast planning as problem solving used means ends analysis to create plans strips took a different approach viewing planning as theorem proving graphplan takes a least commitment approach to planning rather than sequentially choosing actions from an initial state working forwards or a goal state if working backwards satplan is an approach to planning where a planning problem is reduced to a boolean satisfiability problem natural language processing edit main article natural language processing natural language processing focuses on treating language as data to perform tasks such as identifying topics without necessarily understanding the intended meaning natural language understanding in contrast constructs a meaning representation and uses that for further processing such as answering questions parsing tokenizing spelling correction part of speech tagging noun and verb phrase chunking are all aspects of natural language processing long handled by symbolic ai but since improved by deep learning approaches in symbolic ai discourse representation theory and first order logic have been used to represent sentence meanings latent semantic analysis lsa and explicit semantic analysis also provided vector representations of documents in the latter case vector components are interpretable as concepts named by wikipedia articles new deep learning approaches based on transformer models have now eclipsed these earlier symbolic ai approaches and attained state of the art performance in natural language processing however transformer models are opaque and do not yet produce human interpretable semantic representations for sentences and documents instead they produce task specific vectors where the meaning of the vector components is opaque agents and multi agent systems edit main articles agent architecture and multi agent system agents are autonomous systems embedded in an environment they perceive and act upon in some sense russell and norvig s standard textbook on artificial intelligence is organized to reflect agent architectures of increasing sophistication 91 93 93 the sophistication of agents varies from simple reactive agents to those with a model of the world and automated planning capabilities possibly a bdi agent i e one with beliefs desires and intentions or alternatively a reinforcement learning model learned over time to choose actions up to a combination of alternative architectures such as a neuro symbolic architecture that includes deep learning for perception in contrast a multi agent system consists of multiple agents that communicate amongst themselves with some inter agent communication language such as knowledge query and manipulation language kqml the agents need not all have the same internal architecture advantages of multi agent systems include the ability to divide work among the agents and to increase fault tolerance when agents are lost research problems include how agents reach consensus distributed problem solving multi agent learning multi agent planning and distributed constraint optimization controversies edit controversies arose from early on in symbolic ai both within the field e g between logicists the pro logic neats and non logicists the anti logic scruffies and between those who embraced ai but rejected symbolic approaches primarily connectionists and those outside the field critiques from outside of the field were primarily from philosophers on intellectual grounds but also from funding agencies especially during the two ai winters connectionist ai philosophical challenges and sociological conflicts edit connectionist approaches include earlier work on neural networks 91 94 93 such as perceptrons work in the mid to late 80s such as danny hillis s connection machine and yann le cun s advances in convolutional neural networks to today s more advanced approaches such as transformers gans and other work in deep learning three philosophical positions 91 95 93 have been outlined among connectionists implementationism where connectionist architectures implement the capabilities for symbolic processing radical connectionism where symbolic processing is rejected totally and connectionist architectures underly intelligence and are fully sufficient to explain it moderate connectionism where symbolic processing and connectionist architectures are viewed as complementary and both are required for intelligence olazaran in his sociological history of the controversies within the neural network community described the moderate connectionism view as essentially compatible with current research in neuro symbolic hybrids the third and last position i would like to examine here is what i call the moderate connectionist view a more eclectic view of the current debate between connectionism and symbolic ai one of the researchers who has elaborated this position most explicitly is andy clark a philosopher from the school of cognitive and computing sciences of the university of sussex brighton england clark defended hybrid partly symbolic partly connectionist systems he claimed that at least two kinds of theories are needed in order to study and model cognition on the one hand for some information processing tasks such as pattern recognition connectionism has advantages over symbolic models but on the other hand for other cognitive processes such as serial deductive reasoning and generative symbol manipulation processes the symbolic paradigm offers adequate models and not only approximations contrary to what radical connectionists would claim 91 96 93 gary marcus has claimed that the animus in the deep learning community against symbolic approaches now may be more sociological than philosophical to think that we can simply abandon symbol manipulation is to suspend disbelief and yet for the most part that s how most current ai proceeds hinton and many others have tried hard to banish symbols altogether the deep learning hope seemingly grounded not so much in science but in a sort of historical grudge is that intelligent behavior will emerge purely from the confluence of massive data and deep learning where classical computers and software solve tasks by defining sets of symbol manipulating rules dedicated to particular jobs such as editing a line in a word processor or performing a calculation in a spreadsheet neural networks typically try to solve tasks by statistical approximation and learning from examples according to marcus geoffrey hinton and his colleagues have been vehemently anti symbolic when deep learning reemerged in 2012 it was with a kind of take no prisoners attitude that has characterized most of the last decade by 2015 his hostility toward all things symbols had fully crystallized he gave a talk at an ai workshop at stanford comparing symbols to aether one of science s greatest mistakes since then his anti symbolic campaign has only increased in intensity in 2016 yann lecun bengio and hinton wrote a manifesto for deep learning in one of science s most important journals nature it closed with a direct attack on symbol manipulation calling not for reconciliation but for outright replacement later hinton told a gathering of european union leaders that investing any further money in symbol manipulating approaches was a huge mistake likening it to investing in internal combustion engines in the era of electric cars 91 97 93 part of these disputes may be due to unclear terminology turing award winner judea pearl offers a critique of machine learning which unfortunately conflates the terms machine learning and deep learning similarly when geoffrey hinton refers to symbolic ai the connotation of the term tends to be that of expert systems dispossessed of any ability to learn the use of the terminology is in need of clarification machine learning is not confined to association rule mining c f the body of work on symbolic ml and relational learning the differences to deep learning being the choice of representation localist logical rather than distributed and the non use of gradient based learning algorithms equally symbolic ai is not just about production rules written by hand a proper definition of ai concerns knowledge representation and reasoning autonomous multi agent systems planning and argumentation as well as learning 91 98 93 philosophical critiques from dreyfus and other philosophers edit main article philosophy of artificial intelligence now we turn to attacks from outside the field specifically by philosophers one argument frequently cited by philosophers was made earlier by the computer scientist alan turing in his 1950 paper computing machinery and intelligence when he said that human behavior is far too complex to be captured by any formal set of rules humans must be using some informal guidelines that could never be captured in a formal set of rules and thus could never be codified in a computer program 91 99 93 turing called this the argument from informality of behaviour 91 100 93 similar critiques were provided by hubert dreyfus in his books what computers can t do and what computers still can t do dreyfus predicted ai would only be suitable for toy problems and thought that building more complex systems or scaling up the idea towards useful software would not be possible 91 101 93 john haugeland another philosopher similarly argued against rule based symbolic ai in his book artificial intelligence the very idea calling it gofai good old fashioned artificial intelligence russell and norvig explain that these arguments were targeted to the symbolic ai of the 1980s the technology they criticized came to be called good old fashioned ai gofai gofai corresponds to the simplest logical agent design described and we saw that it is indeed difficult to capture every contingency of appropriate behavior in a set of necessary and sufficient logical rules we called that the qualification problem 91 102 93 since then probabilistic reasoning systems have extended the capability of symbolic ai so they can be much more appropriate for open ended domains 91 102 93 however dreyfus raised another argument that cannot be addressed by disembodied symbolic ai systems one of dreyfus s strongest arguments is for situated agents rather than disembodied logical inference engines an agent whose understanding of dog comes only from a limited set of logical sentences such as dog x mammal x is at a disadvantage compared to an agent that has watched dogs run has played fetch with them and has been licked by one as philosopher andy clark 1998 says biological brains are first and foremost the control systems for biological bodies biological bodies move and act in rich real world surroundings according to clark we are good at frisbee bad at logic the embodied cognition approach claims that it makes no sense to consider the brain separately cognition takes place within a body which is embedded in an environment we need to study the system as a whole the brain s functioning exploits regularities in its environment including the rest of its body under the embodied cognition approach robotics vision and other sensors become central not peripheral 91 102 93 situated robotics the world as a model edit rodney brooks created behavior based robotics also named nouvelle ai as an alternative to both symbolic ai and connectionist ai his approach rejected representations either symbolic or distributed as not only unnecessary but as detrimental instead he created the subsumption architecture a layered architecture for embodied agents each layer achieves a different purpose and must function in the real world for example the first robot he describes in intelligence without representation has three layers the bottom layer interprets sonar sensors to avoid objects the middle layer causes the robot to wander around when there are no obstacles the top layer causes the robot to go to more distant places for further exploration each layer can temporarily inhibit or suppress a lower level layer he criticized ai researchers for defining ai problems for their systems when there is no clean division between perception abstraction and reasoning in the real world 91 103 93 he called his robots creatures and each layer was composed of a fixed topology network of simple finite state machines 91 104 93 in the nouvelle ai approach first it is vitally important to test the creatures we build in the real world i e in the same world that we humans inhabit it is disastrous to fall into the temptation of testing them in a simplified world first even with the best intentions of later transferring activity to an unsimplified world 91 105 93 his emphasis on real world testing was in contrast to early work in ai concentrated on games geometrical problems symbolic algebra theorem proving and other formal systems 91 106 93 and the use of the blocks world in symbolic ai systems such as shrdlu current views edit each approach symbolic connectionist and behavior based has advantages but has been criticized by the other approaches symbolic ai has been criticized as disembodied liable to the qualification problem and poor in handling the perceptual problems where deep learning excels in turn connectionist ai has been criticized as poorly suited for deliberative step by step problem solving incorporating knowledge and handling planning finally nouvelle ai excels in reactive and real world robotics domains but has been criticized for difficulties in incorporating learning and knowledge hybrid ais incorporating one or more of these approaches are currently viewed as the path forward 91 21 93 91 84 93 91 85 93 russell and norvig conclude that overall dreyfus saw areas where ai did not have complete answers and said that al is therefore impossible we now see many of these same areas undergoing continued research and development leading to increased capability not impossibility 91 102 93 see also edit artificial intelligence automated planning and scheduling automated theorem proving belief revision case based reasoning cognitive architecture cognitive science connectionism constraint programming deep learning first order logic history of artificial intelligence inductive logic programming knowledge based systems knowledge representation and reasoning logic programming machine learning model checking model based reasoning multi agent system neuro symbolic ai ontology philosophy of artificial intelligence physical symbol systems hypothesis semantic web sequential pattern mining statistical relational learning symbolic mathematics yago ontology wordnet notes edit mccarthy once said this is ai so we don t care if it s psychologically real 91 2 93 mccarthy reiterated his position in 2006 at the ai 50 conference where he said artificial intelligence is not by definition simulation of human intelligence 91 29 93 pamela mccorduck writes that there are two major branches of artificial intelligence one aimed at producing intelligent behavior regardless of how it was accomplished and the other aimed at modeling intelligent processes found in nature particularly human ones 91 30 93 stuart russell and peter norvig wrote aeronautical engineering texts do not define the goal of their field as making machines that fly so exactly like pigeons that they can fool even other pigeons 91 31 93 citations edit garnelo marta shanahan murray 2019 10 01 reconciling deep learning with symbolic artificial intelligence representing objects and relations current opinion in behavioral sciences 29 17 23 doi 10 1016 j cobeha 2018 12 010 s2cid 160 72336067 a b kolata 1982 russell amp norvig 2003 p 160 5 russell amp norvig 2021 p 160 24 kautz 2020 pp 160 107 109 russell amp norvig 2021 p 160 19 russell amp norvig 2021 pp 160 22 23 a b kautz 2020 pp 160 109 110 kautz 2020 p 160 110 a b kautz 2020 pp 160 110 111 a b russell amp norvig 2021 p 160 25 kautz 2020 p 160 111 rumelhart david e hinton geoffrey e williams ronald j 1986 learning representations by back propagating errors nature 323 6088 533 536 bibcode 1986natur 323 533r doi 10 1038 323533a0 issn 160 1476 4687 s2cid 160 205001834 lecun y boser b denker i henderson d howard r hubbard w tackel l 1989 backpropagation applied to handwritten zip code recognition neural computation 1 4 541 551 doi 10 1162 neco 1989 1 4 541 s2cid 160 41312633 a b marcus amp davis 2019 a b rossi francesca thinking fast and slow in ai aaai retrieved 5 july 2022 a b selman bart aaai presidential address the state of ai aaai retrieved 5 july 2022 newell amp simon 1976 p 160 116 shustek len june 2010 an interview with ed feigenbaum communications of the acm 53 6 41 45 doi 10 1145 1743546 1743564 issn 160 0001 0782 s2cid 160 10239007 retrieved 2022 07 14 lenat douglas b feigenbaum edward a 1988 on the thresholds of knowledge proceedings of the international workshop on artificial intelligence for industrial applications 291 300 doi 10 1109 aiia 1988 13308 s2cid 160 11778085 a b c kautz 2020 kautz 2020 p 160 106 newell amp simon 1972 amp mccorduck 2004 pp 160 139 179 245 250 322 323 epam crevier 1993 pp 160 145 149 mccorduck 2004 pp 160 450 451 crevier 1993 pp 160 258 263 a b kautz 2022 p 160 108 maker 2006 mccorduck 2004 pp 160 100 101 russell amp norvig 2003 pp 160 2 3 mccorduck 2004 pp 160 251 259 crevier 1993 pp 160 193 196 howe 1994 mccorduck 2004 pp 160 259 305 crevier 1993 pp 160 83 102 163 176 russell amp norvig 2003 p 160 19 mccorduck 2004 pp 160 421 424 486 489 crevier 1993 p 160 168 mccorduck 2004 p 160 489 crevier 1993 pp 160 239 243 russell amp norvig 2003 p 160 363 365 kautz 2022 p 160 109 russell amp norvig 2021 p 160 22 mccorduck 2004 pp 160 266 276 298 300 314 421 russell amp norvig 2003 pp 160 22 23 russell amp norvig 2003 pp 160 22 24 mccorduck 2004 pp 160 327 335 434 435 crevier 1993 pp 160 145 62 197 203 norvig 2022 p 160 23 sfn error no target citerefnorvig2022 help a b clancey 1987 a b kautz 2022 p 160 110 a b shustek len 2010 an interview with ed feigenbaum communications of the acm 53 6 41 45 doi 10 1145 1743546 1743564 issn 160 0001 0782 s2cid 160 10239007 retrieved 2022 08 05 russell amp norvig 2021 p 160 23 the fascination with ai what is artificial intelligence ionos digitalguide retrieved 2021 12 02 hayes roth murray amp adelman hayes roth barbara 1985 a blackboard architecture for control artificial intelligence 26 3 251 321 doi 10 1016 0004 3702 85 90063 3 hayes roth barbara 1980 human planning processes rand pearl 1988 spiegelhalter et al 1993 russell amp norvig 2021 pp 160 335 337 russell amp norvig 2021 p 160 459 quinlan j ross chapter 15 learning efficient classification procedures and their application to chess end games in michalski carbonell amp mitchell 1983 quinlan j ross 1992 10 15 c4 5 programs for machine learning 1st 160 ed san mateo calif morgan kaufmann isbn 160 978 1 55860 238 0 mitchell tom m utgoff paul e banerji ranan chapter 6 learning by experimentation acquiring and refining problem solving heuristics in michalski carbonell amp mitchell 1983 valiant l g 1984 11 05 a theory of the learnable communications of the acm 27 11 1134 1142 doi 10 1145 1968 1972 issn 160 0001 0782 s2cid 160 12837541 retrieved 2022 08 19 koedinger k r anderson j r hadley w h mark m a others 1997 intelligent tutoring goes to school in the big city international journal of artificial intelligence in education ijaied 8 30 43 retrieved 2012 08 18 shapiro ehud y 1981 the model inference system proceedings of the 7th international joint conference on artificial intelligence ijcai vol 160 2 p 160 1064 manna zohar waldinger richard 1980 01 01 a deductive approach to program synthesis acm trans program lang syst 2 90 121 doi 10 1145 357084 357090 s2cid 160 14770735 schank roger c 1983 01 28 dynamic memory a theory of reminding and learning in computers and people cambridge cambridgeshire 160 new york cambridge university press isbn 160 978 0 521 27029 8 hammond kristian j 1989 04 11 case based planning viewing planning as a memory task boston academic press isbn 160 978 0 12 322060 8 koza john r 1992 12 11 genetic programming on the programming of computers by means of natural selection 1st 160 ed cambridge mass a bradford book isbn 160 978 0 262 11170 6 mostow david jack chapter 12 machine transformation of advice into a heuristic search procedure in michalski carbonell amp mitchell 1983 bareiss ray porter bruce wier craig chapter 4 protos an exemplar based learning apprentice in michalski carbonell amp mitchell 1986 pp 160 112 139 carbonell jaime chapter 5 learning by analogy formulating and generalizing plans from past experience in michalski carbonell amp mitchell 1983 pp 160 137 162 carbonell jaime chapter 14 derivational analogy a theory of reconstructive problem solving and expertise acquisition in michalski carbonell amp mitchell 1986 pp 160 371 392 mitchell tom mabadevan sridbar steinberg louis chapter 10 leap a learning apprentice for vlsi design in kodratoff amp michalski 1990 pp 160 271 289 lenat douglas chapter 9 the role of heuristics in learning by discovery three case studies in michalski carbonell amp mitchell 1983 pp 160 243 306 korf richard e 1985 learning to solve problems by searching for macro operators research notes in artificial intelligence pitman publishing isbn 160 0 273 08690 1 valiant 2008 a b garcez et al 2015 marcus 2020 p 160 44 marcus 2020 p 160 17 a b rossi 2022 a b selman 2022 garcez amp lamb 2020 p 160 2 garcez et al 2002 rockt schel tim riedel sebastian 2016 learning knowledge base inference with neural theorem provers proceedings of the 5th workshop on automated knowledge base construction san diego ca association for computational linguistics pp 160 45 50 doi 10 18653 v1 w16 1309 retrieved 2022 08 06 serafini luciano garcez artur d avila 2016 logic tensor networks deep learning and logical reasoning from data and knowledge arxiv 1606 04422 retrieved 2022 08 02 kiczales gregor rivieres jim des bobrow daniel g 1991 07 30 the art of the metaobject protocol 1st 160 ed cambridge mass the mit press isbn 160 978 0 262 61074 2 motik boris shearer rob horrocks ian 2009 10 28 hypertableau reasoning for description logics journal of artificial intelligence research 36 165 228 arxiv 1401 3485 doi 10 1613 jair 2811 issn 160 1076 9757 s2cid 160 190609 retrieved 2022 09 04 kuipers benjamin 1994 qualitative reasoning modeling and simulation with incomplete knowledge mit press isbn 160 978 0 262 51540 5 russell amp norvig 2021 nilsson 1998 p 160 7 olazaran 1993 pp 160 411 416 sfn error no target citerefolazaran1993 help olazaran 1993 pp 160 415 416 sfn error no target citerefolazaran1993 help marcus 2022 sfn error no target citerefmarcus2022 help garcez amp lamb 2020 p 160 8 russell amp norvig 2021 p 160 981 turing 1950 p 160 452 sfn error no target citerefturing1950 help dreyfus 1981 pp 160 161 204 a b c d russell amp norvig 2021 p 160 982 brooks 1991 p 160 143 brooks 1991 p 160 151 brooks 1991 p 160 150 brooks 1991 p 160 142 references edit brooks rodney a 1991 intelligence without representation artificial intelligence 47 1 139 159 doi 10 1016 0004 3702 91 90053 m issn 160 0004 3702 retrieved 2022 09 13 clancey william 1987 knowledge based tutoring the guidon program mit press series in artificial intelligence hardcover 160 ed crevier daniel 1993 ai the tumultuous search for artificial intelligence new york ny basicbooks isbn 160 0 465 02997 3 dreyfus hubert l 1981 from micro worlds to knowledge representation ai at an impasse pdf mind design mit press cambridge ma 161 204 garcez artur s d avila broda krysia gabbay dov m gabbay augustus de morgan professor of logic dov m 2002 neural symbolic learning systems foundations and applications springer science amp business media isbn 160 978 1 85233 512 0 garcez artur besold tarek de raedt luc f ldi k peter hitzler pascal icard thomas k hnberger kai uwe lamb lu s miikkulainen risto silver daniel 2015 neural symbolic learning and reasoning contributions and challenges aai spring symposium knowledge representation and reasoning integrating symbolic and neural approaches stanford ca aaai press doi 10 13140 2 1 1779 4243 garcez artur d avila gori marco lamb luis c serafini luciano spranger michael tran son n 2019 neural symbolic computing an effective methodology for principled integration of machine learning and reasoning arxiv 1905 06088 retrieved 2022 07 12 garcez artur d avila lamb luis c 2020 neurosymbolic ai the 3rd wave arxiv 2012 05876 retrieved 2022 07 14 haugeland john 1985 artificial intelligence the very idea cambridge mass mit press isbn 160 0 262 08153 9 hayes roth frederick murray william adelman leonard expert systems accessscience doi 10 1036 1097 8542 248550 honavar vasant uhr leonard 1994 symbolic artificial intelligence connectionist networks amp beyond technical report iowa state university digital repository computer science technical reports 76 p 160 6 honavar vasant 1995 symbolic artificial intelligence and numeric artificial neural networks towards a resolution of the dichotomy the springer international series in engineering and computer science springer us pp 160 351 388 doi 10 1007 978 0 585 29599 2 11 howe j november 1994 artificial intelligence at edinburgh university a perspective archived from the original on 15 may 2007 retrieved 30 august 2007 kautz henry 2020 02 11 the third ai summer henry kautz aaai 2020 robert s engelmore memorial award lecture retrieved 2022 07 06 kautz henry 2022 the third ai summer aaai robert s engelmore memorial lecture ai magazine 43 1 93 104 doi 10 1609 aimag v43i1 19122 issn 160 2371 9621 s2cid 160 248213051 retrieved 2022 07 12 kodratoff yves michalski ryszard eds 1990 machine learning 160 an artificial intelligence approach vol 160 iii san mateo calif morgan kaufman isbn 160 0 934613 09 5 oclc 160 893488404 kolata g 1982 how can computers get common sense science 217 4566 1237 1238 bibcode 1982sci 217 1237k doi 10 1126 science 217 4566 1237 pmid 160 17837639 maker meg houston 2006 ai 50 ai past present future dartmouth college archived from the original on 3 january 2007 retrieved 16 october 2008 marcus gary davis ernest 2019 rebooting ai building artificial intelligence we can trust new york pantheon books isbn 160 9781524748258 oclc 160 1083223029 marcus gary 2020 the next decade in ai four steps towards robust artificial intelligence arxiv 2002 06177 retrieved 2022 07 12 mccorduck pamela 2004 machines who think 2nd 160 ed natick ma a k peters ltd isbn 160 1 56881 205 1 michalski ryszard carbonell jaime mitchell tom eds 1983 machine learning 160 an artificial intelligence approach vol 160 i palo alto calif tioga publishing company isbn 160 0 935382 05 4 oclc 160 9262069 michalski ryszard carbonell jaime mitchell tom eds 1986 machine learning 160 an artificial intelligence approach vol 160 ii los altos calif morgan kaufman isbn 160 0 934613 00 1 newell allen simon herbert a 1972 human problem solving 1st 160 ed englewood cliffs new jersey prentice hall isbn 160 0 13 445403 0 newell allen simon h a 1976 computer science as empirical inquiry symbols and search communications of the acm 19 3 113 126 doi 10 1145 360018 360022 nilsson nils 1998 artificial intelligence a new synthesis morgan kaufmann isbn 160 978 1 55860 467 4 archived from the original on 26 july 2020 retrieved 18 november 2019 pearl j 1988 probabilistic reasoning in intelligent systems networks of plausible inference san mateo california morgan kaufmann isbn 160 978 1 55860 479 7 oclc 160 249625842 russell stuart j norvig peter 2003 artificial intelligence a modern approach 2nd 160 ed upper saddle river new jersey prentice hall isbn 160 0 13 790395 2 russell stuart j norvig peter 2021 artificial intelligence a modern approach 4th 160 ed hoboken pearson isbn 160 978 0 13 461099 3 lccn 160 20190474 rossi francesca 2022 07 06 aaai2022 thinking fast and slow in ai aaai 2022 invited talk retrieved 2022 07 06 selman bart 2022 07 06 aaai2022 presidential address the state of ai retrieved 2022 07 06 serafini luciano garcez artur d avila 2016 07 07 logic tensor networks deep learning and logical reasoning from data and knowledge arxiv 1606 04422 retrieved 2022 08 02 spiegelhalter david j dawid a philip lauritzen steffen cowell robert g 1993 bayesian analysis in expert systems statistical science 8 3 turing a m 1950 i computing machinery and intelligence mind lix 236 433 460 doi 10 1093 mind lix 236 433 issn 160 0026 4423 retrieved 2022 09 14 valiant leslie g 2008 knowledge infusion in pursuit of robustness in artificial intelligence in hariharan r mukund m vinay v eds foundations of software technology and theoretical computer science bangalore pp 160 415 422 xifan yao jiajun zhou jiangming zhang claudio r boer 2017 from intelligent manufacturing to smart manufacturing for industry 4 0 driven by next generation artificial intelligence and further on 2017 5th international conference on enterprise systems es ieee doi 10 1109 es 2017 58 retrieved from https en wikipedia org w index php title symbolic artificial intelligence amp oldid 1128884677 categories artificial intelligencehidden categories harv and sfn no target errorsarticles with short descriptionshort description is different from wikidata 