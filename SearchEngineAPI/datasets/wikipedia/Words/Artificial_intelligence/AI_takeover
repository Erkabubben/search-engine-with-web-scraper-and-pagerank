ai takeover from wikipedia the free encyclopedia jump to navigation jump to search hypothetical artificial intelligence scenario robots revolt in r u r a 1920 play part of a series onartificial intelligence major goals artificial general intelligence planning computer vision general game playing knowledge reasoning machine learning natural language processing robotics approaches symbolic deep learning bayesian networks evolutionary algorithms philosophy chinese room friendly ai control problem takeover ethics existential risk turing test history timeline progress ai winter technology applications projects programming languages glossary glossary vte an ai takeover is a hypothetical scenario in which an artificial intelligence ai becomes the dominant form of intelligence on earth as computer programs or robots effectively take the control of the planet away from the human species possible scenarios include replacement of the entire human workforce takeover by a superintelligent ai and the popular notion of a robot uprising some public figures such as stephen hawking and elon musk have advocated research into precautionary measures to ensure future superintelligent machines remain under human control 91 1 93 contents 1 types 1 1 automation of the economy 1 1 1 technologies that may displace workers 1 1 2 computer integrated manufacturing 1 1 3 white collar machines 1 1 4 autonomous cars 1 2 eradication 2 in fiction 3 contributing factors 3 1 advantages of superhuman intelligence over humans 3 1 1 sources of ai advantage 3 2 possibility of unfriendly ai preceding friendly ai 3 2 1 is strong ai inherently dangerous 3 2 2 odds of conflict 3 2 3 precautions 4 warnings 5 prevention through ai alignment 6 see also 7 notes 8 references 9 external links types edit automation of the economy edit main article technological unemployment the traditional consensus among economists has been that technological progress does not cause long term unemployment however recent innovation in the fields of robotics and artificial intelligence has raised worries that human labor will become obsolete leaving people in various sectors without jobs to earn a living leading to an economic crisis 91 2 93 91 3 93 91 4 93 91 5 93 many small and medium size businesses may also be driven out of business if they will not be able to afford or licence the latest robotic and ai technology and may need to focus on areas or services that cannot easily be replaced for continued viability in the face of such technology 91 6 93 technologies that may displace workers edit ai technologies have been widely adopted in recent years and this trend will only continue to gain popularity given the digital transformation efforts from companies across the world while these technologies have replaced many traditional workers they also create new opportunities industries that are most susceptible to experience ai takeover include transportation retail and military ai military technologies for example allow soldiers to work remotely without any risk of injury author dave bond argues that as ai technologies continue to develop and expand the relationship between humans and robots will change they will become closely integrated in several aspects of life overall it is safe to assume that ai will displace some workers while creating opportunities for new jobs in other sectors especially in fields where tasks are repeatable 91 7 93 91 8 93 computer integrated manufacturing edit see also artificial intelligence in industry computer integrated manufacturing is the manufacturing approach of using computers to control the entire production process this integration allows individual processes to exchange information with each other and initiate actions although manufacturing can be faster and less error prone by the integration of computers the main advantage is the ability to create automated manufacturing processes computer integrated manufacturing is used in automotive aviation space and ship building industries white collar machines edit see also white collar worker the 21st century has seen a variety of skilled tasks partially taken over by machines including translation legal research and even low level journalism care work entertainment and other tasks requiring empathy previously thought safe from automation have also begun to be performed by robots 91 9 93 91 10 93 91 11 93 91 12 93 autonomous cars edit an autonomous car is a vehicle that is capable of sensing its environment and navigating without human input many such vehicles are being developed but as of may 2017 automated cars permitted on public roads are not yet fully autonomous they all require a human driver at the wheel who is ready at a moment s notice to take control of the vehicle among the main obstacles to widespread adoption of autonomous vehicles are concerns about the resulting loss of driving related jobs in the road transport industry on march 18 2018 the first human was killed by an autonomous vehicle in tempe arizona by an uber self driving car 91 13 93 eradication edit main article existential risk from artificial general intelligence scientists such as stephen hawking are confident that superhuman artificial intelligence is physically possible stating there is no physical law precluding particles from being organised in ways that perform even more advanced computations than the arrangements of particles in human brains 91 14 93 91 15 93 scholars like nick bostrom debate how far off superhuman intelligence is and whether it would actually pose a risk to mankind according to bostrom a superintelligent machine would not necessarily be motivated by the same emotional desire to collect power that often drives human beings but might rather treat power as a means toward attaining its ultimate goals taking over the world would both increase its access to resources and help to prevent other agents from stopping the machine s plans as an oversimplified example a paperclip maximizer designed solely to create as many paperclips as possible would want to take over the world so that it can use all of the world s resources to create as many paperclips as possible and additionally prevent humans from shutting it down or using those resources on things other than paperclips 91 16 93 in fiction edit main article ai takeovers in popular culture see also artificial intelligence in fiction and self replicating machines in fiction ai takeover is a common theme in science fiction fictional scenarios typically differ vastly from those hypothesized by researchers in that they involve an active conflict between humans and an ai or robots with anthropomorphic motives who see them as a threat or otherwise have active desire to fight humans as opposed to the researchers concern of an ai that rapidly exterminates humans as a byproduct of pursuing arbitrary goals 91 17 93 the idea is seen in karel apek s r u r which introduced the word robot to the global lexicon in 1921 91 18 93 and can even be glimpsed in mary shelley s frankenstein published in 1818 as victor ponders whether if he grants his monster s request and makes him a wife they would reproduce and their kind would destroy humanity 91 19 93 the word robot from r u r comes from the czech word robota meaning laborer or serf the 1920 play was a protest against the rapid growth of technology featuring manufactured robots with increasing capabilities who eventually revolt 91 20 93 hal 9000 1968 and the original terminator 1984 are two iconic examples of hostile ai in pop culture 91 21 93 contributing factors edit advantages of superhuman intelligence over humans edit nick bostrom and others have expressed concern that an ai with the abilities of a competent artificial intelligence researcher would be able to modify its own source code and increase its own intelligence if its self reprogramming leads to its getting even better at being able to reprogram itself the result could be a recursive intelligence explosion where it would rapidly leave human intelligence far behind bostrom defines a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest and enumerates some advantages a superintelligence would have if it chose to compete against humans 91 17 93 91 22 93 technology research a machine with superhuman scientific research abilities would be able to beat the human research community to milestones such as nanotechnology or advanced biotechnology strategizing a superintelligence might be able to simply outwit human opposition social manipulation a superintelligence might be able to recruit human support 91 17 93 or covertly incite a war between humans 91 23 93 economic productivity as long as a copy of the ai could produce more economic wealth than the cost of its hardware individual humans would have an incentive to voluntarily allow the artificial general intelligence agi to run a copy of itself on their systems hacking a superintelligence could find new exploits in computers connected to the internet and spread copies of itself onto those systems or might steal money to finance its plans sources of ai advantage edit according to bostrom a computer program that faithfully emulates a human brain or that otherwise runs algorithms that are equally powerful as the human brain s algorithms could still become a speed superintelligence if it can think many orders of magnitude faster than a human due to being made of silicon rather than flesh or due to optimization focusing on increasing the speed of the agi biological neurons operate at about 200 160 hz whereas a modern microprocessor operates at a speed of about 2 000 000 000 160 hz human axons carry action potentials at around 120 160 m s whereas computer signals travel near the speed of light 91 17 93 a network of human level intelligences designed to network together and share complex thoughts and memories seamlessly able to collectively work as a giant unified team without friction or consisting of trillions of human level intelligences would become a collective superintelligence 91 17 93 more broadly any number of qualitative improvements to a human level agi could result in a quality superintelligence perhaps resulting in an agi as far above us in intelligence as humans are above non human apes the number of neurons in a human brain is limited by cranial volume and metabolic constraints while the number of processors in a supercomputer can be indefinitely expanded an agi need not be limited by human constraints on working memory and might therefore be able to intuitively grasp more complex relationships than humans can an agi with specialized cognitive support for engineering or computer programming would have an advantage in these fields compared with humans who evolved no specialized mental modules to specifically deal with those domains unlike humans an agi can spawn copies of itself and tinker with its copies source code to attempt to further improve its algorithms 91 17 93 possibility of unfriendly ai preceding friendly ai edit is strong ai inherently dangerous edit main article ai control problem a significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly ai while both require large advances in recursive optimisation process design friendly ai also requires the ability to make goal structures invariant under self improvement or the ai could transform itself into something unfriendly and a goal structure that aligns with human values and does not undergo instrumental convergence in ways that may automatically destroy the entire human race an unfriendly ai on the other hand can optimize for an arbitrary goal structure which does not need to be invariant under self modification 91 24 93 the sheer complexity of human value systems makes it very difficult to make ai s motivations human friendly 91 17 93 91 25 93 unless moral philosophy provides us with a flawless ethical theory an ai s utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not common sense according to eliezer yudkowsky there is little reason to suppose that an artificially designed mind would have such an adaptation 91 26 93 odds of conflict edit many scholars including evolutionary psychologist steven pinker argue that a superintelligent machine is likely to coexist peacefully with humans 91 27 93 the fear of cybernetic revolt is often based on interpretations of humanity s history which is rife with incidents of enslavement and genocide such fears stem from a belief that competitiveness and aggression are necessary in any intelligent being s goal system however such human competitiveness stems from the evolutionary background to our intelligence where the survival and reproduction of genes in the face of human and non human competitors was the central goal 91 28 93 according to ai researcher steve omohundro an arbitrary intelligence could have arbitrary goals there is no particular reason that an artificially intelligent machine not sharing humanity s evolutionary context would be hostile or friendly unless its creator programs it to be such and it is not inclined or capable of modifying its programming but the question remains what would happen if ai systems could interact and evolve evolution in this context means self modification or selection and reproduction and need to compete over resources would that create goals of self preservation ai s goal of self preservation could be in conflict with some goals of humans 91 29 93 many scholars dispute the likelihood of unanticipated cybernetic revolt as depicted in science fiction such as the matrix arguing that it is more likely that any artificial intelligence powerful enough to threaten humanity would probably be programmed not to attack it pinker acknowledges the possibility of deliberate bad actors but states that in the absence of bad actors unanticipated accidents are not a significant threat pinker argues that a culture of engineering safety will prevent ai researchers from accidentally unleashing malign superintelligence 91 27 93 in contrast yudkowsky argues that humanity is less likely to be threatened by deliberately aggressive ais than by ais which were programmed such that their goals are unintentionally incompatible with human survival or well being as in the film i robot and in the short story the evitable conflict omohundro suggests that present day automation systems are not designed for safety and that ais may blindly optimize narrow utility functions say playing chess at all costs leading them to seek self preservation and elimination of obstacles including humans who might turn them off 91 30 93 precautions edit main article ai control problem the ai control problem is the issue of how to build a superintelligent agent that will aid its creators while avoiding inadvertently building a superintelligence that will harm its creators 91 31 93 some scholars argue that solutions to the control problem might also find applications in existing non superintelligent ai 91 32 93 major approaches to the control problem include alignment which aims to align ai goal systems with human values and capability control which aims to reduce an ai system s capacity to harm humans or gain control an example of capability control is to research whether a superintelligence ai could be successfully confined in an ai box according to bostrom such capability control proposals are not reliable or sufficient to solve the control problem in the long term but may potentially act as valuable supplements to alignment efforts 91 17 93 warnings edit physicist stephen hawking microsoft founder bill gates and spacex founder elon musk have expressed concerns about the possibility that ai could develop to the point that humans could not control it with hawking theorizing that this could spell the end of the human race 91 33 93 stephen hawking said in 2014 that success in creating ai would be the biggest event in human history unfortunately it might also be the last unless we learn how to avoid the risks hawking believed that in the coming decades ai could offer incalculable benefits and risks such as technology outsmarting financial markets out inventing human researchers out manipulating human leaders and developing weapons we cannot even understand in january 2015 nick bostrom joined stephen hawking max tegmark elon musk lord martin rees jaan tallinn and numerous ai researchers in signing the future of life institute s open letter speaking to the potential risks and benefits associated with artificial intelligence the signatories believe that research on how to make ai systems robust and beneficial is both important and timely and that there are concrete research directions that can be pursued today 91 34 93 91 35 93 prevention through ai alignment edit this paragraph is an excerpt from ai alignment edit in the field of artificial intelligence ai ai alignment research aims to steer ai systems towards their designers intended goals and interests 91 a 93 an aligned ai system advances the intended objective a misaligned ai system is competent at advancing some objective but not the intended one 91 b 93 see also edit artificial philosophy artificial intelligence arms race autonomous robot industrial robot mobile robot self replicating machine cyberocracy effective altruism existential risk from artificial general intelligence future of humanity institute global catastrophic risk existential risk government by algorithm human extinction machine ethics machine learning deep learning outline of transhumanism self replication technophobia technological singularity intelligence explosion superintelligence superintelligence paths dangers strategies notes edit other definitions of ai alignment require that the ai system advances more general goals such as human values other ethical principles or the intentions its designers would have if they were more informed and enlightened 91 36 93 see the textbook russel amp norvig artificial intelligence a modern approach 91 37 93 the distinction between misaligned ai and incompetent ai has been formalized in certain contexts 91 38 93 references edit lewis tanya 2015 01 12 don t let artificial intelligence take over top scientists warn livescience purch retrieved october 20 2015 stephen hawking elon musk and dozens of other top scientists and technology leaders have signed a letter warning of the potential dangers of developing artificial intelligence ai lee kai fu 2017 06 24 the real threat of artificial intelligence the new york times retrieved 2017 08 15 these tools can outperform human beings at a given task this kind of a i is spreading to thousands of domains and as it does it will eliminate many jobs larson nina 2017 06 08 ai good for the world says ultra lifelike robot phys org retrieved 2017 08 15 among the feared consequences of the rise of the robots is the growing impact they will have on human jobs and economies santini jean louis 2016 02 14 intelligent robots threaten millions of jobs phys org retrieved 2017 08 15 we are approaching a time when machines will be able to outperform humans at almost any task said moshe vardi director of the institute for information technology at rice university in texas williams grut oscar 2016 02 15 robots will steal your job how ai could increase unemployment and inequality businessinsider com business insider retrieved 2017 08 15 top computer scientists in the us warned that the rise of artificial intelligence ai and robots in the workplace could cause mass unemployment and dislocated economies rather than simply unlocking productivity gains and freeing us all up to watch tv and play sports how can smes prepare for the rise of the robots leanstaff 2017 10 17 archived from the original on 2017 10 18 retrieved 2017 10 17 frank morgan 2019 03 25 toward understanding the impact of artificial intelligence on labor proceedings of the national academy of sciences of the united states of america 116 14 6531 6539 doi 10 1073 pnas 1900949116 pmc 160 6452673 pmid 160 30910965 bond dave 2017 artificial intelligence pp 160 67 69 skidelsky robert 2013 02 19 rise of the robots what will the future of work look like the guardian london retrieved 14 july 2015 bria francesca february 2016 the robot economy may already have arrived opendemocracy retrieved 20 may 2016 srnicek nick march 2016 4 reasons why technological unemployment might really be different this time novara wire archived from the original on 25 june 2016 retrieved 20 may 2016 brynjolfsson erik mcafee andrew 2014 passim see esp chpt 9 the second machine age work progress and prosperity in a time of brilliant technologies w w norton amp company isbn 160 978 0393239355 wakabayashi daisuke march 19 2018 self driving uber car kills pedestrian in arizona where robots roam new york times hawking stephen stuart russell max tegmark frank wilczek 1 may 2014 stephen hawking transcendence looks at the implications of artificial intelligence but are we taking ai seriously enough the independent archived from the original on 2015 10 02 retrieved 1 april 2016 m ller vincent c bostrom nick 2016 future progress in artificial intelligence a survey of expert opinion pdf fundamental issues of artificial intelligence springer pp 160 555 572 doi 10 1007 978 3 319 26485 1 33 isbn 160 978 3 319 26483 7 ai systems will reach overall human ability very likely with 90 probability by 2075 from reaching human ability it will move on to superintelligence within 30 years 75 so most of the ai experts responding to the surveys think that superintelligence is likely to come in a few decades bostrom nick 2012 the superintelligent will motivation and instrumental rationality in advanced artificial agents pdf minds and machines springer 22 2 71 85 doi 10 1007 s11023 012 9281 3 a b c d e f g h bostrom nick superintelligence paths dangers strategies the origin of the word robot science friday public radio 22 april 2011 retrieved 30 april 2020 botkin kowacki eva 28 october 2016 a female frankenstein would lead to humanity s extinction say scientists christian science monitor retrieved 30 april 2020 hockstein n g gourin c g faust r a terris d j 17 march 2007 a history of robots from science fiction to surgical robotics journal of robotic surgery 1 2 113 118 doi 10 1007 s11701 007 0021 2 pmc 160 4247417 pmid 160 25484946 hellmann melissa 21 september 2019 ai 101 what is artificial intelligence and where is it going the seattle times retrieved 30 april 2020 babcock james kr mar j nos yampolskiy roman v 2019 guidelines for artificial intelligence containment next generation ethics pp 160 90 112 arxiv 1707 08476 doi 10 1017 9781108616188 008 isbn 160 9781108616188 s2cid 160 22007028 baraniuk chris 23 may 2016 checklist of worst case scenarios could help prepare for evil ai new scientist retrieved 21 september 2016 yudkowsky eliezer s may 2004 coherent extrapolated volition singularity institute for artificial intelligence archived from the original on 2012 06 15 muehlhauser luke helm louie 2012 intelligence explosion and machine ethics pdf singularity hypotheses a scientific and philosophical assessment springer yudkowsky eliezer 2011 complex value systems in friendly ai artificial general intelligence lecture notes in computer science vol 160 6830 pp 160 388 393 doi 10 1007 978 3 642 22887 2 48 isbn 160 978 3 642 22886 5 issn 160 0302 9743 a b pinker steven 13 february 2018 we re told to fear robots but why do we think they ll turn on us popular science retrieved 8 june 2020 creating a new intelligent species choices and responsibilities for artificial intelligence designers archived february 6 2007 at the wayback machine singularity institute for artificial intelligence 2005 omohundro stephen m june 2008 the basic ai drives pdf artificial general intelligence 2008 pp 160 483 492 tucker patrick 17 apr 2014 why there will be a robot uprising defense one retrieved 15 july 2014 russell stuart j 8 october 2019 human compatible 160 artificial intelligence and the problem of control isbn 160 978 0 525 55862 0 oclc 160 1237420037 google developing kill switch for ai bbc news 8 june 2016 retrieved 7 june 2020 rawlinson kevin 29 january 2015 microsoft s bill gates insists ai is a threat bbc news retrieved 30 january 2015 the future of life institute open letter the future of life institute 28 october 2015 retrieved 29 march 2019 bradshaw tim 11 january 2015 scientists and investors warn on ai the financial times retrieved 4 march 2015 gabriel iason 2020 09 01 artificial intelligence values and alignment minds and machines 30 3 411 437 doi 10 1007 s11023 020 09539 2 issn 160 1572 8641 s2cid 160 210920551 retrieved 2022 07 23 russell stuart j norvig peter 2020 artificial intelligence a modern approach 4th 160 ed pearson pp 160 31 34 isbn 160 978 1 292 40113 3 oclc 160 1303900751 langosco lauro langosco di koch jack sharkey lee d pfau jacob krueger david 2022 07 17 goal misgeneralization in deep reinforcement learning international conference on machine learning vol 160 162 pmlr pp 160 12004 12019 external links edit automation not domination how robots will take over our world a positive outlook of robot and ai integration into society machine intelligence research institute official miri formerly singularity institute for artificial intelligence website lifeboat foundation aishield to protect against unfriendly ai ted talk can we build ai without losing control over it vteexistential risk from artificial intelligenceconcepts ai alignment ai capability control ai takeover accelerating change existential risk from artificial general intelligence friendly artificial intelligence instrumental convergence intelligence explosion machine ethics superintelligence technological singularity organizations allen institute for ai center for applied rationality center for human compatible artificial intelligence centre for the study of existential risk deepmind foundational questions institute future of humanity institute future of life institute humanity institute for ethics and emerging technologies leverhulme centre for the future of intelligence machine intelligence research institute openai people scott alexander nick bostrom eric drexler sam harris stephen hawking bill hibbard bill joy elon musk steve omohundro huw price martin rees stuart j russell jaan tallinn max tegmark frank wilczek roman yampolskiy andrew yang eliezer yudkowsky other artificial intelligence as a global catastrophic risk controversies and dangers of artificial general intelligence ethics of artificial intelligence suffering risks human compatible open letter on artificial intelligence our final invention the precipice superintelligence paths dangers strategies do you trust this computer category vteglobal catastrophic risks future of the earth future of an expanding universe ultimate fate of the universe technological chemical warfare cyberattack cyberwarfare cyberterrorism cybergeddon gray goo nanoweapons kinetic bombardment relativistic kinetic kill vehicle nuclear warfare mutual assured destruction dead hand doomsday clock doomsday device antimatter weapon electromagnetic pulse emp safety of high energy particle collision experiments micro black hole strangelet synthetic intelligence artificial intelligence ai takeover existential risk from artificial intelligence technological singularity transhumanism year 2000 problem year 2038 problem year 10 000 problem sociological anthropogenic hazard collapsology doomsday argument self indication assumption doomsday argument rebuttal self referencing doomsday argument rebuttal economic collapse malthusian catastrophe new world order conspiracy theory nuclear holocaust cobalt famine winter societal collapse world war iii ecologicalclimate change anoxic event biodiversity loss mass mortality event cascade effect cataclysmic pole shift hypothesis climate apocalypse deforestation desertification extinction risk from global warming tipping points in the climate system flood basalt global dimming global terrestrial stilling global warming hypercane ice age ecocide ecological collapse environmental degradation habitat destruction human impact on the environment coral reefs on marine life land degradation land consumption land surface effects on climate ocean acidification ozone depletion resource depletion sea level rise supervolcano winter verneshot water pollution water scarcity earth overshoot day overexploitation overpopulation human overpopulation biologicalextinction extinction event holocene extinction human extinction list of extinction events genetic erosion genetic pollution others biodiversity loss decline in amphibian populations decline in insect populations biotechnology risk biological agent biological warfare bioterrorism colony collapse disorder defaunation interplanetary contamination pandemic pollinator decline overfishing astronomical big crunch big rip coronal mass ejection geomagnetic storm false vacuum decay gamma ray burst heat death of the universe proton decay virtual black hole impact event asteroid impact avoidance asteroid impact prediction potentially hazardous object near earth object winter rogue planet near earth supernova hypernova micronova solar flare stellar collision eschatological buddhist maitreya three ages hindu kalki kali yuga last judgement second coming 1 enoch daniel abomination of desolation prophecy of seventy weeks messiah christian dispensationalism futurism historicism interpretations of revelation idealism preterism 2 esdras 2 thessalonians man of sin katechon antichrist book of revelation events four horsemen of the apocalypse lake of fire number of the beast seven bowls seven seals the beast two witnesses war in heaven whore of babylon great apostasy new earth new jerusalem olivet discourse great tribulation son of perdition sheep and goats islamic al qa im beast of the earth dhul qarnayn dhul suwayqatayn dajjal israfil mahdi sufyani jewish messiah war of gog and magog third temple norse zoroastrian saoshyant others 2011 end times prediction 2012 phenomenon apocalypse apocalyptic literature apocalypticism armageddon blood moon prophecy earth changes end time gog and magog list of dates predicted for apocalyptic events messianism messianic age millenarianism millennialism premillennialism amillennialism postmillennialism nemesis hypothetical star nibiru cataclysm rapture prewrath post tribulation rapture resurrection of the dead world to come fictional alien invasion apocalyptic and post apocalyptic fiction list of apocalyptic and post apocalyptic fiction list of apocalyptic films climate fiction disaster films list of disaster films list of fictional doomsday devices zombie apocalypse zombie organizations centre for the study of existential risk future of humanity institute future of life institute nuclear threat initiative general cyber ransom cyberwarfare depression droughts epidemic famine financial crisis pandemic riots social crisis survivalism 160 world 32 portal categories apocalypticism future problems hazards risk analysis doomsday scenarios retrieved from https en wikipedia org w index php title ai takeover amp oldid 1130591042 categories doomsday scenariosfuture problemsexistential risk from artificial general intelligencetechnophobiahidden categories webarchive template wayback linksarticles with short descriptionshort description is different from wikidataarticles with excerpts 