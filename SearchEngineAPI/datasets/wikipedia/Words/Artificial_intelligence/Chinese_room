chinese room from wikipedia the free encyclopedia jump to navigation jump to search thought experiment on artificial intelligence by john searle for the british video game development studio see the chinese room part of a series onartificial intelligence major goals artificial general intelligence planning computer vision general game playing knowledge reasoning machine learning natural language processing robotics approaches symbolic deep learning bayesian networks evolutionary algorithms philosophy chinese room friendly ai control problem takeover ethics existential risk turing test history timeline progress ai winter technology applications projects programming languages glossary glossary vte the chinese room argument holds that a digital computer executing a program cannot have a mind understanding or consciousness 91 a 93 regardless of how intelligently or human like the program may make the computer behave the argument was presented by philosopher john searle in his paper minds brains and programs published in behavioral and brain sciences in 1980 similar arguments were presented by gottfried leibniz 1714 anatoly dneprov 1961 lawrence davis 1974 and ned block 1978 searle s version has been widely discussed in the years since 91 1 93 the centerpiece of searle s argument is a thought experiment known as the chinese room 91 2 93 the argument is directed against the philosophical positions of functionalism and computationalism 91 3 93 which hold that the mind may be viewed as an information processing system operating on formal symbols and that simulation of a given mental state is sufficient for its presence specifically the argument is intended to refute a position searle calls strong ai the appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds 91 b 93 although it was originally presented in reaction to the statements of artificial intelligence ai researchers it is not an argument against the goals of mainstream ai research because it does not show a limit in the amount of intelligent behavior a machine can display 91 4 93 the argument applies only to digital computers running programs and does not apply to machines in general 91 5 93 contents 1 chinese room thought experiment 2 history 3 philosophy 3 1 strong ai 3 2 strong ai as computationalism or functionalism 3 3 strong ai vs biological naturalism 3 4 consciousness 3 5 applied ethics 4 computer science 4 1 strong ai vs ai research 4 2 turing test 4 3 symbol processing 4 4 chinese room and turing completeness 5 complete argument 6 replies 6 1 systems and virtual mind replies finding the mind 6 2 robot and semantics replies finding the meaning 6 2 1 robot reply 6 2 2 derived meaning 6 2 3 commonsense knowledge contextualist reply 6 3 brain simulation and connectionist replies redesigning the room 6 3 1 brain simulator reply 6 3 1 1 china brain 6 3 1 2 brain replacement scenario 6 3 2 connectionist replies 6 3 3 combination reply 6 3 4 many mansions wait till next year reply 6 4 speed and complexity appeals to intuition 6 5 other minds and zombies meaninglessness 6 6 other replies 7 in popular culture 8 see also 9 notes 10 citations 11 references 12 further reading chinese room thought experiment edit searle s thought experiment begins with this hypothetical premise suppose that artificial intelligence research has succeeded in constructing a computer that behaves as if it understands chinese it takes chinese characters as input and by following the instructions of a computer program produces other chinese characters which it presents as output suppose says searle that this computer performs its task so convincingly that it comfortably passes the turing test it convinces a human chinese speaker that the program is itself a live chinese speaker to all of the questions that the person asks it makes appropriate responses such that any chinese speaker would be convinced that they are talking to another chinese speaking human being the question searle wants to answer is this does the machine literally understand chinese or is it merely simulating the ability to understand chinese 91 6 93 91 c 93 searle calls the first position strong ai and the latter weak ai 91 d 93 searle then supposes that he is in a closed room and has a book with an english version of the computer program along with sufficient papers pencils erasers and filing cabinets searle could receive chinese characters through a slot in the door process them according to the program s instructions and produce chinese characters as output without understanding any of the content of the chinese writing if the computer had passed the turing test this way it follows says searle that he would do so as well simply by running the program manually searle asserts that there is no essential difference between the roles of the computer and himself in the experiment each simply follows a program step by step producing behavior that is then interpreted by the user as demonstrating intelligent conversation however searle himself would not be able to understand the conversation i don t speak a word of chinese 91 9 93 he points out therefore he argues it follows that the computer would not be able to understand the conversation either searle argues that without understanding or intentionality we cannot describe what the machine is doing as thinking and since it does not think it does not have a mind in anything like the normal sense of the word therefore he concludes that the strong ai hypothesis is false history edit gottfried leibniz made a similar argument in 1714 against mechanism the position that the mind is a machine and nothing more leibniz used the thought experiment of expanding the brain until it was the size of a mill 91 10 93 leibniz found it difficult to imagine that a mind capable of perception could be constructed using only mechanical processes 91 e 93 soviet cyberneticist anatoly dneprov made an essentially identical argument in 1961 in the form of the short story the game in it a stadium of people act as switches and memory cells implementing a program to translate a sentence of portuguese a language that none of them knows 91 11 93 the game was organized by a professor zarubin to answer the question can mathematical machines think speaking through zarubin dneprov writes the only way to prove that machines can think is to turn yourself into a machine and examine your thinking process and he concludes as searle does we ve proven that even the most perfect simulation of machine thinking is not the thinking process itself in 1974 lawrence davis imagined duplicating the brain using telephone lines and offices staffed by people and in 1978 ned block envisioned the entire population of china involved in such a brain simulation this thought experiment is called the china brain also the chinese nation or the chinese gym 91 12 93 john searle in december 2005 searle s version appeared in his 1980 paper minds brains and programs published in behavioral and brain sciences 91 13 93 it eventually became the journal s most influential target article 91 1 93 generating an enormous number of commentaries and responses in the ensuing decades and searle has continued to defend and refine the argument in many papers popular articles and books david cole writes that the chinese room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years 91 14 93 most of the discussion consists of attempts to refute it the overwhelming majority notes bbs editor stevan harnad 91 f 93 still think that the chinese room argument is dead wrong 91 15 93 the sheer volume of the literature that has grown up around it inspired pat hayes to comment that the field of cognitive science ought to be redefined as the ongoing research program of showing searle s chinese room argument to be false 91 16 93 searle s argument has become something of a classic in cognitive science according to harnad 91 15 93 varol akman agrees and has described the original paper as an exemplar of philosophical clarity and purity 91 17 93 philosophy edit although the chinese room argument was originally presented in reaction to the statements of artificial intelligence researchers philosophers have come to consider it as an important part of the philosophy of mind it is a challenge to functionalism and the computational theory of mind 91 g 93 and is related to such questions as the mind body problem the problem of other minds the symbol grounding problem and the hard problem of consciousness 91 a 93 strong ai edit searle identified a philosophical position he calls strong ai the appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds 91 b 93 the definition depends on the distinction between simulating a mind and actually having a mind searle writes that according to strong ai the correct simulation really is a mind according to weak ai the correct simulation is a model of the mind 91 7 93 the claim is implicit in some of the statements of early ai researchers and analysts for example in 1955 ai founder herbert a simon declared that there are now in the world machines that think that learn and create 91 23 93 simon together with allen newell and cliff shaw after having completed the first ai program the logic theorist claimed that they had solved the venerable mind body problem explaining how a system composed of matter can have the properties of mind 91 24 93 john haugeland wrote that ai wants only the genuine article machines with minds in the full and literal sense this is not science fiction but real science based on a theoretical conception as deep as it is daring namely we are at root computers ourselves 91 25 93 searle also ascribes the following claims to advocates of strong ai ai systems can be used to explain the mind 91 d 93 the study of the brain is irrelevant to the study of the mind 91 h 93 and the turing test is adequate for establishing the existence of mental states 91 i 93 strong ai as computationalism or functionalism edit in more recent presentations of the chinese room argument searle has identified strong ai as computer functionalism a term he attributes to daniel dennett 91 3 93 91 30 93 functionalism is a position in modern philosophy of mind that holds that we can define mental phenomena such as beliefs desires and perceptions by describing their functions in relation to each other and to the outside world because a computer program can accurately represent functional relationships as relationships between symbols a computer can have mental phenomena if it runs the right program according to functionalism stevan harnad argues that searle s depictions of strong ai can be reformulated as recognizable tenets of computationalism a position unlike strong ai that is actually held by many thinkers and hence one worth refuting 91 31 93 computationalism 91 j 93 is the position in the philosophy of mind which argues that the mind can be accurately described as an information processing system each of the following according to harnad is a tenet of computationalism 91 34 93 mental states are computational states which is why computers can have mental states and help to explain the mind computational states are implementation independent in other words it is the software that determines the computational state not the hardware which is why the brain being hardware is irrelevant and that since implementation is unimportant the only empirical data that matters is how the system functions hence the turing test is definitive strong ai vs biological naturalism edit searle holds a philosophical position he calls biological naturalism that consciousness 91 a 93 and understanding require specific biological machinery that are found in brains he writes brains cause minds 91 5 93 and that actual human mental phenomena are dependent on actual physical chemical properties of actual human brains 91 35 93 searle argues that this machinery known to neuroscience as the neural correlates of consciousness must have some causal powers that permit the human experience of consciousness 91 36 93 searle s belief in the existence of these powers has been criticized 91 k 93 searle does not disagree with the notion that machines can have consciousness and understanding because as he writes we are precisely such machines 91 5 93 searle holds that the brain is in fact a machine but that the brain gives rise to consciousness and understanding using machinery that is non computational if neuroscience is able to isolate the mechanical process that gives rise to consciousness then searle grants that it may be possible to create machines that have consciousness and understanding however without the specific machinery required searle does not believe that consciousness can occur biological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions because the specific machinery of the brain is essential thus biological naturalism is directly opposed to both behaviorism and functionalism including computer functionalism or strong ai 91 37 93 biological naturalism is similar to identity theory the position that mental states are identical to or composed of neurological events however searle has specific technical objections to identity theory 91 38 93 91 l 93 searle s biological naturalism and strong ai are both opposed to cartesian dualism 91 37 93 the classical idea that the brain and mind are made of different substances indeed searle accuses strong ai of dualism writing that strong ai only makes sense given the dualistic assumption that where the mind is concerned the brain doesn t matter 91 26 93 consciousness edit searle s original presentation emphasized understanding that is mental states with what philosophers call intentionality and did not directly address other closely related ideas such as consciousness however in more recent presentations searle has included consciousness as the real target of the argument 91 3 93 computational models of consciousness are not sufficient by themselves for consciousness the computational model for consciousness stands to consciousness in the same way the computational model of anything stands to the domain being modelled nobody supposes that the computational model of rainstorms in london will leave us all wet but they make the mistake of supposing that the computational model of consciousness is somehow conscious it is the same mistake in both cases 91 39 93 8201 john r searle consciousness and language p 16 david chalmers writes it is fairly clear that consciousness is at the root of the matter of the chinese room 91 40 93 colin mcginn argues that the chinese room provides strong evidence that the hard problem of consciousness is fundamentally insoluble the argument to be clear is not about whether a machine can be conscious but about whether it or anything else for that matter can be shown to be conscious it is plain that any other method of probing the occupant of a chinese room has the same difficulties in principle as exchanging questions and answers in chinese it is simply not possible to divine whether a conscious agency or some clever simulation inhabits the room 91 41 93 searle argues that this is only true for an observer outside of the room the whole point of the thought experiment is to put someone inside the room where they can directly observe the operations of consciousness searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness other than himself and clearly he does not have a mind that can speak chinese 91 citation needed 93 applied ethics edit sitting in the combat information center aboard a warship proposed as a real life analog to the chinese room patrick hew used the chinese room argument to deduce requirements from military command and control systems if they are to preserve a commander s moral agency he drew an analogy between a commander in their command center and the person in the chinese room and analyzed it under a reading of aristotle s notions of compulsory and ignorance information could be down converted from meaning to symbols and manipulated symbolically but moral agency could be undermined if there was inadequate up conversion into meaning hew cited examples from the uss vincennes incident 91 42 93 computer science edit the chinese room argument is primarily an argument in the philosophy of mind and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields 91 4 93 however several concepts developed by computer scientists are essential to understanding the argument including symbol processing turing machines turing completeness and the turing test strong ai vs ai research edit searle s arguments are not usually considered an issue for ai research stuart russell and peter norvig observe that most ai researchers don t care about the strong ai hypothesis as long as the program works they don t care whether you call it a simulation of intelligence or real intelligence 91 4 93 the primary mission of artificial intelligence research is only to create useful systems that act intelligently and it does not matter if the intelligence is merely a simulation searle does not disagree that ai research can create machines that are capable of highly intelligent behavior the chinese room argument leaves open the possibility that a digital machine could be built that acts more intelligently than a person but does not have a mind or intentionality in the same way that brains do searle s strong ai should not be confused with strong ai as defined by ray kurzweil and other futurists 91 43 93 who use the term to describe machine intelligence that rivals or exceeds human intelligence kurzweil is concerned primarily with the amount of intelligence displayed by the machine whereas searle s argument sets no limit on this searle argues that even a superintelligent machine would not necessarily have a mind and consciousness turing test edit main article turing test the standard interpretation of the turing test in which player c the interrogator is given the task of trying to determine which player a or b is a computer and which is a human the interrogator is limited to using the responses to written questions to make the determination image adapted from saygin et al 2000 91 44 93 the chinese room implements a version of the turing test 91 45 93 alan turing introduced the test in 1950 to help answer the question can machines think in the standard version a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being all participants are separated from one another if the judge cannot reliably tell the machine from the human the machine is said to have passed the test turing then considered each possible objection to the proposal machines can think and found that there are simple obvious answers if the question is de mystified in this way he did not however intend for the test to measure for the presence of consciousness or understanding he did not believe this was relevant to the issues that he was addressing he wrote i do not wish to give the impression that i think there is no mystery about consciousness there is for instance something of a paradox connected with any attempt to localise it but i do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper 91 45 93 to searle as a philosopher investigating in the nature of mind and consciousness these are the relevant mysteries the chinese room is designed to show that the turing test is insufficient to detect the presence of consciousness even if the room can behave or function as a conscious mind would symbol processing edit main article physical symbol system the chinese room and all modern computers manipulate physical objects in order to carry out calculations and do simulations ai researchers allen newell and herbert a simon called this kind of machine a physical symbol system it is also equivalent to the formal systems used in the field of mathematical logic searle emphasizes the fact that this kind of symbol manipulation is syntactic borrowing a term from the study of grammar the computer manipulates the symbols using a form of syntax rules without any knowledge of the symbol s semantics that is their meaning newell and simon had conjectured that a physical symbol system such as a digital computer had all the necessary machinery for general intelligent action or as it is known today artificial general intelligence they framed this as a philosophical position the physical symbol system hypothesis a physical symbol system has the necessary and sufficient means for general intelligent action 91 46 93 91 47 93 the chinese room argument does not refute this because it is framed in terms of intelligent action i e the external behavior of the machine rather than the presence or absence of understanding consciousness and mind chinese room and turing completeness edit see also turing completeness and church turing thesis the chinese room has a design analogous to that of a modern computer it has a von neumann architecture which consists of a program the book of instructions some memory the papers and file cabinets a cpu that follows the instructions the man and a means to write symbols in memory the pencil and eraser a machine with this design is known in theoretical computer science as turing complete because it has the necessary machinery to carry out any computation that a turing machine can do and therefore it is capable of doing a step by step simulation of any other digital machine given enough memory and time alan turing writes all digital computers are in a sense equivalent 91 48 93 the widely accepted church turing thesis holds that any function computable by an effective procedure is computable by a turing machine the turing completeness of the chinese room implies that it can do whatever any other digital computer can do albeit much much more slowly thus if the chinese room does not or can not contain a chinese speaking mind then no other digital computer can contain a mind some replies to searle begin by arguing that the room as described cannot have a chinese speaking mind arguments of this form according to stevan harnad are no refutation but rather an affirmation 91 49 93 of the chinese room argument because these arguments actually imply that no digital computers can have a mind 91 28 93 there are some critics such as hanoch ben yami who argue that the chinese room cannot simulate all the abilities of a digital computer such as being able to determine the current time 91 50 93 complete argument edit searle has produced a more formal version of the argument of which the chinese room forms a part he presented the first version in 1984 the version given below is from 1990 91 51 93 91 m 93 the chinese room thought experiment is intended to prove point a3 91 n 93 he begins with three axioms a1 programs are formal syntactic a program uses syntax to manipulate symbols and pays no attention to the semantics of the symbols it knows where to put the symbols and how to move them around but it does not know what they stand for or what they mean for the program the symbols are just physical objects like any others a2 minds have mental contents semantics unlike the symbols used by a program our thoughts have meaning they represent things and we know what it is they represent a3 syntax by itself is neither constitutive of nor sufficient for semantics this is what the chinese room thought experiment is intended to prove the chinese room has syntax because there is a man in there moving symbols around the chinese room has no semantics because according to searle there is no one or nothing in the room that understands what the symbols mean therefore having syntax is not enough to generate semantics searle posits that these lead directly to this conclusion c1 programs are neither constitutive of nor sufficient for minds this should follow without controversy from the first three programs don t have semantics programs have only syntax and syntax is insufficient for semantics every mind has semantics therefore no programs are minds this much of the argument is intended to show that artificial intelligence can never produce a machine with a mind by writing programs that manipulate symbols the remainder of the argument addresses a different issue is the human brain running a program in other words is the computational theory of mind correct 91 g 93 he begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds a4 brains cause minds searle claims that we can derive immediately and trivially 91 52 93 that c2 any other system capable of causing minds would have to have causal powers at least equivalent to those of brains brains must have something that causes a mind to exist science has yet to determine exactly what it is but it must exist because minds exist searle calls it causal powers causal powers is whatever the brain uses to create a mind if anything else can cause a mind to exist it must have equivalent causal powers equivalent causal powers is whatever else that could be used to make a mind and from this he derives the further conclusions c3 any artifact that produced mental phenomena any artificial brain would have to be able to duplicate the specific causal powers of brains and it could not do that just by running a formal program this follows from c1 and c2 since no program can produce a mind and equivalent causal powers produce minds it follows that programs do not have equivalent causal powers c4 the way that human brains actually produce mental phenomena cannot be solely by virtue of running a computer program since programs do not have equivalent causal powers equivalent causal powers produce minds and brains produce minds it follows that brains do not use programs to produce minds refutations of searle s argument take many different forms see below computationalists and functionalists reject a3 arguing that syntax as searle describes it can have semantics if the syntax has the right functional structure eliminative materialists reject a2 arguing that minds don t actually have semantics that thoughts and other mental phenomena are inherently meaningless but nevertheless function as if they had meaning replies edit replies to searle s argument may be classified according to what they claim to show 91 o 93 those which identify who speaks chinese those which demonstrate how meaningless symbols can become meaningful those which suggest that the chinese room should be redesigned in some way those which contend that searle s argument is misleading those which argue that the argument makes false assumptions about subjective conscious experience and therefore proves nothing some of the arguments robot and brain simulation for example fall into multiple categories systems and virtual mind replies finding the mind edit these replies attempt to answer the question since the man in the room doesn t speak chinese where is the mind that does these replies address the key ontological issues of mind vs body and simulation vs reality all of the replies that identify the mind in the room are versions of the system reply the basic version of the system reply argues that it is the whole system that understands chinese 91 57 93 91 p 93 while the man understands only english when he is combined with the program scratch paper pencils and file cabinets they form a system that can understand chinese here understanding is not being ascribed to the mere individual rather it is being ascribed to this whole system of which he is a part searle explains 91 29 93 the fact that a certain man does not understand chinese is irrelevant because it is only the system as a whole that matters searle notes that in this simple version of the reply the system is nothing more than a collection of ordinary physical objects it grants the power of understanding and consciousness to the conjunction of that person and bits of paper 91 29 93 without making any effort to explain how this pile of objects has become a conscious thinking being searle argues that no reasonable person should be satisfied with the reply unless they are under the grip of an ideology 91 29 93 in order for this reply to be remotely plausible one must take it for granted that consciousness can be the product of an information processing system and does not require anything resembling the actual biology of the brain searle then responds by simplifying this list of physical objects he asks what happens if the man memorizes the rules and keeps track of everything in his head then the whole system consists of just one object the man himself searle argues that if the man does not understand chinese then the system does not understand chinese either because now the system and the man both describe exactly the same object 91 29 93 critics of searle s response argue that the program has allowed the man to have two minds in one head 91 who 93 if we assume a mind is a form of information processing then the theory of computation can account for two computations occurring at once namely 1 the computation for universal programmability which is the function instantiated by the person and note taking materials independently from any particular program contents and 2 the computation of the turing machine that is described by the program which is instantiated by everything including the specific program 91 59 93 the theory of computation thus formally explains the open possibility that the second computation in the chinese room could entail a human equivalent semantic understanding of the chinese inputs the focus belongs on the program s turing machine rather than on the person s 91 60 93 however from searle s perspective this argument is circular the question at issue is whether consciousness is a form of information processing and this reply requires that we make that assumption more sophisticated versions of the systems reply try to identify more precisely what the system is and they differ in exactly how they describe it according to these replies 91 who 93 the mind that speaks chinese could be such things as the software a program a running program a simulation of the neural correlates of consciousness the functional system a simulated mind an emergent property or a virtual mind described below marvin minsky suggested a version of the system reply known as the virtual mind reply 91 q 93 the term virtual is used in computer science to describe an object that appears to exist in a computer or computer network only because software makes it appear to exist the objects inside computers including files folders and so on are all virtual except for the computer s electronic components similarly minsky argues a computer may contain a mind that is virtual in the same sense as virtual machines virtual communities and virtual reality to clarify the distinction between the simple systems reply given above and virtual mind reply david cole notes that two simulations could be running on one system at the same time one speaking chinese and one speaking korean while there is only one system there can be multiple virtual minds thus the system cannot be the mind 91 64 93 searle responds that such a mind is at best a simulation and writes no one supposes that computer simulations of a five alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched 91 65 93 nicholas fearn responds that for some things simulation is as good as the real thing when we call up the pocket calculator function on a desktop computer the image of a pocket calculator appears on the screen we don t complain that it isn t really a calculator because the physical attributes of the device do not matter 91 66 93 the question is is the human mind like the pocket calculator essentially composed of information or is the mind like the rainstorm something other than a computer and not realizable in full by a computer simulation for decades this question of simulation has led ai researchers and philosophers to consider whether the term synthetic intelligence is more appropriate than the common description of such intelligences as artificial these replies provide an explanation of exactly who it is that understands chinese if there is something besides the man in the room that can understand chinese searle cannot argue that 1 the man does not understand chinese therefore 2 nothing in the room understands chinese this according to those who make this reply shows that searle s argument fails to prove that strong ai is false 91 r 93 these replies by themselves do not provide any evidence that strong ai is true however they do not show that the system or the virtual mind understands chinese other than the hypothetical premise that it passes the turing test searle argues that if we are to consider strong ai remotely plausible the chinese room is an example that requires explanation and it is difficult or impossible to explain how consciousness might emerge from the room or how the system would have consciousness as searle writes the systems reply simply begs the question by insisting that the system must understand chinese 91 29 93 and thus is dodging the question or hopelessly circular robot and semantics replies finding the meaning edit as far as the person in the room is concerned the symbols are just meaningless squiggles but if the chinese room really understands what it is saying then the symbols must get their meaning from somewhere these arguments attempt to connect the symbols to the things they symbolize these replies address searle s concerns about intentionality symbol grounding and syntax vs semantics robot reply edit suppose that instead of a room the program was placed into a robot that could wander around and interact with its environment this would allow a causal connection between the symbols and things they represent 91 68 93 91 s 93 hans moravec comments if we could graft a robot to a reasoning program we wouldn t need a person to provide the meaning anymore it would come from the physical world 91 70 93 91 t 93 searle s reply is to suppose that unbeknownst to the individual in the chinese room some of the inputs came directly from a camera mounted on a robot and some of the outputs were used to manipulate the arms and legs of the robot nevertheless the person in the room is still just following the rules and does not know what the symbols mean searle writes he doesn t see what comes into the robot s eyes 91 72 93 see mary s room for a similar thought experiment derived meaning edit some respond that the room as searle describes it is connected to the world through the chinese speakers that it is talking to and through the programmers who designed the knowledge base in his file cabinet the symbols searle manipulates are already meaningful they re just not meaningful to him 91 73 93 91 u 93 searle says that the symbols only have a derived meaning like the meaning of words in books the meaning of the symbols depends on the conscious understanding of the chinese speakers and the programmers outside the room the room like a book has no understanding of its own 91 v 93 commonsense knowledge contextualist reply edit some have argued that the meanings of the symbols would come from a vast background of commonsense knowledge encoded in the program and the filing cabinets this would provide a context that would give the symbols their meaning 91 71 93 91 w 93 searle agrees that this background exists but he does not agree that it can be built into programs hubert dreyfus has also criticized the idea that the background can be represented symbolically 91 76 93 to each of these suggestions searle s response is the same no matter how much knowledge is written into the program and no matter how the program is connected to the world he is still in the room manipulating symbols according to rules his actions are syntactic and this can never explain to him what the symbols stand for searle writes syntax is insufficient for semantics 91 77 93 91 x 93 however for those who accept that searle s actions simulate a mind separate from his own the important question is not what the symbols mean to searle what is important is what they mean to the virtual mind while searle is trapped in the room the virtual mind is not it is connected to the outside world through the chinese speakers it speaks to through the programmers who gave it world knowledge and through the cameras and other sensors that roboticists can supply brain simulation and connectionist replies redesigning the room edit these arguments are all versions of the systems reply that identify a particular kind of system as being important they identify some special technology that would create conscious understanding in a machine the robot and commonsense knowledge replies above also specify a certain kind of system as being important brain simulator reply edit suppose that the program simulated in fine detail the action of every neuron in the brain of a chinese speaker 91 79 93 91 y 93 this strengthens the intuition that there would be no significant difference between the operation of the program and the operation of a live human brain searle replies that such a simulation does not reproduce the important features of the brain its causal and intentional states searle is adamant that human mental phenomena are dependent on actual physical chemical properties of actual human brains 91 26 93 moreover he argues i magine that instead of a monolingual man in a room shuffling symbols we have the man operate an elaborate set of water pipes with valves connecting them when the man receives the chinese symbols he looks up in the program written in english which valves he has to turn on and off each water connection corresponds to a synapse in the chinese brain and the whole system is rigged up so that after doing all the right firings that is after turning on all the right faucets the chinese answers pop out at the output end of the series of pipes now where is the understanding in this system it takes chinese as input it simulates the formal structure of the synapses of the chinese brain and it gives chinese as output but the man certainly doesn t understand chinese and neither do the water pipes and if we are tempted to adopt what i think is the absurd view that somehow the conjunction of man and water pipes understands remember that in principle the man can internalize the formal structure of the water pipes and do all the neuron firings in his imagination 91 81 93 two variations on the brain simulator reply are the china brain and the brain replacement scenario china brain edit what if we ask each citizen of china to simulate one neuron using the telephone system to simulate the connections between axons and dendrites in this version it seems obvious that no individual would have any understanding of what the brain might be saying 91 82 93 91 z 93 it is also obvious that this system would be functionally equivalent to a brain so if consciousness is a function this system would be conscious brain replacement scenario edit in this we are asked to imagine that engineers have invented a tiny computer that simulates the action of an individual neuron what would happen if we replaced one neuron at a time replacing one would clearly do nothing to change conscious awareness replacing all of them would create a digital computer that simulates a brain if searle is right then conscious awareness must disappear during the procedure either gradually or all at once searle s critics argue that there would be no point during the procedure when he can claim that conscious awareness ends and mindless simulation begins 91 84 93 91 aa 93 91 ab 93 see ship of theseus for a similar thought experiment connectionist replies edit closely related to the brain simulator reply this claims that a massively parallel connectionist architecture would be capable of understanding 91 ac 93 combination reply edit this response combines the robot reply with the brain simulation reply arguing that a brain simulation connected to the world through a robot body could have a mind 91 89 93 many mansions wait till next year reply edit better technology in the future will allow computers to understand 91 27 93 91 ad 93 searle agrees that this is possible but considers this point irrelevant searle agrees that there may be designs that would cause a machine to have conscious understanding these arguments and the robot or commonsense knowledge replies identify some special technology that would help create conscious understanding in a machine they may be interpreted in two ways either they claim 1 this technology is required for consciousness the chinese room does not or cannot implement this technology and therefore the chinese room cannot pass the turing test or even if it did it would not have conscious understanding or they may be claiming that 2 it is easier to see that the chinese room has a mind if we visualize this technology as being used to create it in the first case where features like a robot body or a connectionist architecture are required searle claims that strong ai as he understands it has been abandoned 91 ae 93 the chinese room has all the elements of a turing complete machine and thus is capable of simulating any digital computation whatsoever if searle s room cannot pass the turing test then there is no other digital technology that could pass the turing test if searle s room could pass the turing test but still does not have a mind then the turing test is not sufficient to determine if the room has a mind either way it denies one or the other of the positions searle thinks of as strong ai proving his argument the brain arguments in particular deny strong ai if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was he writes i thought the whole idea of strong ai was that we don t need to know how the brain works to know how the mind works 91 27 93 if computation does not provide an explanation of the human mind then strong ai has failed according to searle other critics hold that the room as searle described it does in fact have a mind however they argue that it is difficult to see searle s description is correct but misleading by redesigning the room more realistically they hope to make this more obvious in this case these arguments are being used as appeals to intuition see next section in fact the room can just as easily be redesigned to weaken our intuitions ned block s blockhead argument 91 90 93 suggests that the program could in theory be rewritten into a simple lookup table of rules of the form if the user writes s reply with p and goto x at least in principle any program can be rewritten or refactored into this form even a brain simulation 91 af 93 in the blockhead scenario the entire mental state is hidden in the letter x which represents a memory address a number associated with the next rule it is hard to visualize that an instant of one s conscious experience can be captured in a single large number yet this is exactly what strong ai claims on the other hand such a lookup table would be ridiculously large to the point of being physically impossible and the states could therefore be extremely specific searle argues that however the program is written or however the machine is connected to the world the mind is being simulated by a simple step by step digital machine or machines these machines are always just like the man in the room they understand nothing and do not speak chinese they are merely manipulating symbols without knowing what they mean searle writes i can have any formal program you like but i still understand nothing 91 9 93 speed and complexity appeals to intuition edit the following arguments and the intuitive interpretations of the arguments above do not directly explain how a chinese speaking mind could exist in searle s room or how the symbols he manipulates could become meaningful however by raising doubts about searle s intuitions they support other positions such as the system and robot replies these arguments if accepted prevent searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires several critics believe that searle s argument relies entirely on intuitions ned block writes searle s argument depends for its force on intuitions that certain entities do not think 91 91 93 daniel dennett describes the chinese room argument as a misleading intuition pump 91 92 93 and writes searle s thought experiment depends illicitly on your imagining too simple a case an irrelevant case and drawing the obvious conclusion from it 91 92 93 some of the arguments above also function as appeals to intuition especially those that are intended to make it seem more plausible that the chinese room contains a mind which can include the robot commonsense knowledge brain simulation and connectionist replies several of the replies above also address the specific issue of complexity the connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain the commonsense knowledge reply emphasizes that any program that passed a turing test would have to be an extraordinarily supple sophisticated and multilayered system brimming with world knowledge and meta knowledge and meta meta knowledge as daniel dennett explains 91 75 93 many of these critiques emphasize speed and complexity of the human brain 91 ag 93 which processes information at 100 billion operations per second by some estimates 91 94 93 several critics point out that the man in the room would probably take millions of years to respond to a simple question and would require filing cabinets of astronomical proportions 91 95 93 this brings the clarity of searle s intuition into doubt an especially vivid version of the speed and complexity reply is from paul and patricia churchland they propose this analogous thought experiment consider a dark room containing a man holding a bar magnet or charged object if the man pumps the magnet up and down then according to maxwell s theory of artificial luminance al it will initiate a spreading circle of electromagnetic waves and will thus be luminous but as all of us who have toyed with magnets or charged balls well know their forces or any other forces for that matter even when set in motion produce no luminance at all it is inconceivable that you might constitute real luminance just by moving forces around 91 83 93 churchland s point is that the problem is that he would have to wave the magnet up and down something like 450 trillion times per second in order to see anything 91 96 93 stevan harnad is critical of speed and complexity replies when they stray beyond addressing our intuitions he writes some have made a cult of speed and timing holding that when accelerated to the right speed the computational may make a phase transition into the mental it should be clear that is not a counterargument but merely an ad hoc speculation as is the view that it is all just a matter of ratcheting up to the right degree of complexity 91 97 93 91 ah 93 searle argues that his critics are also relying on intuitions however his opponents intuitions have no empirical basis he writes that in order to consider the system reply as remotely plausible a person must be under the grip of an ideology 91 29 93 the system reply only makes sense to searle if one assumes that any system can have consciousness just by virtue of being a system with the right behavior and functional parts this assumption he argues is not tenable given our experience of consciousness other minds and zombies meaninglessness edit several replies argue that searle s argument is irrelevant because his assumptions about the mind and consciousness are faulty searle believes that human beings directly experience their consciousness intentionality and the nature of the mind every day and that this experience of consciousness is not open to question he writes that we must presuppose the reality and knowability of the mental 91 100 93 the replies below question whether searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing in particular the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds even the mind of a computer the eliminative materialist reply argues that searle s own personal consciousness does not exist in the sense that searle thinks it does and the epiphenoma replies question whether we can make any argument at all about something like consciousness which can not by definition be detected by any experiment the other minds reply points out that searle s argument is a version of the problem of other minds applied to machines there is no way we can determine if other people s subjective experience is the same as our own we can only study their behavior i e by giving them our own turing test critics of searle argue that he is holding the chinese room to a higher standard than we would hold an ordinary person 91 101 93 91 ai 93 nils nilsson writes if a program behaves as if it were multiplying most of us would say that it is in fact multiplying for all i know searle may only be behaving as if he were thinking deeply about these matters but even though i disagree with him his simulation is pretty good so i m willing to credit him with real thought 91 103 93 alan turing anticipated searle s line of argument which he called the argument from consciousness in 1950 and makes the other minds reply 91 104 93 he noted that people never consider the problem of other minds when dealing with each other he writes that instead of arguing continually over this point it is usual to have the polite convention that everyone thinks 91 105 93 the turing test simply extends this polite convention to machines he does not intend to solve the problem of other minds for machines or people and he does not think we need to 91 aj 93 several philosophers argue that consciousness as searle describes it does not exist this position is sometimes referred to as eliminative materialism the view that consciousness is not a concept that can enjoy reduction to a strictly mechanical i e material description but rather is a concept that will be simply eliminated once the way the material brain works is fully understood in just the same way as the concept of a demon has already been eliminated from science rather than enjoying reduction to a strictly mechanical description and that our experience of consciousness is as daniel dennett describes it a user illusion 91 108 93 other mental properties such as original intentionality also called meaning content and semantic character are also commonly regarded as special properties related to beliefs and other propositional attitudes eliminative materialism maintains that propositional attitudes such as beliefs and desires among other intentional mental states that have content do not exist if eliminative materialism is the correct scientific account of human cognition then the assumption of the chinese room argument that minds have mental contents semantics must be rejected 91 109 93 stuart russell and peter norvig argue that if we accept searle s description of intentionality consciousness and the mind we are forced to accept that consciousness is epiphenomenal that it casts no shadow i e is undetectable in the outside world they argue that searle must be mistaken about the knowability of the mental and in his belief that there are causal properties in our neurons that give rise to the mind they point out that by searle s own description these causal properties cannot be detected by anyone outside the mind otherwise the chinese room could not pass the turing test the people outside would be able to tell there was not a chinese speaker in the room by detecting their causal properties since they cannot detect causal properties they cannot detect the existence of the mental in short searle s causal properties and consciousness itself is undetectable and anything that cannot be detected either does not exist or does not matter 91 110 93 mike alder makes the same point which he calls the newton s flaming laser sword reply he argues that the entire argument is frivolous because it is non verificationist not only is the distinction between simulating a mind and having a mind ill defined but it is also irrelevant because no experiments were or even can be proposed to distinguish between the two 91 111 93 daniel dennett provides this extension to the epiphenomena argument suppose that by some mutation a human being is born that does not have searle s causal properties but nevertheless acts exactly like a human being this sort of animal is called a zombie in thought experiments in the philosophy of mind this new animal would reproduce just as any other human and eventually there would be more of these zombies natural selection would favor the zombies since their design is we could suppose a bit simpler eventually the humans would die out so therefore if searle is right it is most likely that human beings as we see them today are actually zombies who nevertheless insist they are conscious it is impossible to know whether we are all zombies or not even if we are all zombies we would still believe that we are not 91 112 93 searle disagrees with this analysis and argues that the study of the mind starts with such facts as that humans have beliefs while thermostats telephones and adding machines don t what we wanted to know is what distinguishes the mind from thermostats and livers 91 72 93 he takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point other replies edit margaret boden argued in her paper escaping from the chinese room that even if the person in the room does not understand the chinese it does not mean there is no understanding in the room the person in the room at least understands the rule book used to provide output responses 91 113 93 in popular culture edit the chinese room argument is a central concept in peter watts s novels blindsight and to a lesser extent echopraxia 91 114 93 greg egan illustrates the concept succinctly and somewhat horrifically in his 1990 short story learning to be me in his axiomatic collection it is a central theme in the video game zero escape virtue s last reward and ties into the game s narrative 91 115 93 in season 4 of the american crime drama numb3rs there is a brief reference to the chinese room 91 116 93 the chinese room is also the name of a british independent video game development studio best known for working on experimental first person games such as everybody s gone to the rapture or dear esther 91 117 93 in the 2016 video game the turing test the chinese room thought experiment is explained to the player by an ai see also edit computational models of language acquisition emergence philosophical zombie synthetic intelligence i am a strange loop notes edit a b c the section consciousness of this article discusses the relationship between the chinese room argument and consciousness a b this version is from searle s mind language and society 91 20 93 and is also quoted in daniel dennett s consciousness explained 91 21 93 searle s original formulation was the appropriately programmed computer really is a mind in the sense that computers given the right programs can be literally said to understand and have other cognitive states 91 22 93 strong ai is defined similarly by stuart russell and peter norvig the assertion that machines could possibly act intelligently or perhaps better act as if they were intelligent is called the weak ai hypothesis by philosophers and the assertion that machines that do so are actually thinking as opposed to simulating thinking is called the strong ai hypothesis 91 4 93 searle writes that according to strong ai the correct simulation really is a mind according to weak ai the correct simulation is a model of the mind 91 7 93 he also writes on the strong ai view the appropriately programmed computer does not just simulate having a mind it literally has a mind 91 8 93 a b searle writes partisans of strong ai claim that in this question and answer sequence the machine is not only simulating a human ability but also 1 that the machine can literally be said to understand the story and provide the answers to questions and 2 that what the machine and its program do explains the human ability to understand the story and answer questions about it 91 6 93 note that leibniz was objecting to a mechanical theory of the mind the philosophical position known as mechanism searle is objecting to an information processing view of the mind the philosophical position known as computationalism searle accepts mechanism and rejects computationalism harnad edited bbs during the years which saw the introduction and popularisation of the chinese room argument a b stevan harnad holds that the searle s argument is against the thesis that has since come to be called computationalism according to which cognition is just computation hence mental states are just computational states 91 18 93 david cole agrees that the argument also has broad implications for functionalist and computational theories of meaning and of mind 91 19 93 searle believes that strong ai only makes sense given the dualistic assumption that where the mind is concerned the brain doesn t matter 91 26 93 he writes elsewhere i thought the whole idea of strong ai was that we don t need to know how the brain works to know how the mind works 91 27 93 this position owes its phrasing to stevan harnad 91 28 93 one of the points at issue writes searle is the adequacy of the turing test 91 29 93 computationalism is associated with jerry fodor and hilary putnam 91 32 93 and is held by allen newell 91 28 93 zenon pylyshyn 91 28 93 and steven pinker 91 33 93 among others see the replies to searle under meaninglessness below larry hauser writes that biological naturalism is either confused waffling between identity theory and dualism or else it just is identity theory or dualism 91 37 93 the wording of each axiom and conclusion are from searle s presentation in scientific american 91 52 93 91 53 93 a1 3 and c1 are described as 1 2 3 and 4 in david cole 91 54 93 paul and patricia churchland write that the chinese room thought experiment is intended to shore up axiom 3 91 55 93 david cole combines the second and third categories as well as the fourth and fifth 91 56 93 versions of the system reply are held by ned block jack copeland daniel dennett jerry fodor john haugeland ray kurzweil and georges rey among others 91 58 93 the virtual mind reply is held by marvin minsky 91 61 93 91 62 93 tim maudlin david chalmers and david cole 91 63 93 david cole writes from the intuition that in the cr thought experiment he would not understand chinese by running a program searle infers that there is no understanding created by running a program clearly whether that inference is valid or not turns on a metaphysical question about the identity of persons and minds if the person understanding is not identical with the room operator then the inference is unsound 91 67 93 this position is held by margaret boden tim crane daniel dennett jerry fodor stevan harnad hans moravec and georges rey among others 91 69 93 david cole calls this the externalist account of meaning 91 71 93 the derived meaning reply is associated with daniel dennett and others searle distinguishes between intrinsic intentionality and derived intentionality intrinsic intentionality is the kind that involves conscious understanding like you would have in a human mind daniel dennett doesn t agree that there is a distinction david cole writes derived intentionality is all there is according to dennett 91 74 93 david cole describes this as the internalist approach to meaning 91 71 93 proponents of this position include roger schank doug lenat marvin minsky and with reservations daniel dennett who writes the fact is that any program that passed a turing test would have to be an extraordinarily supple sophisticated and multilayered system brimming with world knowledge and meta knowledge and meta meta knowledge 91 75 93 searle also writes formal symbols by themselves can never be enough for mental contents because the symbols by definition have no meaning or interpretation or semantics except insofar as someone outside the system gives it to them 91 78 93 the brain simulation reply has been made by paul churchland patricia churchland and ray kurzweil 91 80 93 early versions of this argument were put forward in 1974 by lawrence davis and in 1978 by ned block block s version used walkie talkies and was called the chinese gym paul and patricia churchland described this scenario as well 91 83 93 an early version of the brain replacement scenario was put forward by clark glymour in the mid 70s and was touched on by zenon pylyshyn in 1980 hans moravec presented a vivid version of it 91 85 93 and it is now associated with ray kurzweil s version of transhumanism searle does not consider the brain replacement scenario as an argument against the cra however in another context searle examines several possible solutions including the possibility that you find to your total amazement that you are indeed losing control of your external behavior you find for example that when doctors test your vision you hear them say we are holding up a red object in front of you please tell us what you see you want to cry out i can t see anything i m going totally blind but you hear your voice saying in a way that is completely outside of your control i see a red object in front of me y our conscious experience slowly shrinks to nothing while your externally observable behavior remains the same 91 86 93 the connectionist reply is made by andy clark and ray kurzweil 91 87 93 as well as paul and patricia churchland 91 88 93 searle 2009 uses the name wait til next year reply searle writes that the robot reply tacitly concedes that cognition is not solely a matter of formal symbol manipulation 91 72 93 stevan harnad makes the same point writing now just as it is no refutation but rather an affirmation of the cra to deny that the turing test is a strong enough test or to deny that a computer could ever pass it it is merely special pleading to try to save computationalism by stipulating ad hoc in the face of the cra that implementational details do matter after all and that the computer s is the right kind of implementation whereas searle s is the wrong kind 91 49 93 that is any program running on a machine with a finite amount memory speed and complexity replies are made by daniel dennett tim maudlin david chalmers steven pinker paul churchland patricia churchland and others 91 93 93 daniel dennett points out the complexity of world knowledge 91 75 93 critics of the phase transition form of this argument include stevan harnad tim maudlin daniel dennett and david cole 91 93 93 this phase transition idea is a version of strong emergentism what daniel dennett derides as woo woo west coast emergence 91 98 93 harnad accuses churchland and patricia churchland of espousing strong emergentism ray kurzweil also holds a form of strong emergentism 91 99 93 the other minds reply has been offered by daniel dennett ray kurzweil and hans moravec among others 91 102 93 one of turing s motivations for devising the turing test is to avoid precisely the kind of philosophical problems that searle is interested in he writes i do not wish to give the impression that i think there is no mystery but i do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper 91 106 93 although turing is discussing consciousness not the mind or understanding or intentionality stuart russell and peter norvig argue that turing s comments apply the chinese room 91 107 93 citations edit a b harnad 2001 p 160 1 roberts 2016 a b c searle 1992 p 160 44 a b c d russell amp norvig 2003 p 160 947 a b c searle 1980 p 160 11 a b searle 1980 p 160 2 a b searle 2009 p 160 1 searle 2004 p 160 66 a b searle 1980 p 160 3 cole 2004 2 1 leibniz 1714 section 17 a russian chinese room story antedating searle s 1980 discussion center for consciousness studies june 15 2018 cole 2004 2 3 searle 1980 cole 2004 p 160 2 preston amp bishop 2002 a b harnad 2001 p 160 2 harnad 2001 p 160 1 cole 2004 p 160 2 akman 1998 harnad 2005 p 160 1 cole 2004 p 160 1 searle 1999 p 160 91 page 160 needed 93 dennett 1991 p 160 435 searle 1980 p 160 1 quoted in russell amp norvig 2003 p 160 21 quoted in crevier 1993 p 160 46 and russell amp norvig 2003 p 160 17 haugeland 1985 p 160 2 160 italics his a b c searle 1980 p 160 13 a b c searle 1980 p 160 8 a b c d harnad 2001 a b c d e f g searle 1980 p 160 6 searle 2004 p 160 45 harnad 2001 p 160 3 160 italics his horst 2005 p 160 1 pinker 1997 harnad 2001 pp 160 3 5 searle 1990a p 160 29 searle 1990b a b c hauser 2006 p 160 8 searle 1992 chpt 5 searle 2002 chalmers 1996 p 160 322 mcginn 2000 hew 2016 kurzweil 2005 p 160 260 saygin cicekli amp akman 2000 a b turing 1950 newell amp simon 1976 p 160 116 russell amp norvig 2003 p 160 18 turing 1950 p 160 442 a b harnad 2001 p 160 14 ben yami 1993 searle 1984 searle 1990a a b searle 1990a hauser 2006 p 160 5 cole 2004 p 160 5 churchland amp churchland 1990 p 160 34 cole 2004 pp 160 5 6 searle 1980 pp 160 5 6 cole 2004 pp 160 6 7 hauser 2006 pp 160 2 3 russell amp norvig 2003 p 160 959 dennett 1991 p 160 439 fearn 2007 p 160 44 crevier 1993 p 160 269 cole 2004 p 160 6 yee 1993 p 44 footnote 2 yee 1993 pp 160 42 47 minsky 1980 p 160 440 cole 2004 p 160 7 cole 2004 pp 160 7 9 cole 2004 p 160 8 searle 1980 p 160 12 fearn 2007 p 160 47 cole 2004 p 160 21 searle 1980 p 160 7 cole 2004 pp 160 9 11 hauser 2006 p 160 3 fearn 2007 p 160 44 cole 2004 p 160 9 quoted in crevier 1993 p 160 272 a b c cole 2004 p 160 18 a b c searle 1980 p 160 7 hauser 2006 p 160 11 cole 2004 p 160 19 cole 2004 p 160 19 a b c dennett 1991 p 160 438 dreyfus 1979 the epistemological assumption searle 1984 motzkin amp searle 1989 p 160 45 searle 1980 pp 160 7 8 cole 2004 pp 160 12 13 hauser 2006 pp 160 3 4 churchland amp churchland 1990 cole 2004 p 160 12 searle 1980 p 160 91 page 160 needed 93 cole 2004 p 160 4 hauser 2006 p 160 11 a b churchland amp churchland 1990 russell amp norvig 2003 pp 160 956 958 cole 2004 p 160 20 moravec 1988 kurzweil 2005 p 160 262 crevier 1993 pp 160 271 and 279 moravec 1988 searle 1992 quoted in russell amp norvig 2003 p 160 957 cole 2004 pp 160 12 amp 17 hauser 2006 p 160 7 searle 1980 pp 160 8 9 hauser 2006 p 160 11 block 1981 quoted in cole 2004 p 160 13 a b dennett 1991 pp 160 437 440 a b cole 2004 p 160 14 crevier 1993 p 160 269 cole 2004 pp 160 14 15 crevier 1993 pp 160 269 270 pinker 1997 p 160 95 churchland amp churchland 1990 cole 2004 p 160 12 crevier 1993 p 160 270 fearn 2007 pp 160 45 46 pinker 1997 p 160 94 harnad 2001 p 160 7 crevier 1993 p 160 275 kurzweil 2005 searle 1980 p 160 10 searle 1980 p 160 9 cole 2004 p 160 13 hauser 2006 pp 160 4 5 nilsson 1984 cole 2004 pp 160 12 13 nilsson 1984 turing 1950 pp 160 11 12 turing 1950 p 160 11 turing 1950 p 160 12 russell amp norvig 2003 pp 160 952 953 dennett 1991 91 page 160 needed 93 eliminative materialism stanford encyclopedia of philosophy march 11 2019 russell amp norvig 2003 alder 2004 cole 2004 p 160 22 crevier 1993 p 160 271 harnad 2005 p 160 4 margaret a boden 1988 escaping from the chinese room in john heil ed computer models of mind cambridge university press isbn 160 9780521248686 whitmarsh 2016 two minute game crit virtue s last reward and the chinese room july 30 2016 numb3rs season 4 www amazon com asin 160 b000w5kbi4 archived from the original on 2007 12 01 retrieved 2021 02 26 home the chinese room retrieved 2018 04 27 references edit akman varol 1998 book review john haugeland editor mind design ii philosophy psychology and artificial intelligence retrieved 2018 10 02 8211 via cogprints alder mike 2004 newton s flaming laser sword philosophy now 46 29 33 archived from the original on 2018 03 26 also available at newton s flaming laser sword pdf archived from the original pdf on 2011 11 14 ben yami hanoch 1993 a note on the chinese room synthese 95 2 169 72 doi 10 1007 bf01064586 s2cid 160 46968094 block ned 1981 psychologism and behaviourism the philosophical review 90 1 5 43 citeseerx 160 10 1 1 4 5828 doi 10 2307 2184371 jstor 160 2184371 chalmers david march 30 1996 the conscious mind in search of a fundamental theory oxford university press isbn 160 978 0 19 983935 3 churchland paul churchland patricia january 1990 could a machine think scientific american 262 1 32 39 bibcode 1990sciam 262a 32c doi 10 1038 scientificamerican0190 32 pmid 160 2294584 cole david fall 2004 the chinese room argument in zalta edward n ed the stanford encyclopedia of philosophy page numbers above refer to a standard pdf print of the article crevier daniel 1993 ai the tumultuous search for artificial intelligence new york ny basicbooks isbn 160 0 465 02997 3 dennett daniel 1991 consciousness explained the penguin press isbn 160 978 0 7139 9037 9 dreyfus hubert 1979 what computers still can t do new york mit press isbn 160 978 0 262 04134 8 fearn nicholas 2007 the latest answers to the oldest questions a philosophical adventure with the world s greatest thinkers new york grove press harnad stevan 2001 what s wrong and right about searle s chinese room argument in m preston j eds views into the chinese room new essays on searle and artificial intelligence oxford university press page numbers above refer to a standard pdf print of the article harnad stevan 2005 searle s chinese room argument encyclopedia of philosophy macmillan archived from the original on 2007 01 16 retrieved 2006 04 06 page numbers above refer to a standard pdf print of the article haugeland john 1985 artificial intelligence the very idea cambridge mass mit press isbn 160 978 0 262 08153 5 haugeland john 1981 mind design cambridge mass mit press isbn 160 978 0 262 08110 8 hauser larry 2006 searle s chinese room internet encyclopedia of philosophy page numbers above refer to a standard pdf print of the article hew patrick chisan september 2016 preserving a combat commander s moral agency the vincennes incident as a chinese room ethics and information technology 18 3 227 235 doi 10 1007 s10676 016 9408 y s2cid 160 15333272 kurzweil ray 2005 the singularity is near viking press horst steven fall 2005 the computational theory of mind in zalta edward n ed the stanford encyclopedia of philosophy leibniz gottfried 1714 monadology george macdonald ross trans archived from the original on 2011 07 03 moravec hans 1988 mind children the future of robot and human intelligence harvard university press minsky marvin 1980 decentralized minds behavioral and brain sciences 3 3 439 40 doi 10 1017 s0140525x00005914 s2cid 160 246243634 mcginn collin 2000 the mysterious flame conscious minds in a material world basic books p 160 194 isbn 160 978 0786725168 moor james ed 2003 the turing test the elusive standard of artificial intelligence dordrecht kluwer academic publishers isbn 160 978 1 4020 1205 1 motzkin elhanan searle john february 16 1989 artificial intelligence and the chinese room an exchange new york review of books newell allen simon h a 1976 computer science as empirical inquiry symbols and search communications of the acm 19 3 113 126 doi 10 1145 360018 360022 nikoli danko 2015 practopoiesis or how life fosters a mind journal of theoretical biology 373 40 61 arxiv 1402 5332 bibcode 2015jthbi 373 40n doi 10 1016 j jtbi 2015 03 003 pmid 160 25791287 s2cid 160 12680941 nilsson nils 1984 a short rebuttal to searle pdf russell stuart j norvig peter 2003 artificial intelligence a modern approach 2nd 160 ed upper saddle river new jersey prentice hall isbn 160 0 13 790395 2 pinker steven 1997 how the mind works new york ny w w norton amp company inc isbn 160 978 0 393 31848 7 preston john bishop mark eds 2002 views into the chinese room new essays on searle and artificial intelligence oxford university press isbn 160 978 0 19 825057 9 roberts jacob 2016 thinking machines the search for artificial intelligence distillations 2 2 14 23 archived from the original on 2018 08 19 retrieved 2018 03 22 saygin a p cicekli i akman v 2000 turing test 50 years later pdf minds and machines 10 4 463 518 doi 10 1023 a 1011288000451 hdl 11693 24987 s2cid 160 990084 archived from the original pdf on 2011 04 09 retrieved 2015 06 05 reprinted in moor 2003 pp 160 23 78 searle john 1980 minds brains and programs behavioral and brain sciences 3 3 417 457 doi 10 1017 s0140525x00005756 archived from the original on 2007 12 10 retrieved 2009 05 13 page numbers above refer to a standard pdf print of the article see also searle s original draft searle john 1983 can computers think in chalmers david ed philosophy of mind classical and contemporary readings oxford oxford university press pp 160 669 675 isbn 160 978 0 19 514581 6 searle john 1984 minds brains and science the 1984 reith lectures harvard university press isbn 160 978 0 674 57631 5 paperback isbn 160 0 674 57633 0 searle john january 1990a is the brain s mind a computer program scientific american vol 160 262 no 160 1 pp 160 26 31 bibcode 1990sciam 262a 26s doi 10 1038 scientificamerican0190 26 pmid 160 2294583 searle john november 1990b is the brain a digital computer proceedings and addresses of the american philosophical association 64 3 21 37 doi 10 2307 3130074 jstor 160 3130074 archived from the original on 2012 11 14 searle john 1992 the rediscovery of the mind cambridge massachusetts m i t press isbn 160 978 0 262 26113 5 searle john 1999 mind language and society new york ny basic books isbn 160 978 0 465 04521 1 oclc 160 231867665 searle john november 1 2004 mind a brief introduction oxford university press inc isbn 160 978 0 19 515733 8 searle john 2002 consciousness and language cambridge university press p 160 16 isbn 160 978 0521597449 searle john 2009 chinese room argument scholarpedia 4 8 3100 bibcode 2009schpj 4 3100s doi 10 4249 scholarpedia 3100 turing alan october 1950 computing machinery and intelligence mind lix 236 433 460 doi 10 1093 mind lix 236 433 issn 160 0026 4423 page numbers above refer to a standard pdf print of the article whitmarsh patrick 2016 imagine you re a machine narrative systems in peter watts s blindsight and echopraxia science fiction studies 43 2 237 259 doi 10 5621 sciefictstud 43 2 0237 yee richard 1993 turing machines and semantic symbol processing why real computers don t mind chinese emperors pdf lyceum 5 1 37 59 page numbers above and diagram contents refer to the lyceum pdf print of the article further reading edit wikibooks has a book on the topic of consciousness studies general presentations of the argument 160 chinese room argument internet encyclopedia of philosophy the chinese room argument stanford encyclopedia of philosophy understanding the chinese room mark rosenfelder sources involving john searle 160 chinese room argument by john searle on scholarpedia the chinese room argument part 4 of the september 2 1999 interview with searle philosophy and the habits of critical thinking in the conversations with history series john r searle what your computer can t know review of luciano floridi the fourth revolution how the infosphere is reshaping human reality oxford university press 2014 and nick bostrom superintelligence paths dangers strategies oxford university press 2014 the new york review of books vol lxi no 15 october 9 2014 pp 160 52 55 criticism of the argument 160 a refutation of john searle s chinese room argument archived 2010 02 03 at the wayback machine by bob murphy kugel p 2004 the chinese room is a trick behavioral and brain sciences 27 doi 10 1017 s0140525x04210044 s2cid 160 56032408 pdf at author s homepage critical paper based on the assumption that the cr cannot use its inputs which are in chinese to change its program which is in english wolfram schmied 2004 demolishing searle s chinese room arxiv cs ai 0403009 john preston and mark bishop views into the chinese room oxford university press 2002 includes chapters by john searle roger penrose stevan harnad and kevin warwick margaret boden escaping from the chinese room cognitive science research papers no csrp 092 university of sussex school of cognitive sciences 1987 oclc 160 19297071 online pdf an excerpt from a chapter in the then unpublished computer models of mind 160 computational approaches in theoretical psychology isbn 160 0 521 24868 x 1988 reprinted in boden ed the philosophy of artificial intelligence isbn 160 0 19 824854 7 1989 and isbn 160 0 19 824855 5 1990 boden artificial intelligence in psychology interdisciplinary essays isbn 160 0 262 02285 0 mit press 1989 chapter 6 reprinted in heil pp 160 253 266 1988 possibly abridged j heil ed philosophy of mind a guide and anthology oxford university press 2004 pages 253 266 same version as in artificial intelligence in psychology vtephilosophy of mindphilosophers anscombe austin aquinas bain bergson bhattacharya block brentano broad burge chalmers churchland dennett dharmakirti davidson descartes goldman heidegger husserl feyerabend fodor james kierkegaard leibniz lewis mcdowell merleau ponty minsky moore nagel parfit putnam popper rorty ryle searle spinoza turing vasubandhu wittgenstein zhuangzi more theories behaviorism biological naturalism dualism eliminative materialism emergent materialism epiphenomenalism functionalism idealism interactionism materialism monism na ve realism neurophenomenology neutral monism occasionalism parallelism phenomenalism phenomenology physicalism identity theory property dualism representational solipsism substance dualism concepts abstract object artificial intelligence chinese room cognition cognitive closure concept concept and object consciousness hard problem of consciousness hypostatic abstraction idea identity ingenuity intelligence intentionality introspection intuition language of thought materialism mental event mental image mental process mental property mental representation mind mind body problem new mysterianism pain problem of other minds propositional attitude qualia tabula rasa understanding zombie more related metaphysics philosophy of artificial intelligence 160 32 information 160 32 perception 160 32 self category philosophers category project task force authority control national libraries germany retrieved from https en wikipedia org w index php title chinese room amp oldid 1128489116 categories philosophy of artificial intelligencephilosophical argumentsthought experiments in philosophy of mindhidden categories wikipedia articles needing page number citations from february 2012wikipedia articles needing page number citations from january 2019wikipedia articles needing page number citations from february 2011articles with short descriptionshort description is different from wikidatause mdy dates from september 2020all articles with unsourced statementsarticles with unsourced statements from november 2020all articles with specifically marked weasel worded phrasesarticles with specifically marked weasel worded phrases from march 2011articles with internet encyclopedia of philosophy linkswebarchive template wayback linksarticles with gnd identifiers 