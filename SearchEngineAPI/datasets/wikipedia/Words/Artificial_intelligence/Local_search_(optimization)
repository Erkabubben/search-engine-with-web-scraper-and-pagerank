local search optimization from wikipedia the free encyclopedia jump to navigation jump to search this article includes a list of general references but it lacks sufficient corresponding inline citations please help to improve this article by introducing more precise citations may 2015 learn how and when to remove this template message in computer science local search is a heuristic method for solving computationally hard optimization problems local search can be used on problems that can be formulated as finding a solution maximizing a criterion among a number of candidate solutions local search algorithms move from solution to solution in the space of candidate solutions the search space by applying local changes until a solution deemed optimal is found or a time bound is elapsed local search algorithms are widely applied to numerous hard computational problems including problems from computer science particularly artificial intelligence mathematics operations research engineering and bioinformatics examples of local search algorithms are walksat the 2 opt algorithm for the traveling salesman problem and the metropolis hastings algorithm 91 1 93 contents 1 examples 2 description 3 see also 3 1 real valued search spaces 4 references 5 bibliography examples edit some problems where local search has been applied are the vertex cover problem in which a solution is a vertex cover of a graph and the target is to find a solution with a minimal number of nodes the traveling salesman problem in which a solution is a cycle containing all nodes of the graph and the target is to minimize the total length of the cycle the boolean satisfiability problem in which a candidate solution is a truth assignment and the target is to maximize the number of clauses satisfied by the assignment in this case the final solution is of use only if it satisfies all clauses the nurse scheduling problem where a solution is an assignment of nurses to shifts which satisfies all established constraints the k medoid clustering problem and other related facility location problems for which local search offers the best known approximation ratios from a worst case perspective the hopfield neural networks problem for which finding stable configurations in hopfield network description edit most problems can be formulated in terms of a search space and target in several different manners for example for the traveling salesman problem a solution can be a route visiting all cities and the goal is to find the shortest route but a solution can also be a path and being a cycle is part of the target a local search algorithm starts from a candidate solution and then iteratively moves to a neighbor solution a neighborhood being the set of all potential solutions that differ from the current solution by the minimal possible extent this requires a neighborhood relation to be defined on the search space as an example the neighborhood of vertex cover is another vertex cover only differing by one node for boolean satisfiability the neighbors of a boolean assignment are those that have a single variable in an opposite state the same problem may have multiple distinct neighborhoods defined on it local optimization with neighborhoods that involve changing up to k components of the solution is often referred to as k opt typically every candidate solution has more than one neighbor solution the choice of which one to select is taken using only information about the solutions in the neighborhood of the current assignment hence the name local search when the choice of the neighbor solution is done by taking the one locally maximizing the criterion i e a greedy search the metaheuristic takes the name hill climbing when no improving neighbors are present local search is stuck at a locally optimal point this local optima problem can be cured by using restarts repeated local search with different initial conditions randomization or more complex schemes based on iterations like iterated local search on memory like reactive search optimization on memory less stochastic modifications like simulated annealing local search does not provide a guarantee that any given solution is optimal the search can terminate after a given time bound or when the best solution found thus far has not improved in a given number of steps local search is an anytime algorithm it can return a valid solution even if it s interrupted at any time after finding the first valid solution local search is typically an approximation or incomplete algorithm because the search may stop even if the current best solution found is not optimal this can happen even if termination happens because the current best solution could not be improved as the optimal solution can lie far from the neighborhood of the solutions crossed by the algorithm schuurman amp southey propose three measures of effectiveness for local search depth mobility and coverage 91 2 93 depth the cost of the current best solution mobility the ability to rapidly move to different areas of the search space whilst keeping the cost low coverage how systematically the search covers the search space the maximum distance between any unexplored assignment and all visited assignments they hypothesize that local search algorithms work well not because they have some understanding of the search space but because they quickly move to promising regions and explore the search space at low depths as quickly broadly and systematically as possible see also edit local search is a sub field of metaheuristics stochastic optimization optimization fields within local search include hill climbing simulated annealing suited for either local or global search tabu search late acceptance hill climbing reactive search optimization combining machine learning and local search heuristics real valued search spaces edit several methods exist for performing local search of real valued search spaces luus jaakola searches locally using a uniform distribution and an exponentially decreasing search range random optimization searches locally using a normal distribution random search searches locally by sampling a hypersphere surrounding the current position pattern search takes steps along the axes of the search space using exponentially decreasing step sizes references edit 12localsearch key pdf d schuurmans and f southey local search characteristics of in complete sat procedures ai j 132 2 121 150 2001 bibliography edit battiti roberto mauro brunato franco mascia 2008 reactive search and intelligent optimization springer verlag isbn 160 978 0 387 09623 0 archived from the original on 2012 03 16 hoos h h and stutzle t 2005 stochastic local search foundations and applications morgan kaufmann vijay arya and naveen garg and rohit khandekar and adam meyerson and kamesh munagala and vinayaka pandit 2004 local search heuristics for k median and facility location problems siam journal of computing 33 3 juraj hromkovi algorithmics for hard problems introduction to combinatorial optimization randomization approximation and heuristics springer wil michiels emile aarts jan korst theoretical aspects of local search springer vtemajor subfields of optimization convex programming integer programming quadratic programming nonlinear programming stochastic programming robust optimization combinatorial optimization infinite dimensional optimization metaheuristics constraint satisfaction multiobjective optimization simulated annealing retrieved from https en wikipedia org w index php title local search optimization amp oldid 1101424577 categories metaheuristicsoptimization algorithms and methodshidden categories articles lacking in text citations from may 2015all articles lacking in text citations 