ethics of artificial intelligence from wikipedia the free encyclopedia jump to navigation jump to search ethical issues specific to ai part of a series onartificial intelligence major goals artificial general intelligence planning computer vision general game playing knowledge reasoning machine learning natural language processing robotics approaches symbolic deep learning bayesian networks evolutionary algorithms philosophy chinese room friendly ai control problem takeover ethics existential risk turing test history timeline progress ai winter technology applications projects programming languages glossary glossary vte the ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems 91 1 93 it is sometimes divided into a concern with the moral behavior of humans as they design make use and treat artificially intelligent systems and a concern with the behavior of machines in machine ethics it also includes the issue of a possible singularity due to superintelligent ai contents 1 ethics fields approaches 1 1 robot ethics 1 2 machine ethics 1 3 ethics principles of artificial intelligence 1 3 1 transparency accountability and open source 2 ethical challenges 2 1 biases in ai systems 2 2 robot rights 2 3 threat to human dignity 2 4 liability for self driving cars 2 5 weaponization of artificial intelligence 2 6 opaque algorithms 3 singularity 4 actors in ai ethics 4 1 intergovernmental initiatives 4 2 governmental initiatives 4 3 academic initiatives 4 4 private organizations 5 role and impact of fiction 5 1 history 5 2 impact on technological development 5 3 tv series 5 4 future visions in fiction and games 6 see also 7 notes 8 external links ethics fields approaches edit robot ethics edit main article robot ethics the term robot ethics sometimes roboethics refers to the morality of how humans design construct use and treat robots 91 2 93 robot ethics intersect with the ethics of ai robots are physical machines whereas ai can be only software 91 3 93 not all robots function through ai systems and not all ai systems are robots robot ethics considers how machines may be used to harm or benefit humans their impact on individual autonomy and their effects on social justice machine ethics edit main article machine ethics machine ethics or machine morality is the field of research concerned with designing artificial moral agents amas robots or artificially intelligent computers that behave morally or as though moral 91 4 93 91 5 93 91 6 93 91 7 93 to account for the nature of these agents it has been suggested to consider certain philosophical ideas like the standard characterizations of agency rational agency moral agency and artificial agency which are related to the concept of amas 91 8 93 isaac asimov considered the issue in the 1950s in his i robot at the insistence of his editor john w campbell jr he proposed the three laws of robotics to govern artificially intelligent systems much of his work was then spent testing the boundaries of his three laws to see where they would break down or where they would create paradoxical or unanticipated behavior his work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances 91 9 93 more recently academics and many governments have challenged the idea that ai can itself be held accountable 91 10 93 a panel convened by the united kingdom in 2010 revised asimov s laws to clarify that ai is the responsibility either of its manufacturers or of its owner operator 91 11 93 in 2009 during an experiment at the laboratory of intelligent systems in the ecole polytechnique f d rale of lausanne switzerland robots that were programmed to cooperate with each other in searching out a beneficial resource and avoiding a poisonous one eventually learned to lie to each other in an attempt to hoard the beneficial resource 91 12 93 some experts and academics have questioned the use of robots for military combat especially when such robots are given some degree of autonomous functions 91 13 93 the us navy has funded a report which indicates that as military robots become more complex there should be greater attention to implications of their ability to make autonomous decisions 91 14 93 91 15 93 the president of the association for the advancement of artificial intelligence has commissioned a study to look at this issue 91 16 93 they point to programs like the language acquisition device which can emulate human interaction vernor vinge has suggested that a moment may come when some computers are smarter than humans he calls this the singularity 91 17 93 he suggests that it may be somewhat or possibly very dangerous for humans 91 18 93 this is discussed by a philosophy called singularitarianism the machine intelligence research institute has suggested a need to build friendly ai meaning that the advances which are already occurring with ai should also include an effort to make ai intrinsically friendly and humane 91 19 93 there are discussion on creating tests to see if an ai is capable of making ethical decisions alan winfield concludes that the turing test is flawed and the requirement for an ai to pass the test is too low 91 20 93 a proposed alternative test is one called the ethical turing test which would improve on the current test by having multiple judges decide if the ai s decision is ethical or unethical 91 20 93 in 2009 academics and technical experts attended a conference organized by the association for the advancement of artificial intelligence to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self sufficient and able to make their own decisions they discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy and to what degree they could use such abilities to possibly pose any threat or hazard they noted that some machines have acquired various forms of semi autonomy including being able to find power sources on their own and being able to independently choose targets to attack with weapons they also noted that some computer viruses can evade elimination and have achieved cockroach intelligence they noted that self awareness as depicted in science fiction is probably unlikely but that there were other potential hazards and pitfalls 91 17 93 however there is one technology in particular that could truly bring the possibility of robots with moral competence to reality in a paper on the acquisition of moral values by robots nayef al rodhan mentions the case of neuromorphic chips which aim to process information similarly to humans nonlinearly and with millions of interconnected artificial neurons 91 21 93 robots embedded with neuromorphic technology could learn and develop knowledge in a uniquely humanlike way inevitably this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit or if they end up developing human weaknesses as well selfishness a pro survival attitude hesitation etc in moral machines teaching robots right from wrong 91 22 93 wendell wallach and colin allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern normative theory and by providing a platform for experimental investigation as one example it has introduced normative ethicists to the controversial issue of which specific learning algorithms to use in machines nick bostrom and eliezer yudkowsky have argued for decision trees such as id3 over neural networks and genetic algorithms on the grounds that decision trees obey modern social norms of transparency and predictability e g stare decisis 91 23 93 while chris santos lang argued in the opposite direction on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal hackers 91 24 93 according to a 2019 report from the center for the governance of ai at the university of oxford 82 of americans believe that robots and ai should be carefully managed concerns cited ranged from how ai is used in surveillance and in spreading fake content online known as deep fakes when they include doctored video images and audio generated with help from ai to cyberattacks infringements on data privacy hiring bias autonomous vehicles and drones that do not require a human controller 91 25 93 ethics principles of artificial intelligence edit in the review of 84 91 26 93 ethics guidelines for ai 11 clusters of principles were found transparency justice and fairness non maleficence responsibility privacy beneficence freedom and autonomy trust sustainability dignity solidarity 91 26 93 luciano floridi and josh cowls created an ethical framework of ai principles set by four principles of bioethics beneficence non maleficence autonomy and justice and an additional ai enabling principle explicability 91 27 93 transparency accountability and open source edit bill hibbard argues that because ai will have such a profound effect on humanity ai developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts 91 28 93 ben goertzel and david hart created opencog as an open source framework for ai development 91 29 93 openai is a non profit ai research company created by elon musk sam altman and others to develop open source ai beneficial to humanity 91 30 93 there are numerous other open source ai developments unfortunately making code open source does not make it comprehensible which by many definitions means that the ai code is not transparent the ieee has a standardisation effort on ai transparency 91 31 93 the ieee effort identifies multiple scales of transparency for different users further there is concern that releasing the full capacity of contemporary ai to some organizations may be a public bad that is do more damage than good for example microsoft has expressed concern about allowing universal access to its face recognition software even for those who can pay for it microsoft posted an extraordinary blog on this topic asking for government regulation to help determine the right thing to do 91 32 93 not only companies but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency and through it human accountability this strategy has proven controversial as some worry that it will slow the rate of innovation others argue that regulation leads to systemic stability more able to support innovation in the long term 91 33 93 the oecd un eu and many countries are presently working on strategies for regulating ai and finding appropriate legal frameworks 91 34 93 91 35 93 91 36 93 on june 26 2019 the european commission high level expert group on artificial intelligence ai hleg published its policy and investment recommendations for trustworthy artificial intelligence 91 37 93 this is the ai hleg s second deliverable after the april 2019 publication of the ethics guidelines for trustworthy ai the june ai hleg recommendations cover four principal subjects humans and society at large research and academia the private sector and the public sector the european commission claims that hleg s recommendations reflect an appreciation of both the opportunities for ai technologies to drive economic growth prosperity and innovation as well as the potential risks involved and states that the eu aims to lead on the framing of policies governing ai internationally 91 38 93 to prevent harm in addition to regulation ai deploying organizations need to play a central role in creating and deploying trustworthy ai in line with the principles of trustworthy ai and take accountability to mitigate the risks 91 39 93 ethical challenges edit biases in ai systems edit main article algorithmic bias then us senator kamala harris speaking about racial bias in artificial intelligence in 2020 ai has become increasingly inherent in facial and voice recognition systems some of these systems have real business applications and directly impact people these systems are vulnerable to biases and errors introduced by its human creators also the data used to train these ai systems itself can have biases 91 40 93 91 41 93 91 42 93 91 43 93 for instance facial recognition algorithms made by microsoft ibm and face all had biases when it came to detecting people s gender 91 44 93 these ai systems were able to detect gender of white men more accurately than gender of darker skin men further a 2020 study reviewed voice recognition systems from amazon apple google ibm and microsoft found that they have higher error rates when transcribing black people s voices than white people s 91 45 93 furthermore amazon terminated their use of ai hiring and recruitment because the algorithm favored male candidates over female ones this was because amazon s system was trained with data collected over 10 year period that came mostly from male candidates 91 46 93 bias can creep into algorithms in many ways the most predominant view on how bias is introduced into ai systems is that it is embedded within the historical data used to train the system for instance amazon s ai powered recruitment tool was trained with its own recruitment data accumulated over the years during which time the candidates that successfully got the job were mostly white males consequently the algorithms learned the biased pattern from the historical data and generated predictions for the present future that these types of candidates are mostly like to succeed in getting the job therefore the recruitment decisions made by the ai system turn out to be biased against female and minority candidates friedman and nissenbaum identify three categories of bias in computer systems existing bias technical bias and emergent bias 91 47 93 in natural language processing problems can arise from the text corpus the source material the algorithm uses to learn about the relationships between different words 91 48 93 large companies such as ibm google etc have made efforts to research and address these biases 91 49 93 91 50 93 91 51 93 one solution for addressing bias is to create documentation for the data used to train ai systems 91 52 93 91 53 93 process mining can be an important tool for organizations to achieve compliance with proposed ai regulations by identifying errors monitoring processes identifying potential root causes for improper execution and other functions 91 54 93 the problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law and as more people without a deep technical understanding are tasked with deploying it some experts warn that algorithmic bias is already pervasive in many industries and that almost no one is making an effort to identify or correct it 91 55 93 there are some open sourced tools 91 56 93 by civil societies that are looking to bring more awareness to biased ai robot rights edit robot rights is the concept that people should have moral obligations towards their machines akin to human rights or animal rights 91 57 93 it has been suggested that robot rights such as a right to exist and perform its own mission could be linked to robot duty to serve humanity analogous to linking human rights with human duties before society 91 58 93 these could include the right to life and liberty freedom of thought and expression and equality before the law 91 59 93 the issue has been considered by the institute for the future 91 60 93 and by the u k department of trade and industry 91 61 93 experts disagree on how soon specific and detailed laws on the subject will be necessary 91 61 93 glenn mcgee reported that sufficiently humanoid robots might appear by 2020 91 62 93 while ray kurzweil sets the date at 2029 91 63 93 another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist 91 64 93 the rules for the 2003 loebner prize competition envisioned the possibility of robots having rights of their own 61 if in any given year a publicly available open source entry entered by the university of surrey or the cambridge center wins the silver medal or the gold medal then the medal and the cash award will be awarded to the body responsible for the development of that entry if no such body can be identified or if there is disagreement among two or more claimants the medal and the cash award will be held in trust until such time as the entry may legally possess either in the united states of america or in the venue of the contest the cash award and gold medal in its own right 91 65 93 in october 2017 the android sophia was granted honorary citizenship in saudi arabia though some considered this to be more of a publicity stunt than a meaningful legal recognition 91 66 93 some saw this gesture as openly denigrating of human rights and the rule of law 91 67 93 the philosophy of sentientism grants degrees of moral consideration to all sentient beings primarily humans and most non human animals if artificial or alien intelligence show evidence of being sentient this philosophy holds that they should be shown compassion and granted rights joanna bryson has argued that creating ai that requires rights is both avoidable and would in itself be unethical both as a burden to the ai agents and to human society 91 68 93 threat to human dignity edit main article computer power and human reason joseph weizenbaum 91 69 93 argued in 1976 that ai technology should not be used to replace people in positions that require respect and care such as a customer service representative ai technology is already used today for telephone based interactive voice response systems a nursemaid for the elderly as was reported by pamela mccorduck in her book the fifth generation a soldier a judge a police officer a therapist as was proposed by kenneth colby in the 70s weizenbaum explains that we require authentic feelings of empathy from people in these positions if machines replace them we will find ourselves alienated devalued and frustrated for the artificially intelligent system would not be able to simulate empathy artificial intelligence if used in this way represents a threat to human dignity weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an atrophy of the human spirit that comes from thinking of ourselves as computers 91 70 93 pamela mccorduck counters that speaking for women and minorities i d rather take my chances with an impartial computer pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all 91 70 93 however kaplan and haenlein stress that ai systems are only as smart as the data used to train them since they are in their essence nothing more than fancy curve fitting machines using ai to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and engrained which makes them even more difficult to spot and fight against 91 71 93 weizenbaum was also bothered that ai researchers and some philosophers were willing to view the human mind as nothing more than a computer program a position now known as computationalism to weizenbaum these points suggest that ai research devalues human life 91 69 93 ai founder john mccarthy objects to the moralizing tone of weizenbaum s critique when moralizing is both vehement and vague it invites authoritarian abuse he writes bill hibbard 91 72 93 writes that human dignity requires that we strive to remove our ignorance of the nature of existence and ai is necessary for that striving liability for self driving cars edit main article self driving car liability as the widespread use of autonomous cars becomes increasingly imminent new challenges raised by fully autonomous vehicles must be addressed 91 73 93 91 74 93 recently 91 when 93 there has been debate as to the legal liability of the responsible party if these cars get into accidents 91 75 93 91 76 93 in one report where a driverless car hit a pedestrian the driver was inside the car but the controls were fully in the hand of computers this led to a dilemma over who was at fault for the accident 91 77 93 in another incident on march 18 2018 elaine herzberg was struck and killed by a self driving uber in arizona in this case the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway but it could not anticipate a pedestrian in the middle of the road this raised the question of whether the driver pedestrian the car company or the government should be held responsible for her death 91 78 93 currently self driving cars are considered semi autonomous requiring the driver to pay attention and be prepared to take control if necessary 91 79 93 91 failed verification 93 thus it falls on governments to regulate the driver who over relies on autonomous features as well educate them that these are just technologies that while convenient are not a complete substitute before autonomous cars become widely used these issues need to be tackled through new policies 91 80 93 91 81 93 91 82 93 weaponization of artificial intelligence edit main article lethal autonomous weapon some experts and academics have questioned the use of robots for military combat especially when such robots are given some degree of autonomy 91 13 93 91 83 93 on october 31 2019 the united states department of defense s defense innovation board published the draft of a report recommending principles for the ethical use of artificial intelligence by the department of defense that would ensure a human operator would always be able to look into the black box and understand the kill chain process however a major concern is how the report will be implemented 91 84 93 the us navy has funded a report which indicates that as military robots become more complex there should be greater attention to implications of their ability to make autonomous decisions 91 85 93 91 15 93 some researchers state that autonomous robots might be more humane as they could make decisions more effectively 91 86 93 within this last decade there has been intensive research in autonomous power with the ability to learn using assigned moral responsibilities the results may be used when designing future military robots to control unwanted tendencies to assign responsibility to the robots 91 87 93 from a consequentialist view there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a set moral framework that the ai cannot override 91 88 93 there has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of a robot takeover of mankind ai weapons do present a type of danger different from that of human controlled weapons many governments have begun to fund programs to develop ai weaponry the united states navy recently announced plans to develop autonomous drone weapons paralleling similar announcements by russia and korea respectively due to the potential of ai weapons becoming more dangerous than human operated weapons stephen hawking and max tegmark signed a future of life petition 91 89 93 to ban ai weapons the message posted by hawking and tegmark states that ai weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future 91 90 93 if any major military power pushes ahead with the ai weapon development a global arms race is virtually inevitable and the endpoint of this technological trajectory is obvious autonomous weapons will become the kalashnikovs of tomorrow says the petition which includes skype co founder jaan tallinn and mit professor of linguistics noam chomsky as additional supporters against ai weaponry 91 91 93 physicist and astronomer royal sir martin rees has warned of catastrophic instances like dumb robots going rogue or a network that develops a mind of its own huw price a colleague of rees at cambridge has voiced a similar warning that humans might not survive when intelligence escapes the constraints of biology these two professors created the centre for the study of existential risk at cambridge university in the hope of avoiding this threat to human existence 91 90 93 regarding the potential for smarter than human systems to be employed militarily the open philanthropy project writes that these scenarios seem potentially as important as the risks related to loss of control but research investigating ai s long run social impact have spent relatively little time on this concern this class of scenarios has not been a major focus for the organizations that have been most active in this space such as the machine intelligence research institute miri and the future of humanity institute fhi and there seems to have been less analysis and debate regarding them 91 92 93 opaque algorithms edit approaches like machine learning with neural networks can result in computers making decisions that they and the humans who programmed them cannot explain it is difficult for people to determine if such decisions are fair and trustworthy leading potentially to bias in ai systems going undetected or people rejecting the use of such systems this has led to advocacy and in some jurisdictions legal requirements for explainable artificial intelligence 91 93 93 singularity edit further information existential risk from artificial general intelligence superintelligence and technological singularity many researchers have argued that by way of an intelligence explosion a self improving ai could become so powerful that humans would not be able to stop it from achieving its goals 91 94 93 in his paper ethical issues in advanced artificial intelligence and subsequent book superintelligence paths dangers strategies philosopher nick bostrom argues that artificial intelligence has the capability to bring about human extinction he claims that general superintelligence would be capable of independent initiative and of making its own plans and may therefore be more appropriately thought of as an autonomous agent since artificial intellects need not share our human motivational tendencies it would be up to the designers of the superintelligence to specify its original motivations because a superintelligent ai would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals many uncontrolled unintended consequences could arise it could kill off all other agents persuade them to change their behavior or block their attempts at interference 91 95 93 however instead of overwhelming the human race and leading to our destruction bostrom has also asserted that superintelligence can help us solve many difficult problems such as disease poverty and environmental destruction and could help us to enhance ourselves 91 96 93 the sheer complexity of human value systems makes it very difficult to make ai s motivations human friendly 91 94 93 91 95 93 unless moral philosophy provides us with a flawless ethical theory an ai s utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not common sense according to eliezer yudkowsky there is little reason to suppose that an artificially designed mind would have such an adaptation 91 97 93 ai researchers such as stuart j russell 91 98 93 bill hibbard 91 72 93 roman yampolskiy 91 99 93 shannon vallor 91 100 93 steven umbrello 91 101 93 and luciano floridi 91 102 93 have proposed design strategies for developing beneficial machines actors in ai ethics edit there are many organisations concerned with ai ethics and policy public and governmental as well as corporate and societal amazon google facebook ibm and microsoft have established a non profit the partnership on ai to benefit people and society to formulate best practices on artificial intelligence technologies advance the public s understanding and to serve as a platform about artificial intelligence apple joined in january 2017 the corporate members will make financial and research contributions to the group while engaging with the scientific community to bring academics onto the board 91 103 93 the ieee put together a global initiative on ethics of autonomous and intelligent systems which has been creating and revising guidelines with the help of public input and accepts as members many professionals from within and without its organization traditionally government has been used by societies to ensure ethics are observed through legislation and policing there are now many efforts by national governments as well as transnational government and non government organizations to ensure ai is ethically applied intergovernmental initiatives edit the european commission has a high level expert group on artificial intelligence on 8 april 2019 this published its ethics guidelines for trustworthy artificial intelligence 91 104 93 the european commission also has a robotics and artificial intelligence innovation and excellence unit which published a white paper on excellence and trust in artificial intelligence innovation on 19 february 2020 91 105 93 the oecd established an oecd ai policy observatory 91 106 93 governmental initiatives edit in the united states the obama administration put together a roadmap for ai policy 91 107 93 the obama administration released two prominent white papers on the future and impact of ai in 2019 the white house through an executive memo known as the american ai initiative instructed nist the national institute of standards and technology to begin work on federal engagement of ai standards february 2019 91 108 93 in january 2020 in the united states the trump administration released a draft executive order issued by the office of management and budget omb on guidance for regulation of artificial intelligence applications omb ai memorandum the order emphasizes the need to invest in ai applications boost public trust in ai reduce barriers for usage of ai and keep american ai technology competitive in a global market there is a nod to the need for privacy concerns but no further detail on enforcement the advances of american ai technology seems to be the focus and priority additionally federal entities are even encouraged to use the order to circumnavigate any state laws and regulations that a market might see as too onerous to fulfill 91 109 93 the computing community consortium ccc weighed in with a 100 plus page draft report 91 110 93 a 20 year community roadmap for artificial intelligence research in the us 91 111 93 the center for security and emerging technology advises us policymakers on the security implications of emerging technologies such as ai the non human party is running for election in new south wales with policies around granting rights to robots animals and generally non human entities whose intelligence has been overlooked 91 112 93 in russia the first ever russian codex of ethics of artificial intelligence for business was signed in 2021 it was driven by analytical center for the government of the russian federation together with major commercial and academic institutions such as sberbank yandex rosatom higher school of economics moscow institute of physics and technology itmo university nanosemantics rostelecom cian and others 91 113 93 academic initiatives edit there are three research institutes at the university of oxford that are centrally focused on ai ethics the future of humanity institute that focuses both on ai safety 91 114 93 and the governance of ai 91 115 93 the institute for ethics in ai directed by john tasioulas whose primary goal among others is to promote ai ethics as a field proper in comparison to related applied ethics fields the oxford internet institute directed by luciano floridi focuses on the ethics of near term ai technologies and icts 91 116 93 the ai now institute at nyu is a research institute studying the social implications of artificial intelligence its interdisciplinary research focuses on the themes bias and inclusion labour and automation rights and liberties and safety and civil infrastructure 91 117 93 the institute for ethics and emerging technologies ieet researches the effects of ai on unemployment 91 118 93 91 119 93 and policy the institute for ethics in artificial intelligence ieai at the technical university of munich directed by christoph l tge conducts research across various domains such as mobility employment healthcare and sustainability 91 120 93 private organizations edit algorithmic justice league 91 121 93 black in ai 91 122 93 data for black lives 91 123 93 queer in ai 91 122 93 role and impact of fiction edit main article artificial intelligence in fiction the role of fiction with regards to ai ethics has been a complex one one can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics historically fiction has been prefiguring common tropes that have not only influenced goals and visions for ai but also outlined ethical questions and common fears associated with it during the second half of the twentieth and the first decades of the twenty first century popular culture in particular movies tv series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning ai and robotics recently these themes have also been increasingly treated in literature beyond the realm of science fiction and as carme torras research professor at the institut de rob tica i inform tica industrial institute of robotics and industrial computing at the technical university of catalonia notes 91 124 93 in higher education science fiction is also increasingly used for teaching technology related ethical issues in technological degrees history edit historically speaking the investigation of moral and ethical implications of thinking machines goes back at least to the enlightenment leibniz already poses the question if we might attribute intelligence to a mechanism that behaves as if it were a sentient being 91 125 93 and so does descartes who describes what could be considered an early version of the turing test 91 126 93 the romantic period has several times envisioned artificial creatures that escape the control of their creator with dire consequences most famously in mary shelley s frankenstein the widespread preoccupation with industrialization and mechanization in the 19th and early 20th century however brought ethical implications of unhinged technical developments to the forefront of fiction r u r rossum s universal robots karel apek s play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term robot derived from the czech word for forced labor robota but was also an international success after it premiered in 1921 george bernard shaw s play back to methuselah published in 1921 questions at one point the validity of thinking machines that act like humans fritz lang s 1927 film metropolis shows an android leading the uprising of the exploited masses against the oppressive regime of a technocratic society impact on technological development edit while the anticipation of a future dominated by potentially indomitable technology has fueled the imagination of writers and film makers for a long time one question has been less frequently analyzed namely to what extent fiction has played a role in providing inspiration for technological development it has been documented for instance that the young alan turing saw and appreciated g b shaw s play back to methuselah in 1933 91 127 93 just 3 years before the publication of his first seminal paper 91 128 93 which laid the groundwork for the digital computer and he would likely have been at least aware of plays like r u r which was an international success and translated into many languages one might also ask the question which role science fiction played in establishing the tenets and ethical implications of ai development isaac asimov conceptualized his three laws of robotics in the 1942 short story runaround part of the short story collection i robot arthur c clarke s short the sentinel on which stanley kubrick s film 2001 a space odyssey is based was written in 1948 and published in 1952 another example among many others would be philip k dicks numerous short stories and novels in particular do androids dream of electric sheep published in 1968 and featuring its own version of a turing test the voight kampff test to gauge emotional responses of androids indistinguishable from humans the novel later became the basis of the influential 1982 movie blade runner by ridley scott science fiction has been grappling with ethical implications of ai developments for decades and thus provided a blueprint for ethical issues that might emerge once something akin to general artificial intelligence has been achieved spike jonze s 2013 film her shows what can happen if a user falls in love with the seductive voice of his smartphone operating system ex machina on the other hand asks a more difficult question if confronted with a clearly recognizable machine made only human by a face and an empathetic and sensual voice would we still be able to establish an emotional connection still be seduced by it the film echoes a theme already present two centuries earlier in the 1817 short story the sandmann by e t a hoffmann the theme of coexistence with artificial sentient beings is also the theme of two recent novels machines like me by ian mcewan published in 2019 involves among many other things a love triangle involving an artificial person as well as a human couple klara and the sun by nobel prize winner kazuo ishiguro published in 2021 is the first person account of klara an af artificial friend who is trying in her own way to help the girl she is living with who after having been lifted i e having been subjected to genetic enhancements is suffering from a strange illness tv series edit while ethical questions linked to ai have been featured in science fiction literature and feature films for decades the emergence of the tv series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology the swedish series real humans 2012 2013 tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society the british dystopian science fiction anthology series black mirror 2013 2019 was particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments both the french series osmosis 2020 and british series the one deal with the question of what can happen if technology tries to find the ideal partner for a person several episodes of the netflix series love death robots have imagined scenes of robots and humans living together the most representative one of them is s02 e01 it shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives 91 129 93 future visions in fiction and games edit the movie the thirteenth floor suggests a future where simulated worlds with sentient inhabitants are created by computer game consoles for the purpose of entertainment the movie the matrix suggests a future where the dominant species on planet earth are sentient machines and humanity is treated with utmost speciesism the short story the planck dive suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non sentient the same idea can be found in the emergency medical hologram of starship voyager which is an apparently sentient copy of a reduced subset of the consciousness of its creator dr zimmerman who for the best motives has created the system to give medical assistance in case of emergencies the movies bicentennial man and a i deal with the possibility of sentient robots that could love i robot explored some aspects of asimov s three laws all these scenarios try to foresee possibly unethical consequences of the creation of sentient computers 91 130 93 the ethics of artificial intelligence is one of several core themes in bioware s mass effect series of games 91 131 93 it explores the scenario of a civilization accidentally creating ai through a rapid increase in computational power through a global scale neural network this event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them beyond the initial conflict the complexity of the relationship between the machines and their creators is another ongoing theme throughout the story detroit become human is one of the most famous video games which discusses the ethics of artificial intelligence recently quantic dream designed the chapters of the game using interactive storylines to give players a more immersive gaming experience players manipulate three different awakened bionic people in the face of different events to make different choices to achieve the purpose of changing the human view of the bionic group and different choices will result in different endings this is one of the few games that puts players in the bionic perspective which allows them to better consider the rights and interests of robots once a true artificial intelligence is created 91 132 93 over time debates have tended to focus less and less on possibility and more on desirability 91 133 93 as emphasized in the cosmist and terran debates initiated by hugo de garis and kevin warwick a cosmist according to hugo de garis is actually seeking to build more intelligent successors to the human species experts at the university of cambridge have argued that ai is portrayed in fiction and nonfiction overwhelmingly as racially white in ways that distort perceptions of its risks and benefits 91 134 93 see also edit ai takeover artificial consciousness artificial general intelligence agi computer ethics effective altruism the long term future and global catastrophic risks existential risk from artificial general intelligence human compatible philosophy of artificial intelligence regulation of artificial intelligence robotic governance superintelligence paths dangers strategies researchers timnit gebru joy buolamwini deb raji ruha benjamin safiya noble margaret mitchell meredith whittaker alison adam seth baum nick bostrom joanna bryson kate crawford kate darling luciano floridi anja kaspersen michael kearns ray kurzweil catherine malabou ajung moon vincent c m ller peter norvig steve omohundro stuart j russell anders sandberg mariarosaria taddeo john tasioulas roman yampolskiy eliezer yudkowsky emily m bender organisations center for human compatible artificial intelligence center for security and emerging technology centre for the study of existential risk future of humanity institute future of life institute machine intelligence research institute partnership on ai leverhulme centre for the future of intelligence institute for ethics and emerging technologies oxford internet institute notes edit m ller vincent c 30 april 2020 ethics of artificial intelligence and robotics stanford encyclopedia of philosophy archived from the original on 10 october 2020 retrieved 26 september 2020 veruggio gianmarco 2011 the roboethics roadmap euron roboethics atelier scuola di robotica 2 citeseerx 160 10 1 1 466 2810 m ller vincent c 2020 ethics of artificial intelligence and robotics in zalta edward n ed the stanford encyclopedia of philosophy winter 2020 160 ed metaphysics research lab stanford university retrieved 2021 03 18 anderson machine ethics archived from the original on 28 september 2011 retrieved 27 june 2011 anderson michael anderson susan leigh eds july 2011 machine ethics cambridge university press isbn 160 978 0 521 11235 2 anderson m anderson s l july 2006 guest editors introduction machine ethics ieee intelligent systems 21 4 10 11 doi 10 1109 mis 2006 70 s2cid 160 9570832 anderson michael anderson susan leigh 15 december 2007 machine ethics creating an ethical intelligent agent ai magazine 28 4 15 doi 10 1609 aimag v28i4 2065 s2cid 160 17033332 boyles robert james m 2017 philosophical signposts for artificial moral agent frameworks suri 6 2 92 109 asimov isaac 2008 i robot new york bantam isbn 160 978 0 553 38256 3 bryson joanna diamantis mihailis grant thomas september 2017 of for and by the people the legal lacuna of synthetic persons artificial intelligence and law 25 3 273 291 doi 10 1007 s10506 017 9214 9 principles of robotics uk s epsrc september 2010 archived from the original on 1 april 2018 retrieved 10 january 2019 evolving robots learn to lie to each other archived 2009 08 28 at the wayback machine popular science august 18 2009 a b call for debate on killer robots archived 2009 08 07 at the wayback machine by jason palmer science and technology reporter bbc news 8 3 09 science new navy funded report warns of war robots going terminator archived 2009 07 28 at the wayback machine by jason mick blog dailytech com february 17 2009 a b navy report warns of robot uprising suggests a strong moral compass archived 2011 06 04 at the wayback machine by joseph l flatley engadget com feb 18th 2009 aaai presidential panel on long term ai futures 2008 2009 study archived 2009 08 28 at the wayback machine association for the advancement of artificial intelligence accessed 7 26 09 a b markoff john 25 july 2009 scientists worry machines may outsmart man the new york times archived from the original on 25 february 2017 retrieved 24 february 2017 the coming technological singularity how to survive in the post human era archived 2007 01 01 at the wayback machine by vernor vinge department of mathematical sciences san diego state university c 1993 by vernor vinge article at asimovlaws com archived may 24 2012 at the wayback machine july 2004 accessed 7 27 09 a b winfield a f michael k pitt j evers v march 2019 machine ethics the design and governance of ethical ai and autonomous systems 91 scanning the issue 93 proceedings of the ieee 107 3 509 517 doi 10 1109 jproc 2019 2900622 issn 160 1558 2256 s2cid 160 77393713 archived from the original on 2020 11 02 retrieved 2020 11 21 al rodhan nayef 7 december 2015 the moral code archived from the original on 2017 03 05 retrieved 2017 03 04 wallach wendell allen colin november 2008 moral machines teaching robots right from wrong usa oxford university press isbn 160 978 0 19 537404 9 bostrom nick yudkowsky eliezer 2011 the ethics of artificial intelligence pdf cambridge handbook of artificial intelligence cambridge press archived pdf from the original on 2016 03 04 retrieved 2011 06 22 santos lang chris 2002 ethics for artificial intelligences archived from the original on 2014 12 25 retrieved 2015 01 04 howard ayanna the regulation of ai should organizations be worried ayanna howard mit sloan management review archived from the original on 2019 08 14 retrieved 2019 08 14 a b jobin anna ienca marcello vayena effy 2 september 2020 the global landscape of ai ethics guidelines nature 1 9 389 399 arxiv 1906 11668 doi 10 1038 s42256 019 0088 2 s2cid 160 201827642 floridi luciano cowls josh 2 july 2019 a unified framework of five principles for ai in society harvard data science review 1 doi 10 1162 99608f92 8cd550d1 s2cid 160 198775713 open source ai archived 2016 03 04 at the wayback machine bill hibbard 2008 proceedings of the first conference on artificial general intelligence eds pei wang ben goertzel and stan franklin opencog a software framework for integrative artificial general intelligence archived 2016 03 04 at the wayback machine david hart and ben goertzel 2008 proceedings of the first conference on artificial general intelligence eds pei wang ben goertzel and stan franklin inside openai elon musk s wild plan to set artificial intelligence free archived 2016 04 27 at the wayback machine cade metz wired 27 april 2016 p7001 transparency of autonomous systems p7001 transparency of autonomous systems ieee archived from the original on 10 january 2019 retrieved 10 january 2019 thurm scott july 13 2018 microsoft calls for federal regulation of facial recognition wired archived from the original on may 9 2019 retrieved january 10 2019 bastin roland wantz georges june 2017 the general data protection regulation cross industry innovation pdf inside magazine deloitte archived pdf from the original on 2019 01 10 retrieved 2019 01 10 un artificial intelligence summit aims to tackle poverty humanity s grand challenges un news 2017 06 07 archived from the original on 2019 07 26 retrieved 2019 07 26 artificial intelligence organisation for economic co operation and development www oecd org archived from the original on 2019 07 22 retrieved 2019 07 26 anonymous 2018 06 14 the european ai alliance digital single market european commission archived from the original on 2019 08 01 retrieved 2019 07 26 european commission high level expert group on ai 2019 06 26 policy and investment recommendations for trustworthy artificial intelligence shaping europe s digital future european commission archived from the original on 2020 02 26 retrieved 2020 03 16 eu tech policy brief july 2019 recap center for democracy amp technology archived from the original on 2019 08 09 retrieved 2019 08 09 curtis caitlin gillespie nicole lockey steven 2022 05 24 ai deploying organizations are key to addressing perfect storm of ai risks ai and ethics 1 9 doi 10 1007 s43681 022 00163 7 issn 160 2730 5961 pmc 160 9127285 pmid 160 35634256 gabriel iason 2018 03 14 the case for fairer algorithms iason gabriel medium archived from the original on 2019 07 22 retrieved 2019 07 22 5 unexpected sources of bias in artificial intelligence techcrunch 10 december 2016 archived from the original on 2021 03 18 retrieved 2019 07 22 knight will google s ai chief says forget elon musk s killer robots and worry about bias in ai systems instead mit technology review archived from the original on 2019 07 04 retrieved 2019 07 22 villasenor john 2019 01 03 artificial intelligence and bias four key challenges brookings archived from the original on 2019 07 22 retrieved 2019 07 22 lohr steve 9 february 2018 facial recognition is accurate if you re a white guy the new york times archived from the original on 9 january 2019 retrieved 29 may 2019 koenecke allison nam andrew lake emily nudell joe quartey minnie mengesha zion toups connor rickford john r jurafsky dan goel sharad 7 april 2020 racial disparities in automated speech recognition proceedings of the national academy of sciences 117 14 7684 7689 bibcode 2020pnas 117 7684k doi 10 1073 pnas 1915768117 pmc 160 7149386 pmid 160 32205437 amazon scraps secret ai recruiting tool that showed bias against women reuters 2018 10 10 archived from the original on 2019 05 27 retrieved 2019 05 29 friedman batya nissenbaum helen july 1996 bias in computer systems acm transactions on information systems 14 3 330 347 doi 10 1145 230538 230561 s2cid 160 207195759 eliminating bias in ai techxplore com archived from the original on 2019 07 25 retrieved 2019 07 26 olson parmy google s deepmind has an idea for stopping biased ai forbes retrieved 2019 07 26 machine learning fairness ml fairness google developers archived from the original on 2019 08 10 retrieved 2019 07 26 ai and bias ibm research us www research ibm com archived from the original on 2019 07 17 retrieved 2019 07 26 bender emily m friedman batya december 2018 data statements for natural language processing toward mitigating system bias and enabling better science transactions of the association for computational linguistics 6 587 604 doi 10 1162 tacl a 00041 gebru timnit morgenstern jamie vecchione briana vaughan jennifer wortman wallach hanna daum iii hal crawford kate 2018 datasheets for datasets arxiv 1803 09010 cs db pery andrew 2021 10 06 trustworthy artificial intelligence and process mining challenges and opportunities deepai retrieved 2022 02 18 knight will google s ai chief says forget elon musk s killer robots and worry about bias in ai systems instead mit technology review archived from the original on 2019 07 04 retrieved 2019 07 26 where in the world is ai responsible amp unethical ai examples archived from the original on 2020 10 31 retrieved 2020 10 28 evans woody 2015 posthuman rights dimensions of transhuman worlds teknokultura 12 2 doi 10 5209 rev tk 2015 v12 n2 49072 sheliazhenko yurii 2017 artificial personal autonomy and concept of robot rights european journal of law and political sciences 17 21 doi 10 20534 ejlps 17 1 17 21 archived from the original on 14 july 2018 retrieved 10 may 2017 the american heritage dictionary of the english language fourth edition robots could demand legal rights bbc news december 21 2006 archived from the original on october 15 2019 retrieved january 3 2010 a b henderson mark april 24 2007 human rights for robots we re getting carried away the times online the times of london archived from the original on may 17 2008 retrieved may 2 2010 mcgee glenn a robot code of ethics the scientist archived from the original on 2020 09 06 retrieved 2019 03 25 kurzweil ray 2005 the singularity is near penguin books isbn 160 978 0 670 03384 3 the big question should the human race be worried by the rise of robots independent newspaper loebner prize contest official rules version 2 0 archived 2016 03 03 at the wayback machine the competition was directed by david hamill and the rules were developed by members of the robitron yahoo group saudi arabia bestows citizenship on a robot named sophia 26 october 2017 archived from the original on 2017 10 27 retrieved 2017 10 27 vincent james 30 october 2017 pretending to give a robot citizenship helps no one the verge archived from the original on 3 august 2019 retrieved 10 january 2019 wilks yorick ed 2010 close engagements with artificial companions key social psychological ethical and design issues amsterdam john benjamins pub co isbn 160 978 9027249944 oclc 160 642206106 a b weizenbaum joseph 1976 computer power and human reason san francisco w h freeman amp company isbn 160 978 0 7167 0464 5 mccorduck pamela 2004 machines who think 2nd 160 ed natick ma a k peters ltd isbn 160 1 56881 205 1 pp 132 144 a b joseph weizenbaum quoted in mccorduck 2004 pp 160 356 374 376 kaplan andreas haenlein michael january 2019 siri siri in my hand who s the fairest in the land on the interpretations illustrations and implications of artificial intelligence business horizons 62 1 15 25 doi 10 1016 j bushor 2018 08 004 s2cid 160 158433736 a b hibbard bill 17 november 2015 ethical artificial intelligence arxiv 1411 1373 cs ai davies alex 29 february 2016 google s self driving car caused its first crash wired archived from the original on 7 july 2019 retrieved 26 july 2019 levin sam wong julia carrie 19 march 2018 self driving uber kills arizona woman in first fatal crash involving pedestrian the guardian archived from the original on 26 july 2019 retrieved 26 july 2019 who is responsible when a self driving car has an accident futurism archived from the original on 2019 07 26 retrieved 2019 07 26 radio business policy law and public podcasts america north autonomous car crashes who or what is to blame knowledge wharton archived from the original on 2019 07 26 retrieved 2019 07 26 cite web 124 last2 has generic name help delbridge emily driverless cars gone wild the balance archived from the original on 2019 05 29 retrieved 2019 05 29 stilgoe jack 2020 who killed elaine herzberg who s driving innovation cham springer international publishing pp 160 1 6 doi 10 1007 978 3 030 32320 2 1 isbn 160 978 3 030 32319 6 s2cid 160 214359377 archived from the original on 2021 03 18 retrieved 2020 11 11 maxmen amy october 2018 self driving car dilemmas reveal that moral choices are not universal nature 562 7728 469 470 bibcode 2018natur 562 469m doi 10 1038 d41586 018 07135 0 pmid 160 30356197 regulations for driverless cars gov uk archived from the original on 2019 07 26 retrieved 2019 07 26 automated driving legislative and regulatory action cyberwiki cyberlaw stanford edu archived from the original on 2019 07 26 retrieved 2019 07 26 autonomous vehicles self driving vehicles enacted legislation www ncsl org archived from the original on 2019 07 26 retrieved 2019 07 26 robot three way portends autonomous future archived 2012 11 07 at the wayback machine by david axe wired com august 13 2009 united states defense innovation board ai principles recommendations on the ethical use of artificial intelligence by the department of defense oclc 160 1126650738 new navy funded report warns of war robots going terminator archived 2009 07 28 at the wayback machine by jason mick blog dailytech com february 17 2009 umbrello steven torres phil de bellis angelo f march 2020 the future of war could lethal autonomous weapons make conflict more ethical ai amp society 35 1 273 282 doi 10 1007 s00146 019 00879 x hdl 2318 1699364 issn 160 0951 5666 s2cid 160 59606353 archived from the original on 2021 01 05 retrieved 2020 11 11 hellstr m thomas june 2013 on the moral responsibility of military robots ethics and information technology 15 2 99 107 doi 10 1007 s10676 012 9301 2 s2cid 160 15205810 proquest 160 1372020233 mitra ambarish 5 april 2018 we can train ai to identify good and evil and then use it to teach us morality quartz archived from the original on 2019 07 26 retrieved 2019 07 26 ai principles future of life institute 11 august 2017 archived from the original on 2017 12 11 retrieved 2019 07 26 a b zach musgrave and bryan w roberts 2015 08 14 why artificial intelligence can too easily be weaponized the atlantic the atlantic archived from the original on 2017 04 11 retrieved 2017 03 06 cat zakrzewski 2015 07 27 musk hawking warn of artificial intelligence weapons wsj archived from the original on 2015 07 28 retrieved 2017 08 04 givewell 2015 potential risks from advanced artificial intelligence report archived from the original on 12 october 2015 retrieved 11 october 2015 inside the mind of a i cliff kuang interview a b muehlhauser luke and louie helm 2012 intelligence explosion and machine ethics archived 2015 05 07 at the wayback machine in singularity hypotheses a scientific and philosophical assessment edited by amnon eden johnny s raker james h moor and eric steinhart berlin springer a b bostrom nick 2003 ethical issues in advanced artificial intelligence archived 2018 10 08 at the wayback machine in cognitive emotive and ethical aspects of decision making in humans and in artificial intelligence edited by iva smit and george e lasker 12 17 vol 2 windsor on international institute for advanced studies in systems research cybernetics umbrello steven baum seth d 2018 06 01 evaluating future nanotechnology the net societal impacts of atomically precise manufacturing futures 100 63 73 doi 10 1016 j futures 2018 04 007 hdl 2318 1685533 issn 160 0016 3287 s2cid 160 158503813 archived from the original on 2019 05 09 retrieved 2020 11 29 yudkowsky eliezer 2011 complex value systems in friendly ai archived 2015 09 29 at the wayback machine in schmidhuber th risson and looks 2011 388 393 russell stuart october 8 2019 human compatible artificial intelligence and the problem of control united states viking isbn 160 978 0 525 55861 3 oclc 160 1083694322 yampolskiy roman v 2020 03 01 unpredictability of ai on the impossibility of accurately predicting all actions of a smarter agent journal of artificial intelligence and consciousness 07 1 109 118 doi 10 1142 s2705078520500034 issn 160 2705 0785 s2cid 160 218916769 archived from the original on 2021 03 18 retrieved 2020 11 29 wallach wendell vallor shannon 2020 09 17 moral machines from value alignment to embodied virtue ethics of artificial intelligence oxford university press pp 160 383 412 doi 10 1093 oso 9780190905033 003 0014 isbn 160 978 0 19 090503 3 archived from the original on 2020 12 08 retrieved 2020 11 29 umbrello steven 2019 beneficial artificial intelligence coordination by means of a value sensitive design approach big data and cognitive computing 3 1 5 doi 10 3390 bdcc3010005 floridi luciano cowls josh king thomas c taddeo mariarosaria 2020 how to design ai for social good seven essential factors science and engineering ethics 26 3 1771 1796 doi 10 1007 s11948 020 00213 5 issn 160 1353 3452 pmc 160 7286860 pmid 160 32246245 fiegerman seth 28 september 2016 facebook google amazon create group to ease ai concerns cnnmoney ethics guidelines for trustworthy ai shaping europe s digital future european commission european commission 2019 04 08 archived from the original on 2020 02 20 retrieved 2020 02 20 white paper on artificial intelligence a european approach to excellence and trust 124 shaping europe s digital future oecd ai policy observatory the obama administration s roadmap for ai policy harvard business review 2016 12 21 issn 160 0017 8012 archived from the original on 2021 01 22 retrieved 2021 03 16 accelerating america s leadership in artificial intelligence the white house trumpwhitehouse archives gov archived from the original on 2021 02 25 retrieved 2021 03 16 request for comments on a draft memorandum to the heads of executive departments and agencies guidance for regulation of artificial intelligence applications federal register 2020 01 13 archived from the original on 2020 11 25 retrieved 2020 11 28 ccc offers draft 20 year ai roadmap seeks comments hpcwire 2019 05 14 archived from the original on 2021 03 18 retrieved 2019 07 22 request comments on draft a 20 year community roadmap for ai research in the us 160 ccc blog 13 may 2019 archived from the original on 2019 05 14 retrieved 2019 07 22 non human party 2021 in russian kommersant 25 11 2021 grace katja salvatier john dafoe allan zhang baobao evans owain 2018 05 03 when will ai exceed human performance evidence from ai experts arxiv 1705 08807 cs ai china wants to shape the global future of artificial intelligence mit technology review archived from the original on 2020 11 20 retrieved 2020 11 29 floridi luciano cowls josh beltrametti monica chatila raja chazerand patrice dignum virginia luetge christoph madelin robert pagallo ugo rossi francesca schafer burkhard 2018 12 01 ai4people an ethical framework for a good ai society opportunities risks principles and recommendations minds and machines 28 4 689 707 doi 10 1007 s11023 018 9482 5 issn 160 1572 8641 pmc 160 6404626 pmid 160 30930541 new artificial intelligence research institute launches 2017 11 20 archived from the original on 2020 09 18 retrieved 2021 02 21 hughes james j lagrandeur kevin eds 15 march 2017 surviving the machine age intelligent technology and the transformation of human work cham switzerland isbn 160 978 3 319 51165 8 oclc 160 976407024 archived from the original on 18 march 2021 retrieved 29 november 2020 danaher john 2019 automation and utopia human flourishing in a world without work cambridge massachusetts isbn 160 978 0 674 24220 3 oclc 160 1114334813 tum institute for ethics in artificial intelligence officially opened www tum de archived from the original on 2020 12 10 retrieved 2020 11 29 lee jennifer 8 2020 02 08 when bias is coded into our technology npr retrieved 2021 12 22 a b how one conference embraced diversity nature 564 7735 161 162 2018 12 12 doi 10 1038 d41586 018 07718 x pmid 160 31123357 s2cid 160 54481549 roose kevin 2020 12 30 the 2020 good tech awards the new york times issn 160 0362 4331 retrieved 2021 12 21 torras carme 2020 science fiction a mirror for the future of humankind in idees centre d estudis de temes contemporanis cetc barcelona https revistaidees cat en science fiction favors engaging debate on artificial intelligence and ethics retrieved on 2021 06 10 gottfried wilhelm leibniz 1714 monadology 17 mill argument see also lodge p 2014 leibniz s mill argument against mechanical materialism revisited in ergo volume 1 no 03 https quod lib umich edu e ergo 12405314 0001 003 leibniz s mill argument against mechanical materialism rgn main view fulltext retrieved on 2021 06 10 cited in bringsjord selmer and naveen sundar govindarajulu artificial intelligence the stanford encyclopedia of philosophy summer 2020 edition edward n zalta ed url lt https plato stanford edu archives sum2020 entries artificial intelligence gt retrieved on 2021 06 10 hodges a 2014 alan turing the enigma vintage london p 334 a m turing 1936 on computable numbers with an application to the entscheidungsproblem in proceedings of the london mathematical society 2 s vol 42 1936 1937 pp 230 265 love death amp robots season 2 episode 1 recap automated customer service ready steady cut 2021 05 14 retrieved 2021 12 21 cave stephen dihal kanta dillon sarah eds 14 february 2020 ai narratives a history of imaginative thinking about intelligent machines first 160 ed oxford isbn 160 978 0 19 258604 9 oclc 160 1143647559 archived from the original on 18 march 2021 retrieved 11 november 2020 jerreat poole adam 1 february 2020 sick slow cyborg crip futurity in mass effect game studies 20 issn 160 1604 7982 archived from the original on 9 december 2020 retrieved 11 november 2020 detroit become human will challenge your morals and your humanity coffee or die magazine 2018 08 06 retrieved 2021 12 07 cerqui daniela warwick kevin 2008 re designing humankind the rise of cyborgs a desirable goal philosophy and design dordrecht springer netherlands pp 160 185 195 doi 10 1007 978 1 4020 6591 0 14 isbn 160 978 1 4020 6590 3 archived from the original on 2021 03 18 retrieved 2020 11 11 cave stephen dihal kanta 6 august 2020 the whiteness of ai philosophy amp technology 33 4 685 703 doi 10 1007 s13347 020 00415 6 s2cid 160 225466550 external links edit ethics of artificial intelligence at the internet encyclopedia of philosophy ethics of artificial intelligence and robotics at the stanford encyclopedia of philosophy russell s hauert s altman r veloso m may 2015 robotics ethics of artificial intelligence nature 521 7553 415 418 bibcode 2015natur 521 415 doi 10 1038 521415a pmid 160 26017428 s2cid 160 4452826 bbc news games to take on a life of their own who s afraid of robots archived 2018 03 22 at the wayback machine an article on humanity s fear of artificial intelligence a short history of computer ethics ai ethics guidelines global inventory by algorithmwatch hagendorff thilo march 2020 the ethics of ai ethics an evaluation of guidelines minds and machines 30 1 99 120 doi 10 1007 s11023 020 09517 8 s2cid 160 72940833 vteethicsnormative ethics consequentialism utilitarianism deontology kantian ethics ethics of care existentialist ethics particularism pragmatic ethics role ethics virtue ethics eudaimonia applied ethics animal ethics bioethics business ethics discourse ethics engineering ethics environmental ethics legal ethics machine ethics media ethics medical ethics nursing ethics professional ethics sexual ethics ethics of artificial intelligence ethics of eating meat ethics of technology ethics of terraforming ethics of uncertain sentience meta ethics cognitivism moral realism ethical naturalism ethical non naturalism ethical subjectivism ideal observer theory divine command theory error theory non cognitivism emotivism expressivism quasi realism universal prescriptivism moral universalism value monism value pluralism moral constructivism moral relativism moral nihilism moral rationalism ethical intuitionism moral skepticism concepts index autonomy axiology conscience consent equality free will good and evil good evil happiness ideal immorality justice liberty morality norm freedom suffering or pain stewardship sympathy trust value virtue wrong ethicist philosophers laozi socrates plato aristotle diogenes valluvar cicero confucius augustine of hippo mencius mozi xunzi thomas aquinas baruch spinoza david hume immanuel kant georg w f hegel arthur schopenhauer jeremy bentham john stuart mill s ren kierkegaard henry sidgwick friedrich nietzsche g e moore karl barth paul tillich dietrich bonhoeffer philippa foot john rawls john dewey bernard williams j l mackie g e m anscombe william frankena alasdair macintyre r m hare peter singer derek parfit thomas nagel robert merrihew adams charles taylor joxe azurmendi christine korsgaard martha nussbaum related articles casuistry christian ethics descriptive ethics ethics in religion evolutionary ethics feminist ethics history of ethics ideology islamic ethics jewish ethics moral psychology philosophy of law political philosophy population ethics social philosophy suffering focused ethics category vteexistential risk from artificial intelligenceconcepts ai alignment ai capability control ai takeover accelerating change existential risk from artificial general intelligence friendly artificial intelligence instrumental convergence intelligence explosion machine ethics superintelligence technological singularity organizations allen institute for ai center for applied rationality center for human compatible artificial intelligence centre for the study of existential risk deepmind foundational questions institute future of humanity institute future of life institute humanity institute for ethics and emerging technologies leverhulme centre for the future of intelligence machine intelligence research institute openai people scott alexander nick bostrom eric drexler sam harris stephen hawking bill hibbard bill joy elon musk steve omohundro huw price martin rees stuart j russell jaan tallinn max tegmark frank wilczek roman yampolskiy andrew yang eliezer yudkowsky other artificial intelligence as a global catastrophic risk controversies and dangers of artificial general intelligence ethics of artificial intelligence suffering risks human compatible open letter on artificial intelligence our final invention the precipice superintelligence paths dangers strategies do you trust this computer category vtephilosophy of scienceconcepts analysis analytic synthetic distinction a priori and a posteriori causality commensurability consilience construct creative synthesis demarcation problem empirical evidence explanatory power fact falsifiability feminist method functional contextualism ignoramus et ignorabimus inductive reasoning intertheoretic reduction inquiry nature objectivity observation paradigm problem of induction scientific law scientific method scientific pluralism scientific revolution scientific theory testability theory choice theory ladenness underdetermination unity of science metatheoryof science coherentism confirmation holism constructive empiricism constructive realism constructivist epistemology contextualism conventionalism deductive nomological model hypothetico deductive model inductionism epistemological anarchism evolutionism fallibilism foundationalism instrumentalism pragmatism model dependent realism naturalism physicalism positivism 160 32 reductionism 160 32 determinism rationalism 160 32 empiricism received view 160 32 semantic view of theories scientific realism 160 32 anti realism scientific essentialism scientific formalism scientific skepticism scientism structuralism uniformitarianism vitalism philosophy of physics thermal and statistical motion chemistry biology geography social science technology engineering artificial intelligence computer science information mind psychiatry psychology perception space and time related topics alchemy criticism of science descriptive science epistemology faith and rationality hard and soft science history and philosophy of science history of science history of evolutionary thought logic metaphysics normative science pseudoscience relationship between religion and science rhetoric of science science studies sociology of scientific knowledge sociology of scientific ignorance philosophers of science by eraancient plato aristotle stoicism epicureans epicurus medieval averroes avicenna roger bacon william of ockham hugh of saint victor dominicus gundissalinus robert kilwardby early modern francis bacon thomas hobbes ren descartes galileo galilei pierre gassendi isaac newton david hume late modern immanuel kant friedrich schelling william whewell auguste comte john stuart mill herbert spencer wilhelm wundt charles sanders peirce wilhelm windelband henri poincar pierre duhem rudolf steiner karl pearson contemporary alfred north whitehead bertrand russell albert einstein otto neurath c d broad michael polanyi hans reichenbach rudolf carnap karl popper carl gustav hempel w v o quine thomas kuhn imre lakatos paul feyerabend j rgen habermas ian hacking bas van fraassen larry laudan daniel dennett category 160 philosophy 32 portal 160 science 32 portal retrieved from https en wikipedia org w index php title ethics of artificial intelligence amp oldid 1128163100 categories philosophy of artificial intelligenceethics of science and technologyregulation of robotshidden categories webarchive template wayback linkscs1 errors generic namearticles with russian language sources ru articles with short descriptionshort description is different from wikidataall articles with vague or ambiguous timevague or ambiguous time from november 2020all articles with failed verificationarticles with failed verification from november 2020 