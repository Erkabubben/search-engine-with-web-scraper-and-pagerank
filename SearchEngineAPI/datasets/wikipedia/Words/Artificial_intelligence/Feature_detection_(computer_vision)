feature computer vision from wikipedia the free encyclopedia redirected from feature detection computer vision jump to navigation jump to search piece of information about the content of an image feature detection edge detection canny deriche differential sobel prewitt roberts cross corner detection harris operator shi and tomasi level curve curvature hessian feature strength measures susan fast blob detection laplacian of gaussian log difference of gaussians dog determinant of hessian doh maximally stable extremal regions pcbr ridge detection hough transform hough transform generalized hough transform structure tensor structure tensor generalized structure tensor affine invariant feature detection affine shape adaptation harris affine hessian affine feature description sift surf gloh hog scale space scale space axioms implementation details pyramids vte in computer vision and image processing a feature is a piece of information about the content of an image typically about whether a certain region of the image has certain properties features may be specific structures in the image such as points edges or objects features may also be the result of a general neighborhood operation or feature detection applied to the image other examples of features are related to motion in image sequences or to shapes defined in terms of curves or boundaries between different image regions more broadly a feature is any piece of information which is relevant for solving the computational task related to a certain application this is the same sense as feature in machine learning and pattern recognition generally though image processing has a very sophisticated collection of features the feature concept is very general and the choice of features in a particular computer vision system may be highly dependent on the specific problem at hand contents 1 definition 1 1 feature vectors and feature spaces 2 types 2 1 edges 2 2 corners interest points 2 3 blobs regions of interest points 2 4 ridges 3 detection 4 extraction 4 1 low level 4 1 1 curvature 4 1 2 image motion 4 2 shape based 4 3 flexible methods 5 representation 5 1 certainty or confidence 5 2 averageability 6 matching 7 see also 8 references 9 further reading definition edit there is no universal or exact definition of what constitutes a feature and the exact definition often depends on the problem or the type of application nevertheless a feature is typically defined as an interesting part of an image and features are used as a starting point for many computer vision algorithms since features are used as the starting point and main primitives for subsequent algorithms the overall algorithm will often only be as good as its feature detector consequently the desirable property for a feature detector is repeatability whether or not the same feature will be detected in two or more different images of the same scene feature detection is a low level image processing operation that is it is usually performed as the first operation on an image and examines every pixel to see if there is a feature present at that pixel if this is part of a larger algorithm then the algorithm will typically only examine the image in the region of the features as a built in pre requisite to feature detection the input image is usually smoothed by a gaussian kernel in a scale space representation and one or several feature images are computed often expressed in terms of local image derivative operations occasionally when feature detection is computationally expensive and there are time constraints a higher level algorithm may be used to guide the feature detection stage so that only certain parts of the image are searched for features there are many computer vision algorithms that use feature detection as the initial step so as a result a very large number of feature detectors have been developed these vary widely in the kinds of feature detected the computational complexity and the repeatability when features are defined in terms of local neighborhood operations applied to an image a procedure commonly referred to as feature extraction one can distinguish between feature detection approaches that produce local decisions whether there is a feature of a given type at a given image point or not and those who produce non binary data as result the distinction becomes relevant when the resulting detected features are relatively sparse although local decisions are made the output from a feature detection step does not need to be a binary image the result is often represented in terms of sets of connected or unconnected coordinates of the image points where features have been detected sometimes with subpixel accuracy when feature extraction is done without local decision making the result is often referred to as a feature image consequently a feature image can be seen as an image in the sense that it is a function of the same spatial or temporal variables as the original image but where the pixel values hold information about image features instead of intensity or color this means that a feature image can be processed in a similar way as an ordinary image generated by an image sensor feature images are also often computed as integrated step in algorithms for feature detection feature vectors and feature spaces edit in some applications it is not sufficient to extract only one type of feature to obtain the relevant information from the image data instead two or more different features are extracted resulting in two or more feature descriptors at each image point a common practice is to organize the information provided by all these descriptors as the elements of one single vector commonly referred to as a feature vector the set of all possible feature vectors constitutes a feature space 91 1 93 a common example of feature vectors appears when each image point is to be classified as belonging to a specific class assuming that each image point has a corresponding feature vector based on a suitable set of features meaning that each class is well separated in the corresponding feature space the classification of each image point can be done using standard classification method another and related example occurs when neural network based processing is applied to images the input data fed to the neural network is often given in terms of a feature vector from each image point where the vector is constructed from several different features extracted from the image data during a learning phase the network can itself find which combinations of different features are useful for solving the problem at hand types edit edges edit edges are points where there is a boundary or an edge between two image regions in general an edge can be of almost arbitrary shape and may include junctions in practice edges are usually defined as sets of points in the image which have a strong gradient magnitude furthermore some common algorithms will then chain high gradient points together to form a more complete description of an edge these algorithms usually place some constraints on the properties of an edge such as shape smoothness and gradient value locally edges have a one dimensional structure corners interest points edit the terms corners and interest points are used somewhat interchangeably and refer to point like features in an image which have a local two dimensional structure the name corner arose since early algorithms first performed edge detection and then analysed the edges to find rapid changes in direction corners these algorithms were then developed so that explicit edge detection was no longer required for instance by looking for high levels of curvature in the image gradient it was then noticed that the so called corners were also being detected on parts of the image which were not corners in the traditional sense for instance a small bright spot on a dark background may be detected these points are frequently known as interest points but the term corner is used by tradition 91 citation needed 93 blobs regions of interest points edit blobs provide a complementary description of image structures in terms of regions as opposed to corners that are more point like nevertheless blob descriptors may often contain a preferred point a local maximum of an operator response or a center of gravity which means that many blob detectors may also be regarded as interest point operators blob detectors can detect areas in an image which are too smooth to be detected by a corner detector consider shrinking an image and then performing corner detection the detector will respond to points which are sharp in the shrunk image but may be smooth in the original image it is at this point that the difference between a corner detector and a blob detector becomes somewhat vague to a large extent this distinction can be remedied by including an appropriate notion of scale nevertheless due to their response properties to different types of image structures at different scales the log and doh blob detectors are also mentioned in the article on corner detection ridges edit for elongated objects the notion of ridges is a natural tool a ridge descriptor computed from a grey level image can be seen as a generalization of a medial axis from a practical viewpoint a ridge can be thought of as a one dimensional curve that represents an axis of symmetry and in addition has an attribute of local ridge width associated with each ridge point unfortunately however it is algorithmically harder to extract ridge features from general classes of grey level images than edge corner or blob features nevertheless ridge descriptors are frequently used for road extraction in aerial images and for extracting blood vessels in medical images see ridge detection detection edit feature detection includes methods for computing abstractions of image information and making local decisions at every image point whether there is an image feature of a given type at that point or not the resulting features will be subsets of the image domain often in the form of isolated points continuous curves or connected regions the extraction of features are sometimes made over several scalings one of these methods is the scale invariant feature transform sift common feature detectors and their classification feature detector edge corner blob ridge canny 91 2 93 yes no no no sobel yes no no no harris amp stephens plessey 91 3 93 yes yes no no susan 91 4 93 yes yes no no shi amp tomasi 91 5 93 no yes no no level curve curvature 91 6 93 no yes no no fast 91 7 93 no yes yes no laplacian of gaussian 91 6 93 no yes yes no difference of gaussians 91 8 93 91 9 93 no yes yes no determinant of hessian 91 6 93 no yes yes no hessian strength feature measures 91 10 93 91 11 93 no yes yes no mser 91 12 93 no no yes no principal curvature ridges 91 13 93 91 14 93 91 15 93 no no no yes grey level blobs 91 16 93 no no yes no extraction edit for broader coverage of this topic see feature extraction machine learning once features have been detected a local image patch around the feature can be extracted this extraction may involve quite considerable amounts of image processing the result is known as a feature descriptor or feature vector among the approaches that are used to feature description one can mention n jets and local histograms see scale invariant feature transform for one example of a local histogram descriptor in addition to such attribute information the feature detection step by itself may also provide complementary attributes such as the edge orientation and gradient magnitude in edge detection and the polarity and the strength of the blob in blob detection low level edit edge detection corner detection blob detection ridge detection scale invariant feature transform curvature edit edge direction changing intensity autocorrelation image motion edit motion detection area based differential approach optical flow shape based edit thresholding blob extraction template matching hough transform lines circles ellipses arbitrary shapes generalized hough transform works with any parameterizable feature class variables cluster detection etc generalised hough transform flexible methods edit deformable parameterized shapes active contours snakes representation edit main article visual descriptor a specific image feature defined in terms of a specific structure in the image data can often be represented in different ways for example an edge can be represented as a boolean variable in each image point that describes whether an edge is present at that point alternatively we can instead use a representation which provides a certainty measure instead of a boolean statement of the edge s existence and combine this with information about the orientation of the edge similarly the color of a specific region can either be represented in terms of the average color three scalars or a color histogram three functions when a computer vision system or computer vision algorithm is designed the choice of feature representation can be a critical issue in some cases a higher level of detail in the description of a feature may be necessary for solving the problem but this comes at the cost of having to deal with more data and more demanding processing below some of the factors which are relevant for choosing a suitable representation are discussed in this discussion an instance of a feature representation is referred to as a feature descriptor or simply descriptor certainty or confidence edit two examples of image features are local edge orientation and local velocity in an image sequence in the case of orientation the value of this feature may be more or less undefined if more than one edge are present in the corresponding neighborhood local velocity is undefined if the corresponding image region does not contain any spatial variation as a consequence of this observation it may be relevant to use a feature representation which includes a measure of certainty or confidence related to the statement about the feature value otherwise it is a typical situation that the same descriptor is used to represent feature values of low certainty and feature values close to zero with a resulting ambiguity in the interpretation of this descriptor depending on the application such an ambiguity may or may not be acceptable in particular if a featured image will be used in subsequent processing it may be a good idea to employ a feature representation that includes information about certainty or confidence this enables a new feature descriptor to be computed from several descriptors for example computed at the same image point but at different scales or from different but neighboring points in terms of a weighted average where the weights are derived from the corresponding certainties in the simplest case the corresponding computation can be implemented as a low pass filtering of the featured image the resulting feature image will in general be more stable to noise averageability edit in addition to having certainty measures included in the representation the representation of the corresponding feature values may itself be suitable for an averaging operation or not most feature representations can be averaged in practice but only in certain cases can the resulting descriptor be given a correct interpretation in terms of a feature value such representations are referred to as averageable for example if the orientation of an edge is represented in terms of an angle this representation must have a discontinuity where the angle wraps from its maximal value to its minimal value consequently it can happen that two similar orientations are represented by angles which have a mean that does not lie close to either of the original angles and hence this representation is not averageable there are other representations of edge orientation such as the structure tensor which are averageable another example relates to motion where in some cases only the normal velocity relative to some edge can be extracted if two such features have been extracted and they can be assumed to refer to same true velocity this velocity is not given as the average of the normal velocity vectors hence normal velocity vectors are not averageable instead there are other representations of motions using matrices or tensors that give the true velocity in terms of an average operation of the normal velocity descriptors 91 citation needed 93 matching edit main article correspondence problem features detected in each image can be matched across multiple images to establish corresponding features such as corresponding points the algorithm is based on comparing and analyzing point correspondences between the reference image and the target image if any part of the cluttered scene shares correspondences greater than the threshold that part of the cluttered scene image is targeted and considered to include the reference object there 91 17 93 see also edit computer vision automatic image annotation feature learning feature selection foreground detection vectorization image tracing references edit scott e umbaugh 27 january 2005 computer imaging digital image analysis and processing crc press isbn 160 978 0 8493 2919 7 canny j 1986 a computational approach to edge detection ieee transactions on pattern analysis and machine intelligence 8 6 679 714 doi 10 1109 tpami 1986 4767851 pmid 160 21869365 s2cid 160 13284142 c harris m stephens 1988 a combined corner and edge detector pdf proceedings of the 4th alvey vision conference pp 160 147 151 s m smith j m brady may 1997 susan a new approach to low level image processing international journal of computer vision 23 1 45 78 doi 10 1023 a 1007963824710 s2cid 160 15033310 j shi c tomasi june 1994 good features to track 9th ieee conference on computer vision and pattern recognition springer a b c t lindeberg 1998 feature detection with automatic scale selection abstract international journal of computer vision 30 2 77 116 doi 10 1023 a 1008045108935 s2cid 160 723210 e rosten t drummond 2006 machine learning for high speed corner detection european conference on computer vision springer pp 160 430 443 citeseerx 160 10 1 1 60 3991 doi 10 1007 11744023 34 j l crowley and a c parker a representation for shape based on peaks and ridges in the difference of low pass transform 91 dead link 93 ieee transactions on pami pami 6 2 pp 160 156 170 march 1984 d lowe 2004 distinctive image features from scale invariant keypoints international journal of computer vision 60 2 91 citeseerx 160 10 1 1 73 2924 doi 10 1023 b visi 0000029664 99615 94 s2cid 160 221242327 t lindeberg scale selection properties of generalized scale space interest point detectors journal of mathematical imaging and vision volume 46 issue 2 pages 177 210 2013 t lindeberg image matching using generalized scale space interest points journal of mathematical imaging and vision volume 52 number 1 pages 3 36 2015 j matas o chum m urban t pajdla 2002 robust wide baseline stereo from maximally stable extremum regions pdf british machine vision conference pp 160 384 393 r haralick ridges and valleys on digital images computer vision graphics and image processing vol 22 no 10 pp 160 28 38 apr 1983 d eberly r gardner b morse s pizer c scharlach ridges for image analysis journal of mathematical imaging and vision v 160 4 n 160 4 pp 160 353 373 dec 1994 t lindeberg 1998 edge detection and ridge detection with automatic scale selection abstract international journal of computer vision 30 2 117 154 doi 10 1023 a 1008097225773 s2cid 160 207658261 t lindeberg 1993 detecting salient blob like image structures and their scales with a scale space primal sketch a method for focus of attention abstract international journal of computer vision 11 3 283 318 doi 10 1007 bf01469346 s2cid 160 11998035 object detection in a cluttered scene using point feature matching matlab amp simulink www mathworks com retrieved 2019 07 06 further reading edit t lindeberg 2009 scale space in benjamin wah ed encyclopedia of computer science and engineering vol 160 iv john wiley and sons pp 160 2495 2504 doi 10 1002 9780470050118 ecse609 isbn 160 978 0470050118 summary and review of a number of feature detectors formulated based on a scale space operations vtecomputer visioncategories datasets digital geometry commercial systems feature detection geometry image sensor technology learning morphology motion analysis noise reduction techniques recognition and categorization research infrastructure researchers segmentation software technologies computer stereo vision 3d reconstruction free viewpoint television motion capture applications3d reconstruction 3d reconstruction from multiple images 2d to 3d conversion shape from focus simultaneous localization and mapping structure from motion view synthesis 3d pose estimation activity recognition audio visual speech recognition automatic number plate recognition automated species identification augmented reality computer aided diagnosis eye tracking gesture recognition autonomous vehicles content based image retrieval face recognition optical character recognition pose tracking remote sensing robots video content analysis video trackingmain category retrieved from https en wikipedia org w index php title feature computer vision amp oldid 1126584442 detectors categories feature detection computer vision hidden categories all articles with dead external linksarticles with dead external links from june 2022articles with short descriptionshort description is different from wikidataall articles with unsourced statementsarticles with unsourced statements from may 2020articles with unsourced statements from january 2022 