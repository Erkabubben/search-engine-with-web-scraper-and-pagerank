statistical classification from wikipedia the free encyclopedia jump to navigation jump to search term in statistical classification in statistics classification is the problem of identifying which of a set of categories sub populations an observation or observations belongs to examples are assigning a given email to the spam or non spam class and assigning a diagnosis to a given patient based on observed characteristics of the patient sex blood pressure presence or absence of certain symptoms etc often the individual observations are analyzed into a set of quantifiable properties known variously as explanatory variables or features these properties may variously be categorical e g a b ab or o for blood type ordinal e g large medium or small integer valued e g the number of occurrences of a particular word in an email or real valued e g a measurement of blood pressure other classifiers work by comparing observations to previous observations by means of a similarity or distance function an algorithm that implements classification especially in a concrete implementation is known as a classifier the term classifier sometimes also refers to the mathematical function implemented by a classification algorithm that maps input data to a category terminology across fields is quite varied in statistics where classification is often done with logistic regression or a similar procedure the properties of observations are termed explanatory variables or independent variables regressors etc and the categories to be predicted are known as outcomes which are considered to be possible values of the dependent variable in machine learning the observations are often known as instances the explanatory variables are termed features grouped into a feature vector and the possible categories to be predicted are classes other fields may use different terminology e g in community ecology the term classification normally refers to cluster analysis contents 1 relation to other problems 2 frequentist procedures 3 bayesian procedures 4 binary and multiclass classification 5 feature vectors 6 linear classifiers 7 algorithms 8 evaluation 9 application domains 10 see also 11 references relation to other problems edit classification and clustering are examples of the more general problem of pattern recognition which is the assignment of some sort of output value to a given input value other examples are regression which assigns a real valued output to each input sequence labeling which assigns a class to each member of a sequence of values for example part of speech tagging which assigns a part of speech to each word in an input sentence parsing which assigns a parse tree to an input sentence describing the syntactic structure of the sentence etc a common subclass of classification is probabilistic classification algorithms of this nature use statistical inference to find the best class for a given instance unlike other algorithms which simply output a best class probabilistic algorithms output a probability of the instance being a member of each of the possible classes the best class is normally then selected as the one with the highest probability however such an algorithm has numerous advantages over non probabilistic classifiers it can output a confidence value associated with its choice in general a classifier that can do this is known as a confidence weighted classifier correspondingly it can abstain when its confidence of choosing any particular output is too low because of the probabilities which are generated probabilistic classifiers can be more effectively incorporated into larger machine learning tasks in a way that partially or completely avoids the problem of error propagation frequentist procedures edit early work on statistical classification was undertaken by fisher 91 1 93 91 2 93 in the context of two group problems leading to fisher s linear discriminant function as the rule for assigning a group to a new observation 91 3 93 this early work assumed that data values within each of the two groups had a multivariate normal distribution the extension of this same context to more than two groups has also been considered with a restriction imposed that the classification rule should be linear 91 3 93 91 4 93 later work for the multivariate normal distribution allowed the classifier to be nonlinear 91 5 93 several classification rules can be derived based on different adjustments of the mahalanobis distance with a new observation being assigned to the group whose centre has the lowest adjusted distance from the observation bayesian procedures edit unlike frequentist procedures bayesian classification procedures provide a natural way of taking into account any available information about the relative sizes of the different groups within the overall population 91 6 93 bayesian procedures tend to be computationally expensive and in the days before markov chain monte carlo computations were developed approximations for bayesian clustering rules were devised 91 7 93 some bayesian procedures involve the calculation of group membership probabilities these provide a more informative outcome than a simple attribution of a single group label to each new observation binary and multiclass classification edit classification can be thought of as two separate problems binary classification and multiclass classification in binary classification a better understood task only two classes are involved whereas multiclass classification involves assigning an object to one of several classes 91 8 93 since many classification methods have been developed specifically for binary classification multiclass classification often requires the combined use of multiple binary classifiers feature vectors edit main article feature vector most algorithms describe an individual instance whose category is to be predicted using a feature vector of individual measurable properties of the instance each property is termed a feature also known in statistics as an explanatory variable or independent variable although features may or may not be statistically independent features may variously be binary e g on or off categorical e g a b ab or o for blood type ordinal e g large medium or small integer valued e g the number of occurrences of a particular word in an email or real valued e g a measurement of blood pressure if the instance is an image the feature values might correspond to the pixels of an image if the instance is a piece of text the feature values might be occurrence frequencies of different words some algorithms work only in terms of discrete data and require that real valued or integer valued data be discretized into groups e g less than 5 between 5 and 10 or greater than 10 linear classifiers edit main article linear classifier a large number of algorithms for classification can be phrased in terms of a linear function that assigns a score to each possible category k by combining the feature vector of an instance with a vector of weights using a dot product the predicted category is the one with the highest score this type of score function is known as a linear predictor function and has the following general form score x2061 x i k x03b2 k x22c5 x i displaystyle operatorname score mathbf x i k boldsymbol beta k cdot mathbf x i where xi is the feature vector for instance i k is the vector of weights corresponding to category k and score xi k is the score associated with assigning instance i to category k in discrete choice theory where instances represent people and categories represent choices the score is considered the utility associated with person i choosing category k algorithms with this basic setup are known as linear classifiers what distinguishes them is the procedure for determining training the optimal weights coefficients and the way that the score is interpreted examples of such algorithms include logistic regression 160 8211 statistical model for a binary dependent variable multinomial logistic regression 160 8211 regression for more than two discrete outcomes probit regression the perceptron algorithm support vector machine 160 8211 set of methods for supervised statistical learning linear discriminant analysis 160 8211 method used in statistics pattern recognition and other fields algorithms edit since no single form of classification is appropriate for all data sets a large toolkit of classification algorithms have been developed the most commonly used include 91 9 93 artificial neural networks boosting meta algorithm decision tree learning 160 8211 machine learning algorithm random forest 160 8211 binary search tree based ensemble machine learning method genetic programming 160 8211 technique whereby computer programs are encoded as a set of genes gene expression programming 160 8211 evolutionary algorithm multi expression programming linear genetic programming kernel estimation k nearest neighbor learning vector quantization linear classifier 160 8211 statistical classification in machine learning fisher s linear discriminant logistic regression 160 8211 statistical model for a binary dependent variable naive bayes classifier 160 8211 probabilistic classification algorithm perceptron 160 8211 algorithm for supervised learning of binary classifiers quadratic classifier support vector machine 160 8211 set of methods for supervised statistical learning least squares support vector machine evaluation edit classifier performance depends greatly on the characteristics of the data to be classified there is no single classifier that works best on all given problems a phenomenon that may be explained by the no free lunch theorem various empirical tests have been performed to compare classifier performance and to find the characteristics of data that determine classifier performance determining a suitable classifier for a given problem is however still more an art than a science the measures precision and recall are popular metrics used to evaluate the quality of a classification system more recently receiver operating characteristic roc curves have been used to evaluate the tradeoff between true and false positive rates of classification algorithms as a performance metric the uncertainty coefficient has the advantage over simple accuracy in that it is not affected by the relative sizes of the different classes 91 10 93 further it will not penalize an algorithm for simply rearranging the classes application domains edit see also cluster analysis 160 applications classification has many applications in some of these it is employed as a data mining procedure while in others more detailed statistical modeling is undertaken biological classification 160 8211 the science of identifying describing defining and naming groups of biological organisms biometric identification computer vision 160 8211 computerized information extraction from images medical image analysis and medical imaging 160 8211 technique and process of creating visual representations of the interior of a body optical character recognition 160 8211 computer recognition of visual text video tracking credit scoring document classification 160 8211 process of categorizing documents drug discovery and development 160 8211 process of bringing a new pharmaceutical drug to the market toxicogenomics quantitative structure activity relationship geostatistics 160 8211 branch of statistics focusing on spatial data sets handwriting recognition 160 8211 ability of a computer to receive and interpret intelligible handwritten input internet search engines micro array classification pattern recognition 160 8211 automated recognition of patterns and regularities in data recommender system 160 8211 information filtering system to predict users preferences speech recognition 160 8211 automatic conversion of spoken language into text statistical natural language processing this article includes a list of general references but it lacks sufficient corresponding inline citations please help to improve this article by introducing more precise citations january 2010 learn how and when to remove this template message see also edit wikimedia commons has media related to statistical classification mathematics portal artificial intelligence 160 8211 the ability of systems to perceive synthesize and infer information binary classification class membership probabilities classification rule compound term processing confusion matrix 160 8211 table layout for visualizing performance also called an error matrix data mining 160 8211 process of extracting and discovering patterns in large data sets data warehouse 160 8211 centralized storage of knowledge fuzzy logic 160 8211 system for reasoning about vagueness information retrieval 160 8211 obtaining information resources relevant to an information need list of datasets for machine learning research machine learning 160 8211 study of algorithms that improve automatically through experience recommender system 160 8211 information filtering system to predict users preferences references edit fisher r a 1936 the use of multiple measurements in taxonomic problems annals of eugenics 7 2 179 188 doi 10 1111 j 1469 1809 1936 tb02137 x hdl 2440 15227 fisher r a 1938 the statistical utilization of multiple measurements annals of eugenics 8 4 376 386 doi 10 1111 j 1469 1809 1938 tb02189 x hdl 2440 15232 a b gnanadesikan r 1977 methods for statistical data analysis of multivariate observations wiley isbn 160 0 471 30845 5 p 83 8211 86 rao c r 1952 advanced statistical methods in multivariate analysis wiley section 9c anderson t w 1958 an introduction to multivariate statistical analysis wiley binder d a 1978 bayesian cluster analysis biometrika 65 31 38 doi 10 1093 biomet 65 1 31 binder david a 1981 approximations to bayesian clustering rules biometrika 68 275 285 doi 10 1093 biomet 68 1 275 har peled s roth d zimak d 2003 constraint classification for multiclass classification and ranking in becker b thrun s obermayer k eds advances in neural information processing systems 15 proceedings of the 2002 conference mit press isbn 160 0 262 02550 7 a tour of the top 10 algorithms for machine learning newbies built in 2018 01 20 retrieved 2019 06 10 peter mills 2011 efficient statistical classification of satellite measurements international journal of remote sensing 32 21 6109 6132 arxiv 1202 2194 bibcode 2011ijrs 32 6109m doi 10 1080 01431161 2010 507795 s2cid 160 88518570 vtestatistics outline index descriptive statisticscontinuous datacenter mean arithmetic cubic generalized power geometric harmonic heinz lehmer median mode dispersion average absolute deviation coefficient of variation interquartile range percentile range standard deviation variance shape central limit theorem moments kurtosis l moments skewness count data index of dispersion summary tables contingency table frequency distribution grouped data dependence partial correlation pearson product moment correlation rank correlation kendall s spearman s scatter plot graphics bar chart biplot box plot control chart correlogram fan chart forest plot histogram pie chart q q plot radar chart run chart scatter plot stem and leaf display violin plot data collectionstudy design effect size missing data optimal design population replication sample size determination statistic statistical power survey methodology sampling cluster stratified opinion poll questionnaire standard error controlled experiments blocking factorial experiment interaction random assignment randomized controlled trial randomized experiment scientific control adaptive designs adaptive clinical trial stochastic approximation up and down designs observational studies cohort study cross sectional study natural experiment quasi experiment statistical inferencestatistical theory population statistic probability distribution sampling distribution order statistic empirical distribution density estimation statistical model model specification lp space parameter location scale shape parametric family likelihood 160 monotone location scale family exponential family completeness sufficiency statistical functional bootstrap u v optimal decision loss function efficiency statistical distance divergence asymptotics robustness frequentist inferencepoint estimation estimating equations maximum likelihood method of moments m estimator minimum distance unbiased estimators mean unbiased minimum variance rao blackwellization lehmann scheff theorem median unbiased plug in interval estimation confidence interval pivot likelihood interval prediction interval tolerance interval resampling bootstrap jackknife testing hypotheses 1 amp 2 tails power uniformly most powerful test permutation test randomization test multiple comparisons parametric tests likelihood ratio score lagrange multiplier wald specific tests z test normal student s t test f test goodness of fit chi squared g test kolmogorov smirnov anderson darling lilliefors jarque bera normality shapiro wilk likelihood ratio test model selection cross validation aic bic rank statistics sign sample median signed rank wilcoxon hodges lehmann estimator rank sum mann whitney nonparametric anova 1 way kruskal wallis 2 way friedman ordered alternative jonckheere terpstra van der waerden test bayesian inference bayesian probability prior posterior credible interval bayes factor bayesian estimator maximum posterior estimator correlationregression analysiscorrelation pearson product moment partial correlation confounding variable coefficient of determination regression analysis errors and residuals regression validation mixed effects models simultaneous equations models multivariate adaptive regression splines mars linear regression simple linear regression ordinary least squares general linear model bayesian regression non standard predictors nonlinear regression nonparametric semiparametric isotonic robust heteroscedasticity homoscedasticity generalized linear model exponential families logistic bernoulli 160 32 binomial 160 32 poisson regressions partition of variance analysis of variance anova anova analysis of covariance multivariate anova degrees of freedom categorical 160 32 multivariate 160 32 time series 160 32 survival analysiscategorical cohen s kappa contingency table graphical model log linear model mcnemar s test cochran mantel haenszel statistics multivariate regression manova principal components canonical correlation discriminant analysis cluster analysis classification structural equation model factor analysis multivariate distributions elliptical distributions normal time seriesgeneral decomposition trend stationarity seasonal adjustment exponential smoothing cointegration structural break granger causality specific tests dickey fuller johansen q statistic ljung box durbin watson breusch godfrey time domain autocorrelation acf partial pacf cross correlation xcf arma model arima model box jenkins autoregressive conditional heteroskedasticity arch vector autoregression var frequency domain spectral density estimation fourier analysis least squares spectral analysis wavelet whittle likelihood survivalsurvival function kaplan meier estimator product limit proportional hazards models accelerated failure time aft model first hitting time hazard function nelson aalen estimator test log rank test applicationsbiostatistics bioinformatics clinical trials 160 32 studies epidemiology medical statistics engineering statistics chemometrics methods engineering probabilistic design process 160 32 quality control reliability system identification social statistics actuarial science census crime statistics demography econometrics jurimetrics national accounts official statistics population statistics psychometrics spatial statistics cartography environmental statistics geographic information system geostatistics kriging category 160 mathematics 32 portal commons wikiproject retrieved from https en wikipedia org w index php title statistical classification amp oldid 1129334755 categories statistical classificationclassification algorithmshidden categories articles with short descriptionshort description is different from wikidataarticles lacking in text citations from january 2010all articles lacking in text citationscommons category link from wikidata 